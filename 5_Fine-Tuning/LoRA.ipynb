{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jchen8000/DemystifyingLLMs/blob/main/5_Fine-Tuning/LoRA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdgvQPG0U4ip"
      },
      "source": [
        "# 5. Pre-Training\n",
        "\n",
        "## 5.3 Low-Rank Adaptation (LoRA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56k5pOKQUKty"
      },
      "source": [
        "This script is tested on Google Colab with T4 GPU. This script uses the HuggingFace datasets, as a prerequisite you need a HuggingFace account and obtain a access token, see https://huggingface.co/docs/hub/security-tokens. You should add the token to Colab Secrets as HF_TOKEN to run this script.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-03-21T13:02:58.827156Z",
          "iopub.status.busy": "2024-03-21T13:02:58.826765Z",
          "iopub.status.idle": "2024-03-21T13:03:21.416849Z",
          "shell.execute_reply": "2024-03-21T13:03:21.416022Z",
          "shell.execute_reply.started": "2024-03-21T13:02:58.827132Z"
        },
        "id": "sYmMFmg8oWvD",
        "outputId": "5b454499-17d6-42df-d518-8f387b88a84f",
        "tags": []
      },
      "outputs": [],
      "source": [
        "%pip install \\\n",
        "  numpy==2.0.2 \\\n",
        "  pandas==2.2.2 \\\n",
        "  matplotlib==3.10.0 \\\n",
        "  torch==2.9.0+cu126 \\\n",
        "  torchvision==0.24.0 \\\n",
        "  torchaudio==2.9.0 \\\n",
        "  datasets==4.0.0 \\\n",
        "  sentencepiece==0.2.1 \\\n",
        "  transformers==4.57.3 \\\n",
        "  accelerate==1.12.0 \\\n",
        "  peft==0.18.0 \\\n",
        "  rouge_score==0.1.2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-21T13:03:21.419003Z",
          "iopub.status.busy": "2024-03-21T13:03:21.418646Z",
          "iopub.status.idle": "2024-03-21T13:03:25.865365Z",
          "shell.execute_reply": "2024-03-21T13:03:25.864736Z",
          "shell.execute_reply.started": "2024-03-21T13:03:21.418950Z"
        },
        "id": "kXgqFoscotiD",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import torch\n",
        "from datasets import load_dataset, Dataset\n",
        "from transformers import T5Tokenizer\n",
        "from transformers import T5ForConditionalGeneration\n",
        "from transformers import TrainingArguments\n",
        "from transformers import Trainer\n",
        "from transformers import GenerationConfig\n",
        "from rouge_score import rouge_scorer\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "import warnings\n",
        "\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqfmuKDiwb8e"
      },
      "source": [
        "### Load FLAN-T5 Base model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313,
          "referenced_widgets": [
            "58980f9da63f456bbb1ccb6c4b3c23c6",
            "253670ae2f214e09a8c1172df6f101db",
            "dcc0d76b971d423c91e5515757227006",
            "f6dcbdba12ce492fbdff5f5831de401a",
            "31d88d1a07bc4cd0928c8b0cf1f7ebc3",
            "31df9c08c2f64bb08efc93153bca03bd",
            "9114eaa1f668454793bd0f8244342899",
            "e2d2ea362d4b470d859e5c9e387e1f6b",
            "f834854caa08474c96b18d324174dd5f",
            "4f0dcb67569e4fc68e645d6e36354f8d",
            "7334dbb47f694c33a48fa4c349b5e6bc",
            "95cecf25373d46c1b29bce34c7388222",
            "02c1588498ea4215a485ab8a773eabd6",
            "ee1dbe136383414fbeba11175c4449bf",
            "e8a3809957314cc9a6df66c88bb68f78",
            "3ff6218562e449ceb469882251f1b0cd",
            "d3ed3dfaffc34e67a90b672f8709e0ee",
            "550241edd3c2421798c962f62cfdcd7e",
            "7b8718e4d40949b0b6d312d6240e706d",
            "13297ad743094fd8a3534146f5c6a163",
            "626393381074401cbeb0b8587a6458db",
            "88924305a0d94375b7668f35c3ef9f64",
            "6fe0a96c1fa744d386ff5d85bd77efe7",
            "e2d2f54777f6427a8f44a72d2eba5d38",
            "6bc358cbf3894295a72d4f4235e0b55a",
            "b29672a15fde49c09207699ec0955489",
            "1cbf02dc710f441da13bcd29c261c85d",
            "14492504d1a742b48f0da3662d19b6d1",
            "a4fdd61324164843b326b5cd06fc3585",
            "319ef5f4af6245d99ed8d730a032d6f5",
            "7a3ac908f77c486d8785c6818d00e01d",
            "a43f4ef2dd414e2cb673f78ae0be984b",
            "528b28e6f0a2456aa15a4f54ebb2f3af",
            "6e845ff6fdd24bb8ba6670074135bfc4",
            "406f4fee5c11440a9145c720a125be5a",
            "28e84fb34f304953a5ec8ee79149eaca",
            "5a5a4054ff744ced88eb4de8c8eb2893",
            "69b2c2022f0a45a0b47af0a8fef8b7be",
            "f7f5aafd03734517a517894bd70c570e",
            "f739fe67039b4a8aa31c6e3812e0c396",
            "babf3e1578fc4fdeb3330f82d68438e1",
            "452575682fc249e58ad57320d315510f",
            "f1992a5bdcde4c09b0c384989981363d",
            "90927dd486424aad9dd0eb68e8aef335",
            "f217032b68b34d47a23f5f5b3afefa1f",
            "c38d6da834164fb595a2564e3df88d09",
            "e8036d3d74bc4a8fbf8c1d6b0efc08ca",
            "50d92ef740774829872f40caeac13f96",
            "76014cd611a8454b845bc7bc8400de6d",
            "774b0cadaf424e86b1e721e71f62c486",
            "2cc86350ec554ab6936f6e638cc1e8c2",
            "c81f76d7a00c4cee99f8a3aa977dfc36",
            "710cc8aedc634926b0b14006e5024dfe",
            "bfd68a11bc774ca4ad71ba07c2aa54c9",
            "fc90b4e4250c4ac18471ab13f28f22ae",
            "0cedc4df81b5407e9c517559afbc5848",
            "412a7c8c2efb4404bdea6e40eaaaa7b5",
            "cd6a5275f13c44c8b38dc882364b81d2",
            "43b5fb5217e54b85b530fc760e3fd7ac",
            "05706e182cbe40708a73e2f09e1019f1",
            "28df8a351079420dbb2e2ee7d7d98b63",
            "8c0dc9dc28d9449abba315927a805a37",
            "3d7b9eb94c4943198430b6b81ff028c1",
            "42336ba3b3804d7f9464663f3b2f9908",
            "981a26e4cf954d9dbde9edba74bcbd30",
            "8adf63d78b1949978bf5498b783f8e52",
            "b99b903ac906405ea797de2989142c89",
            "cdc6b50a958b44dba228c398214e87c8",
            "3cbd41e63e48450db651454925c1a524",
            "ceed615e28f24dad885eceb59d735e43",
            "42184dc365df42ee9e491590b4bd542c",
            "aaddad89ab9b4413959c23646cd6e357",
            "8a3a80562ae24901949f556121a64ff6",
            "f61971cb307a4595b2775b052331238a",
            "5fbc2b440c6a4ea5a6e58a20b44c7c35",
            "3bc420a873da425f8a3f617e3ad6e7dd",
            "33d0a822caf844daa646fffd8391dd90"
          ]
        },
        "execution": {
          "iopub.execute_input": "2024-03-21T13:03:25.866901Z",
          "iopub.status.busy": "2024-03-21T13:03:25.866478Z",
          "iopub.status.idle": "2024-03-21T13:03:28.186800Z",
          "shell.execute_reply": "2024-03-21T13:03:28.185869Z",
          "shell.execute_reply.started": "2024-03-21T13:03:25.866875Z"
        },
        "id": "n6ig7sObojuf",
        "outputId": "2170191c-2d73-475a-e243-034d74d1eda5",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "58980f9da63f456bbb1ccb6c4b3c23c6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "95cecf25373d46c1b29bce34c7388222",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6fe0a96c1fa744d386ff5d85bd77efe7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6e845ff6fdd24bb8ba6670074135bfc4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f217032b68b34d47a23f5f5b3afefa1f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0cedc4df81b5407e9c517559afbc5848",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b99b903ac906405ea797de2989142c89",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameters of the model: 247,577,856\n"
          ]
        }
      ],
      "source": [
        "model_name = 'google/flan-t5-base'\n",
        "lora_model_name = 'outputs/flan-t5-base_lora'\n",
        "def load_model(model_name):\n",
        "    tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "    model = T5ForConditionalGeneration.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n",
        "    return tokenizer, model\n",
        "\n",
        "tokenizer, model = load_model(model_name)\n",
        "total_parameter = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Parameters of the model: {total_parameter:,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxciSoTmC40P"
      },
      "source": [
        "### Load TweetSum Dataset\n",
        "\n",
        "https://github.com/sarahaman/CIS6930_TweetSum_Summarization\n",
        "\n",
        "Make sure the three files in the datasets folder:\n",
        "\n",
        "*  tweetsum_train.csv\n",
        "*  tweetsum_valid.csv\n",
        "*  tweetsum_test.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356,
          "referenced_widgets": [
            "c05d16a1cf2e401c8d278022dd4e6f10",
            "55d8cf7d68b945ba9a08faa4d7523262",
            "24e75d939176477fa4ec938defbb00f5",
            "a8a7f4a7712a48568c75dde7098d3b8b",
            "95f94a5ceb9e4ea98a784f70473091ca",
            "9fe6cfab1ac84f9ea713c0103514a384",
            "108b981ae0274fa9836fc8fe346ad1bd",
            "aa48e89024e54b66aa5712b73b2983fd",
            "52ab864fd5b245818d00a6adc5bd5a24",
            "0b3a505b71be4f1e8fb81d787fb7cc8f",
            "8967bc852f844a988f8cca1d953f00c0",
            "4c2fb2c66c974a68bb517b167f98e65d",
            "6de23e7242ff434ca6785de2860ba00b",
            "f786bf509679492a94752d1050ac6d5d",
            "fc520b161d2542d79e02d192d784e935",
            "a749fed5d3d24d8cab91859d24eccb46",
            "9c5e9a15b74348299ea21e225c3afde0",
            "79c5c098ab4d4ed6842d69d98ab71322",
            "492e81f534df46e3af7626a7e5981cbb",
            "efe6a1f4bd87489da71b1725ed2dee38",
            "51617b63228345419d1f13ffcf51a12d",
            "b2fb2d7938ec4a5a9fd556e047b686d4",
            "9b49c3e159ea4c06aee2a68cf54317d4",
            "4123031cb7c84c309a53bce674471e2b",
            "0c61ac99b2994cb2bb81ceb043c78f68",
            "8979bef972e14ee6866ff08f15f92f8c",
            "eb8c1dfe021a41378549440b64d4d66c",
            "b509309bf1ae4e799cbd0f93700a983d",
            "9d5d02522aa348f9b7d5521fdbb8ab85",
            "3c7e5b496b2a4978bc79bae0b7364673",
            "cddfc084ac9045db8628cc6c659caa90",
            "99b1dfe2a6fc404cb372ca1e088562c6",
            "359cadf700fd42b5822ec54926c589b7"
          ]
        },
        "execution": {
          "iopub.execute_input": "2024-03-21T13:03:28.188738Z",
          "iopub.status.busy": "2024-03-21T13:03:28.188366Z",
          "iopub.status.idle": "2024-03-21T13:03:28.295422Z",
          "shell.execute_reply": "2024-03-21T13:03:28.290470Z",
          "shell.execute_reply.started": "2024-03-21T13:03:28.188701Z"
        },
        "id": "RsIfk6HApI8q",
        "outputId": "a3af8201-e95b-413c-8874-e9e3f0b3d182"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c05d16a1cf2e401c8d278022dd4e6f10",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4c2fb2c66c974a68bb517b167f98e65d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9b49c3e159ea4c06aee2a68cf54317d4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['inputs', 'summaries'],\n",
            "        num_rows: 869\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['inputs', 'summaries'],\n",
            "        num_rows: 108\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['inputs', 'summaries'],\n",
            "        num_rows: 110\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import requests\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Folder and file setup\n",
        "folder = \"datasets\"\n",
        "files = {\n",
        "    \"train\": \"tweetsum_train.csv\",\n",
        "    \"validation\": \"tweetsum_valid.csv\",\n",
        "    \"test\": \"tweetsum_test.csv\"\n",
        "}\n",
        "base_url = \"https://raw.githubusercontent.com/jchen8000/DemystifyingLLMs/refs/heads/main/5_Fine-Tuning/datasets\"\n",
        "\n",
        "# Create folder if it doesn't exist\n",
        "if not os.path.exists(folder):\n",
        "    os.makedirs(folder)\n",
        "    print(f\"Created folder: {folder}\")\n",
        "\n",
        "# Download missing files\n",
        "for split, filename in files.items():\n",
        "    file_path = os.path.join(folder, filename)\n",
        "    if not os.path.exists(file_path):\n",
        "        url = f\"{base_url}/{filename}\"\n",
        "        print(f\"Downloading {filename} from {url}...\")\n",
        "        response = requests.get(url)\n",
        "        if response.status_code == 200:\n",
        "            with open(file_path, \"wb\") as f:\n",
        "                f.write(response.content)\n",
        "            print(f\"Saved {filename} to {file_path}\")\n",
        "        else:\n",
        "            print(f\"Failed to download {filename}. Status code: {response.status_code}\")\n",
        "\n",
        "# Load dataset\n",
        "tweetsum = load_dataset(\"csv\", data_files={split: os.path.join(folder, filename) for split, filename in files.items()})\n",
        "print(tweetsum)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_jz4kJ1xXDZ"
      },
      "source": [
        "### Tokenize the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-21T13:03:28.300999Z",
          "iopub.status.busy": "2024-03-21T13:03:28.296421Z",
          "iopub.status.idle": "2024-03-21T13:03:28.307214Z",
          "shell.execute_reply": "2024-03-21T13:03:28.305777Z",
          "shell.execute_reply.started": "2024-03-21T13:03:28.300974Z"
        },
        "id": "ofWryKIU9RNn"
      },
      "outputs": [],
      "source": [
        "def tokenize_function(example):\n",
        "  prompt = [\"Summarize: \" + s for s in example['inputs']]\n",
        "  example['input_ids'] = tokenizer(prompt, padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
        "  example['labels'] = tokenizer(example['summaries'], padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
        "  return example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6FSa7eCxbrA"
      },
      "source": [
        "Take a subset of the original dataset, in order to run the fine-tuning on the limited resources (single GPU, etc.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356,
          "referenced_widgets": [
            "28d94020cba84e44a539d9c2e64bff35",
            "cad41ed411734f958bc99888e915d548",
            "cb1e5752320c45d5b4c0ba78169cd7f7",
            "8406c998c3a7456590f906edfe7da349",
            "4215f48998674d08a6f9bfb241e8663e",
            "79e1e36c86a044289ca8ac4c190db33b",
            "9a3f573c6a21497bbcf1521bacaafd2a",
            "0aa30bcc4f18400baa7e64032a37091f",
            "2c3148e4bc984e2a8d1867425281875d",
            "76dd54b0b51e440188468584d7ff45aa",
            "4d5e5c9409cd474d9975d2b133454286",
            "1fa8a4558a5346eeabfe773cb962bc21",
            "6d8c7deca3a941868630e7ffefa62b62",
            "ce8661e9d23647c6928cab74d7dbcc53",
            "89dba55707f74d488916701851998f0d",
            "a5dcc869b1af4c8ea798aa2e0c86c267",
            "db75c9f990bf4607b39567030bf8d82d",
            "fdfcf9bc967c46ea84c3f1b434a0b275",
            "0730825fd9904a67bd18667930336119",
            "e128ea035b4a449781171e65b2f3ac8d",
            "d0b575568bcf41abbf8fcd0188ff8b0d",
            "8dde7f3349084d20b22b849c6bd4104e",
            "79c763329d234c89b1afffd7a9c9ee06",
            "f60550f6c26647bdaae96e43d7cf8924",
            "5344ce6a2858408dbae06f26a5eee42b",
            "ad5b99b051444146bc62301a98df78c7",
            "dba4d287def64629af1b02903d01b0ec",
            "92703efad8924358ad6ba912bfd2a46e",
            "0f82acdcdb8e475fb73e94e1200802e0",
            "f2a7383cb25140379d69b98ae6226a9d",
            "1bb6f7c7d3f3485286d59ab28d240755",
            "eab148bb0c5f4f6abc783931b740daf9",
            "766e1ed172f146629366b6f29c40f5d2"
          ]
        },
        "execution": {
          "iopub.execute_input": "2024-03-21T13:03:28.309250Z",
          "iopub.status.busy": "2024-03-21T13:03:28.308398Z",
          "iopub.status.idle": "2024-03-21T13:03:28.362747Z",
          "shell.execute_reply": "2024-03-21T13:03:28.361944Z",
          "shell.execute_reply.started": "2024-03-21T13:03:28.309219Z"
        },
        "id": "UkjdXn6v-pPq",
        "outputId": "1a56291d-898a-4bcd-dac1-661c1b025cac"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "28d94020cba84e44a539d9c2e64bff35",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/869 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1fa8a4558a5346eeabfe773cb962bc21",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/108 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "79c763329d234c89b1afffd7a9c9ee06",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/110 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['inputs', 'summaries', 'input_ids', 'labels'],\n",
            "        num_rows: 869\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['inputs', 'summaries', 'input_ids', 'labels'],\n",
            "        num_rows: 108\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['inputs', 'summaries', 'input_ids', 'labels'],\n",
            "        num_rows: 110\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "tokenized_datasets = tweetsum.map(tokenize_function, batched=True)\n",
        "print(tokenized_datasets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNTl9isaw3VQ"
      },
      "source": [
        "### Preliminary evaluation by human assessment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-21T13:03:28.365108Z",
          "iopub.status.busy": "2024-03-21T13:03:28.364815Z",
          "iopub.status.idle": "2024-03-21T13:03:28.369303Z",
          "shell.execute_reply": "2024-03-21T13:03:28.368583Z",
          "shell.execute_reply.started": "2024-03-21T13:03:28.365087Z"
        },
        "id": "LV5Z5JGSuETg"
      },
      "outputs": [],
      "source": [
        "def generate_output(tokenizer, model, input_text, max_length=200):\n",
        "    # Tokenize the input text and generate the model's output\n",
        "    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
        "    outputs = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        generation_config=GenerationConfig(max_new_tokens=200, num_beams=1) )\n",
        "\n",
        "    # Decode the generated tokens to a string\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXQHHPFKyxlo"
      },
      "source": [
        "Produce the output on the randomly selected data samples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-03-21T13:03:28.370464Z",
          "iopub.status.busy": "2024-03-21T13:03:28.370232Z",
          "iopub.status.idle": "2024-03-21T13:03:45.172046Z",
          "shell.execute_reply": "2024-03-21T13:03:45.171301Z",
          "shell.execute_reply.started": "2024-03-21T13:03:28.370446Z"
        },
        "id": "2DvKGsdBqo0_",
        "outputId": "e0170d95-4d3b-4252-a466-148298820cc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt: Summarize: VirginTrains Can you give Coach C on the 1820 Euston departure strobe lighting? This is the party carriage! BrighterAwards <BR> Glow sticks as well? MW <BR> VirginTrains Only balloon animals. Can you provide the fun? Thats what Virgin is known for! <LINK> <BR> Ahhh mannn, is it a hen party? MW <BR> VirginTrains No, just a corporate awards ceremony. You would make our day if you put strobe lighting in Coach C. Just about to leave Stoke, make our day! <BR> Ill be honest, Im not sure theres enough time. However, flashlights on your phone, you know the rest! MW <BR> VirginTrains This is why we need you to provide the fun <LINK> <BR> VirginTrains The people have spoken! <LINK> <BR> Oh my days, when the alcohol kicks in MW <BR> VirginTrains Kicked in an hour ago, we still need your help! <BR> Im on my way Jake. Get me a seat ready! MW <BR> VirginTrains Coach C. Ill buy you a gin and tonic! <BR> Dont drink Gin, Jake. If theres a cider going spare, Im there. After my shift of course MW <BR> VirginTrains You bring the strobes, Ill bring whatever you want <BR> <LINK> <BR> VirginTrains I cannot wait until you come into our office <LINK> <BR> Wheres the destination any way? MW <BR> VirginTrains Manchester Piccadilly. There in 10 minutes. I feel like youre cockminge teasing me <BR>\n",
            "Target: Customer is requesting for to put strobe lighting in coach c for corporate awards ceremony. Agent states he would bring them personally as there is a shortage of time for arrangements.\n",
            "Predict: VirginTrains is asking for a strobe lighting for Coach C on the 1820 Euston departure strobe lighting.\n",
            "\n",
            "Prompt: Summarize:  AppleSupport music and podcast skip around like a CD, then distorts and clears up in few seconds, only happens after iOS 11 <BR> Were here to help. Did this happen after a specific update, or just recently? Thanks! <BR> AppleSupport I noticed shortly after the first patch to iOS 11 not sure which one, but here in the past week or two it has gotten worse and more frequent <BR> AppleSupport Its only done it with Apple Music and Apple Podcast, regardless if saved to phone or streaming <BR> AppleSupport Its only done it with Apple Music and Apple Podcast, regardless if saved to phone or streaming <BR> We want to help further! What model of iOS device are you using? Do you have the most recent version of iOS 11.1 downloaded? <BR> AppleSupport iPhone 7 and yes the software is up to date <BR> Wed like to investigate with you. Send us a DM and we can troubleshoot more from there. <LINK> <BR>\n",
            "Target: The customer is complaining that he was facing issues with ios11.1. The agent asked them send a dm for troubleshoot it.\n",
            "Predict: AppleSupport I noticed shortly after the first patch to iOS 11 not sure which one, but here in the past week or two it has gotten worse and more frequent BR> AppleSupport Its only done it with Apple Music and Apple Podcast, regardless if saved to phone or streaming BR> AppleSupport Its only done it with Apple Music and Apple Podcast, regardless if saved to phone or streaming BR> We want to help further!\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (641 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt: Summarize: HPSupport Problems with Envy 7640 printer, set as default. HP doctor fixes problems, and then it doesnt work again. Updated drivers. <BR> Hey, Thanks for reaching out. I would love to help! Is there any error message that shows up on your printer or on your computer? .12 <BR> Send us a direct message by clicking on the link below. Cheers Mat 22 <LINK> <BR> HPSupport Cant get it to print at all from one computer. Frustrating ready to take it back. <LINK> <BR> Hi Josey, thanks for tweeting, I see from your tweet that you get User intervention required message while printing from your printer, 12 <BR> follow steps from this document <LINK> reply in direct message <LINK> <BR> HPSupport I have followed most of the steps in the document I currently have at least 6 hours troubleshooting the HP Envy printer. It should be plug and play way too complicated. <BR> HPSupport I have followed most of the steps in the document I currently have at least 6 hours troubleshooting the HP Envy printer. It should be plug and play way too complicated. <BR> Hey, Kindly click to send us a private message and we will work to resolve <LINK> <BR>\n",
            "Target: Customer complaining about the ENVY 7640  printer and also can't get it to print at all from one computer. Agent says to click to send a private message and will work to resolve.\n",
            "Predict: HPSupport Can't get it to print at all from one computer. Frustrating ready to take it back. LINK> BR> Hi Josey, thanks for tweeting, I see from your tweet that you get User intervention required message while printing from your printer, 12 BR> follow steps from this document LINK> reply in direct message LINK> BR> HPSupport I have followed most of the steps in the document I currently have at least 6 hours troubleshooting the HP Envy printer. It should be plug and play way too complicated. BR> HPSupport I have followed most of the steps in the document I currently have at least 6 hours troubleshooting the HP Envy printer. It should be plug and play way too complicated. BR>\n",
            "\n",
            "Prompt: Summarize:  saludos,es que tengo un problema con mi iPhone,y lo que ocurre es que no puedo llamar ni recibir llamadas,y no s qu ms hacer,ya que acud a Apple Support y aunque intenten llamarme,no entran llamadas,quiero saber cual es su recomendacin.Gracias. <BR> We offer support via Twitter in English. Get help in Spanish here <LINK> or join <LINK> <BR> AppleSupport I can speak English so so,can you help me?i have an iPhone 7,and 1 week ago,I cant make calls or receive them,what I do? <BR> Being able to make and receive calls is important and wed like to help. Which exact iOS version is installed on it and have you tried any steps yet? <BR> AppleSupport I have iOS 11.1.2 and I have tried everything what the page said.im Colombian. <BR> Is this the page youve tried all the steps from <LINK> yes, what did you find out when you contacted your carrier and when you restored it as new in iTunes? <BR> AppleSupport My Carrier didnt give me a solution,and I dont want restored my phone,that scary me.,can you do something or. I dont know if is the iOS. <BR> To make sure, did your carrier find everything ok on their end when you asked them about the section Contact your carrier in the link we provided? <BR> AppleSupport Yes,I contact them but they dont give me a solution,and yes,I complete everything you say me,without restored. I dont like it. <BR> Got it. Let us know if you have a recent backup of your data in DM. Well continue there <LINK> <BR> AppleSupport Not new but recent.my information can delete? Or my pictures? Or my messages? <BR> With restoring, your information will be deleted, which is why you want to have a recent backup. You can follow the steps in this link for restoring <LINK> If you have any questions, send them over to us in DM from this link <LINK> <BR> AppleSupport Ok thanks,Ill ask you question,but,the best idea can be than I wait for a new iOS,thats can be the problem? <BR> Restoring your device will place a new version of the iOS on your device which can help resolve this issue. Lets discuss it more in DM. <LINK> <BR> AppleSupport Ok,thank you very much. <BR>\n",
            "Target: Customer is unable to do incoming and outgoing calls. Agent ask customer  to restore the device and ask DM for further assistance.\n",
            "Predict: \n",
            "\n",
            "Prompt: Summarize: Oh Delta . Sorry, not sorry is the worst answer to give a customer. And I would agree, it IS an act of god that there was ice in 45 degree weather in FL. Ice freezes at 32degrees Still waiting 3 flights later. SoDisappointed <BR> Hi, Aimee. What flight are you referring to? I would like to take a look. AJL <BR> Delta DL 1234. It says deicing but the pilot let us know once maintenance got there, they found no ice. Missed DL 801, missed standby on the overbooked DL 2335, now waiting for flight 1765. Missed all mtgs by now. My compensation I was told was moving my seat from row 43 to 29. <BR> Delta .uh.hello? Delta AJL <BR> Hello! How may I help you? TCC <BR> Delta Well I already replied to one rep and havent heard back. <BR> Hi, Aimee. My sincere apologies for the delayed response. I am reviewing the details for the delay on DL1234. AJL <BR> The flight history does indicate the delay was for deicing. Do you have additional information from the pilot what the maintenance was for? AJL <BR> Delta The pilot announced over the speaker that he apologized for the delay maintenance took to get there and that once they checked out the wings, there was in fact no ice. Once we were able to taxi, he announced wed have to wait another 5 mins for takeoff line up. <BR> Aimee, all delays are frustrating and Im sorry that you were affected. Well try to have you on your way asap. TLT <BR> Delta Not a great response for what took me 3 flights to try to get where I shouldve been.especially when it means missed meetings and loss of business. Im sure Delta wouldnt be happy about that either. NotASatisfiedCustomer <BR>\n",
            "Target: Customer is complaining about the delay of flights. Agent updated that the flight history does indicate the delay was for deicing.\n",
            "Predict: I'm sorry to hear that. I'm sorry to hear that. I'm sorry to hear that. I'm sorry to hear that. I'm sorry to hear that. I'm sorry to hear that. I'm sorry to hear that. I'm sorry to hear that. I'm sorry to hear that. I'm sorry to hear that. I'm sorry to hear that. I'm sorry to hear that. I'm sorry to hear that. I'm sorry to hear that. I'm sorry to hear that. I'm sorry to hear that. I'm sorry to hear that. I'm sorry to hear that. I'm sorry to hear that. I'm sorry to hear that. I'm sorry to hear that. I'm sorry to hear that. I'm sorry to hear that. I'm sorry to hear that. I'm sorry to hear that.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for item in random.choices(list(tokenized_datasets['test']), k = 5):\n",
        "    prompt = \"Summarize: \" + item['inputs']\n",
        "    output = generate_output(tokenizer, model, prompt)\n",
        "    print(\"Prompt:\", prompt)\n",
        "    print(\"Target:\", item['summaries'])\n",
        "    print(\"Predict:\", output)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tz6SG4_WxtEf"
      },
      "source": [
        "### Fine-tuning with LoRA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-21T13:03:45.173529Z",
          "iopub.status.busy": "2024-03-21T13:03:45.173162Z",
          "iopub.status.idle": "2024-03-21T13:03:45.178693Z",
          "shell.execute_reply": "2024-03-21T13:03:45.177809Z",
          "shell.execute_reply.started": "2024-03-21T13:03:45.173498Z"
        },
        "id": "SIO9kjAW0llM"
      },
      "outputs": [],
      "source": [
        "rank = 16\n",
        "lora_config = LoraConfig(\n",
        "    r=rank,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.SEQ_2_SEQ_LM  #FLAN-T5\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-03-21T13:03:45.180246Z",
          "iopub.status.busy": "2024-03-21T13:03:45.179800Z",
          "iopub.status.idle": "2024-03-21T13:03:45.301539Z",
          "shell.execute_reply": "2024-03-21T13:03:45.300646Z",
          "shell.execute_reply.started": "2024-03-21T13:03:45.180219Z"
        },
        "id": "uvSpCtFS0-kx",
        "outputId": "e87a9fba-a20d-4661-9d35-7c627fb6941d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Parameters: 249,347,328\n",
            "LoRA Parameters: 1,769,472; Percentage: 0.007096414524241463\n"
          ]
        }
      ],
      "source": [
        "lora_model = get_peft_model(model, lora_config)\n",
        "total_parameter = sum(p.numel() for p in lora_model.parameters())\n",
        "lora_parameter = sum(p.numel() for p in lora_model.parameters() if p.requires_grad)\n",
        "print(f\"Total Parameters: {total_parameter:,}\")\n",
        "print(f\"LoRA Parameters: {lora_parameter:,}; Percentage: {lora_parameter/total_parameter}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-21T13:03:45.303476Z",
          "iopub.status.busy": "2024-03-21T13:03:45.302595Z",
          "iopub.status.idle": "2024-03-21T13:03:45.307015Z",
          "shell.execute_reply": "2024-03-21T13:03:45.306222Z",
          "shell.execute_reply.started": "2024-03-21T13:03:45.303444Z"
        },
        "id": "7QJiI6JBJS9k"
      },
      "outputs": [],
      "source": [
        "# print(lora_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "execution": {
          "iopub.execute_input": "2024-03-21T13:03:45.308522Z",
          "iopub.status.busy": "2024-03-21T13:03:45.308146Z",
          "iopub.status.idle": "2024-03-21T13:14:20.900063Z",
          "shell.execute_reply": "2024-03-21T13:14:20.899355Z",
          "shell.execute_reply.started": "2024-03-21T13:03:45.308492Z"
        },
        "id": "RY_srjsb1nil",
        "outputId": "89ed7be4-089f-4870-c92b-531acd9ef699"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 11:30, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>43.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>42.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>37.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>35.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>33.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>31.375000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>28.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>26.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>24.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>23.125000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>20.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>18.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>16.125000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>14.187500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>10.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>7.218800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>6.375000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>5.718800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>5.312500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>5.187500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>4.968800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>4.875000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>4.718800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>4.625000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>4.593800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>4.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>4.437500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>4.375000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>4.343800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>4.312500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>4.218800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>4.125000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>4.062500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>3.953100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>3.859400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>3.734400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>3.562500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>3.296900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>3.046900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>2.953100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>2.734400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>2.515600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>2.406200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>2.218800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>2.078100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>1.937500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>1.921900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>1.710900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>1.710900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.585900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>1.328100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>1.187500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>1.343800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>1.304700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>1.085900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>1.023400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.886700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.863300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.777300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.726600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>0.722700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>0.695300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>0.703100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>0.613300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>0.601600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>0.558600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>0.550800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>0.609400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>0.574200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.539100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>0.498000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>0.531200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>0.474600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>0.474600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.466800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>0.462900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>0.445300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>0.408200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>0.392600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.386700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>0.447300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>0.486300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83</td>\n",
              "      <td>0.343800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>0.361300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>0.392600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>0.375000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>0.449200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>0.427700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>89</td>\n",
              "      <td>0.351600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.390600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>91</td>\n",
              "      <td>0.302700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92</td>\n",
              "      <td>0.339800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>0.328100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>94</td>\n",
              "      <td>0.341800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>0.349600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>0.427700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>97</td>\n",
              "      <td>0.355500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>98</td>\n",
              "      <td>0.279300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>99</td>\n",
              "      <td>0.351600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.337900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>101</td>\n",
              "      <td>0.324200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>102</td>\n",
              "      <td>0.291000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>103</td>\n",
              "      <td>0.302700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>104</td>\n",
              "      <td>0.334000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>105</td>\n",
              "      <td>0.304700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>106</td>\n",
              "      <td>0.304700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>107</td>\n",
              "      <td>0.310500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>108</td>\n",
              "      <td>0.388700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>109</td>\n",
              "      <td>0.351600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.334000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>111</td>\n",
              "      <td>0.324200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>112</td>\n",
              "      <td>0.330100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>113</td>\n",
              "      <td>0.326200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>114</td>\n",
              "      <td>0.306600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>115</td>\n",
              "      <td>0.298800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>116</td>\n",
              "      <td>0.316400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>117</td>\n",
              "      <td>0.275400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>118</td>\n",
              "      <td>0.275400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>119</td>\n",
              "      <td>0.287100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.414100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>121</td>\n",
              "      <td>0.339800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>122</td>\n",
              "      <td>0.287100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>123</td>\n",
              "      <td>0.294900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>124</td>\n",
              "      <td>0.293000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>0.243200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>126</td>\n",
              "      <td>0.269500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>127</td>\n",
              "      <td>0.253900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>128</td>\n",
              "      <td>0.279300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>129</td>\n",
              "      <td>0.238300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.300800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>131</td>\n",
              "      <td>0.337900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>132</td>\n",
              "      <td>0.312500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>133</td>\n",
              "      <td>0.269500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>134</td>\n",
              "      <td>0.308600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>135</td>\n",
              "      <td>0.273400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>136</td>\n",
              "      <td>0.306600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>137</td>\n",
              "      <td>0.334000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>138</td>\n",
              "      <td>0.269500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>139</td>\n",
              "      <td>0.337900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>141</td>\n",
              "      <td>0.252000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>142</td>\n",
              "      <td>0.267600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>143</td>\n",
              "      <td>0.306600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>144</td>\n",
              "      <td>0.257800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>145</td>\n",
              "      <td>0.289100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>146</td>\n",
              "      <td>0.296900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>147</td>\n",
              "      <td>0.283200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>148</td>\n",
              "      <td>0.275400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>149</td>\n",
              "      <td>0.243200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.306600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>151</td>\n",
              "      <td>0.265600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>152</td>\n",
              "      <td>0.298800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>153</td>\n",
              "      <td>0.255900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>154</td>\n",
              "      <td>0.216800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>155</td>\n",
              "      <td>0.285200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>156</td>\n",
              "      <td>0.289100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>157</td>\n",
              "      <td>0.247100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>158</td>\n",
              "      <td>0.257800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>159</td>\n",
              "      <td>0.244100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.337900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>161</td>\n",
              "      <td>0.227500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>162</td>\n",
              "      <td>0.285200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>163</td>\n",
              "      <td>0.269500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>164</td>\n",
              "      <td>0.269500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>165</td>\n",
              "      <td>0.225600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>166</td>\n",
              "      <td>0.263700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>167</td>\n",
              "      <td>0.210000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>168</td>\n",
              "      <td>0.229500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>169</td>\n",
              "      <td>0.232400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.328100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>171</td>\n",
              "      <td>0.257800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>172</td>\n",
              "      <td>0.255900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>173</td>\n",
              "      <td>0.300800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>174</td>\n",
              "      <td>0.230500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>0.225600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>176</td>\n",
              "      <td>0.223600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>177</td>\n",
              "      <td>0.255900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>178</td>\n",
              "      <td>0.281200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>179</td>\n",
              "      <td>0.219700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.246100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>181</td>\n",
              "      <td>0.191400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>182</td>\n",
              "      <td>0.277300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>183</td>\n",
              "      <td>0.271500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>184</td>\n",
              "      <td>0.208000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>185</td>\n",
              "      <td>0.277300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>186</td>\n",
              "      <td>0.228500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>187</td>\n",
              "      <td>0.273400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>188</td>\n",
              "      <td>0.249000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>189</td>\n",
              "      <td>0.225600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.208000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>191</td>\n",
              "      <td>0.252000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>192</td>\n",
              "      <td>0.206100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>193</td>\n",
              "      <td>0.298800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>194</td>\n",
              "      <td>0.253900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>195</td>\n",
              "      <td>0.227500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>196</td>\n",
              "      <td>0.287100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>197</td>\n",
              "      <td>0.281200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>198</td>\n",
              "      <td>0.281200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>199</td>\n",
              "      <td>0.199200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.255900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>201</td>\n",
              "      <td>0.289100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>202</td>\n",
              "      <td>0.217800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>203</td>\n",
              "      <td>0.252000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>204</td>\n",
              "      <td>0.208000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>205</td>\n",
              "      <td>0.253900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>206</td>\n",
              "      <td>0.207000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>207</td>\n",
              "      <td>0.214800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>208</td>\n",
              "      <td>0.285200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>209</td>\n",
              "      <td>0.255900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.239300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>211</td>\n",
              "      <td>0.279300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>212</td>\n",
              "      <td>0.247100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>213</td>\n",
              "      <td>0.235400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>214</td>\n",
              "      <td>0.259800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>215</td>\n",
              "      <td>0.263700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>216</td>\n",
              "      <td>0.293000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>217</td>\n",
              "      <td>0.300800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>218</td>\n",
              "      <td>0.227500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>219</td>\n",
              "      <td>0.269500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.210900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>221</td>\n",
              "      <td>0.219700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>222</td>\n",
              "      <td>0.261700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>223</td>\n",
              "      <td>0.252000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>224</td>\n",
              "      <td>0.252000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>0.222700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>226</td>\n",
              "      <td>0.238300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>227</td>\n",
              "      <td>0.252000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>228</td>\n",
              "      <td>0.236300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>229</td>\n",
              "      <td>0.233400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.298800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>231</td>\n",
              "      <td>0.240200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>232</td>\n",
              "      <td>0.279300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>233</td>\n",
              "      <td>0.257800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>234</td>\n",
              "      <td>0.241200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>235</td>\n",
              "      <td>0.215800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>236</td>\n",
              "      <td>0.229500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>237</td>\n",
              "      <td>0.248000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>238</td>\n",
              "      <td>0.228500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>239</td>\n",
              "      <td>0.231400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.283200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>241</td>\n",
              "      <td>0.204100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>242</td>\n",
              "      <td>0.234400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>243</td>\n",
              "      <td>0.224600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>244</td>\n",
              "      <td>0.296900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>245</td>\n",
              "      <td>0.239300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>246</td>\n",
              "      <td>0.283200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>247</td>\n",
              "      <td>0.247100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>248</td>\n",
              "      <td>0.271500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>249</td>\n",
              "      <td>0.296900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.283200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>251</td>\n",
              "      <td>0.241200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>252</td>\n",
              "      <td>0.269500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>253</td>\n",
              "      <td>0.211900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>254</td>\n",
              "      <td>0.231400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>255</td>\n",
              "      <td>0.238300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>256</td>\n",
              "      <td>0.230500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>257</td>\n",
              "      <td>0.242200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>258</td>\n",
              "      <td>0.314500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>259</td>\n",
              "      <td>0.218800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.267600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>261</td>\n",
              "      <td>0.226600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>262</td>\n",
              "      <td>0.312500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>263</td>\n",
              "      <td>0.226600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>264</td>\n",
              "      <td>0.202100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>265</td>\n",
              "      <td>0.234400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>266</td>\n",
              "      <td>0.287100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>267</td>\n",
              "      <td>0.265600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>268</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>269</td>\n",
              "      <td>0.220700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>0.230500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>271</td>\n",
              "      <td>0.261700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>272</td>\n",
              "      <td>0.316400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>273</td>\n",
              "      <td>0.186500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>274</td>\n",
              "      <td>0.238300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>0.215800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>276</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>277</td>\n",
              "      <td>0.269500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>278</td>\n",
              "      <td>0.244100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>279</td>\n",
              "      <td>0.257800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.247100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>281</td>\n",
              "      <td>0.252000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>282</td>\n",
              "      <td>0.244100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>283</td>\n",
              "      <td>0.245100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>284</td>\n",
              "      <td>0.248000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>285</td>\n",
              "      <td>0.241200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>286</td>\n",
              "      <td>0.257800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>287</td>\n",
              "      <td>0.294900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>288</td>\n",
              "      <td>0.246100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>289</td>\n",
              "      <td>0.197300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>0.255900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>291</td>\n",
              "      <td>0.261700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>292</td>\n",
              "      <td>0.269500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>293</td>\n",
              "      <td>0.257800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>294</td>\n",
              "      <td>0.224600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>295</td>\n",
              "      <td>0.257800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>296</td>\n",
              "      <td>0.241200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>297</td>\n",
              "      <td>0.205100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>298</td>\n",
              "      <td>0.200200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>299</td>\n",
              "      <td>0.231400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.277300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=300, training_loss=2.068942057291667, metrics={'train_runtime': 694.4886, 'train_samples_per_second': 3.456, 'train_steps_per_second': 0.432, 'total_flos': 1652322450014208.0, 'train_loss': 2.068942057291667, 'epoch': 2.75})"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max_steps = 300\n",
        "\n",
        "lora_training_args = TrainingArguments(\n",
        "    learning_rate=1e-3,\n",
        "    auto_find_batch_size=True,\n",
        "    logging_steps=1,\n",
        "    max_steps=max_steps,\n",
        "    report_to=\"none\",\n",
        "    output_dir = 'outputs' )\n",
        "\n",
        "lora_triner = Trainer(\n",
        "    model=lora_model,\n",
        "    args=lora_training_args,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    )\n",
        "\n",
        "lora_triner.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-21T13:14:20.901479Z",
          "iopub.status.busy": "2024-03-21T13:14:20.901050Z",
          "iopub.status.idle": "2024-03-21T13:14:21.031112Z",
          "shell.execute_reply": "2024-03-21T13:14:21.030376Z",
          "shell.execute_reply.started": "2024-03-21T13:14:20.901457Z"
        },
        "id": "yxHx0hb9XXRp"
      },
      "outputs": [],
      "source": [
        "lora_triner.save_model(lora_model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glZdMWWwx0RX"
      },
      "source": [
        "### Visualize the fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "execution": {
          "iopub.execute_input": "2024-03-21T13:14:21.032370Z",
          "iopub.status.busy": "2024-03-21T13:14:21.032052Z",
          "iopub.status.idle": "2024-03-21T13:14:21.299335Z",
          "shell.execute_reply": "2024-03-21T13:14:21.298407Z",
          "shell.execute_reply.started": "2024-03-21T13:14:21.032349Z"
        },
        "id": "DJ0ZxOVLx9Sf",
        "outputId": "5072e912-4b26-4f84-bb5c-3723cb6e4f79"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+QAAAIjCAYAAACKx9GpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABnY0lEQVR4nO3deXhU5f3+8Xuyr5ONrCQhIQHCroTFQEUUFFApKiqiVlCrVXGr2i/aVuvSFhe0rtWqrailrhVEKyqigCIgIPsSAglJCFlYsu/L+f2BOT8iWwhJzszk/bquc3HmbPOZ4WSSe57nPMdmGIYhAAAAAADQqdysLgAAAAAAgK6IQA4AAAAAgAUI5AAAAAAAWIBADgAAAACABQjkAAAAAABYgEAOAAAAAIAFCOQAAAAAAFiAQA4AAAAAgAUI5AAAAAAAWIBADgDAKZoxY4YSEhLatO/DDz8sm83WvgUBAACnRCAHALgMm83Wqmnp0qVWl2qJGTNmKCAgwOoyWm3+/PmaOHGiunXrJi8vL8XExOjKK6/U119/bXVpAAC0C5thGIbVRQAA0B7+/e9/t3j81ltvafHixXr77bdbLD///PMVGRnZ5uepr69XU1OTvL29T3nfhoYGNTQ0yMfHp83P31YzZszQhx9+qIqKik5/7lNhGIZuuOEGzZ07V2eeeaYuv/xyRUVFKT8/X/Pnz9e6deu0YsUKjRw50upSAQA4LR5WFwAAQHu59tprWzxetWqVFi9efNTyn6uqqpKfn1+rn8fT07NN9UmSh4eHPDz49XsiTz/9tObOnau7775bzzzzTIsu/n/4wx/09ttvt8t7aBiGampq5Ovre9rHAgCgLeiyDgDoUsaMGaMBAwZo3bp1Gj16tPz8/PT73/9ekvTxxx/roosuUkxMjLy9vZWUlKTHHntMjY2NLY7x82vI9+zZI5vNpjlz5ujVV19VUlKSvL29NWzYMK1Zs6bFvse6htxms+n222/XggULNGDAAHl7e6t///76/PPPj6p/6dKlGjp0qHx8fJSUlKR//OMf7X5d+gcffKDU1FT5+vqqW7duuvbaa5WXl9dim4KCAl1//fWKjY2Vt7e3oqOjNXnyZO3Zs8fcZu3atRo/fry6desmX19fJSYm6oYbbjjhc1dXV2v27NlKSUnRnDlzjvm6fvWrX2n48OGSjn9N/ty5c2Wz2VrUk5CQoIsvvlhffPGFhg4dKl9fX/3jH//QgAEDdO655x51jKamJnXv3l2XX355i2XPPvus+vfvLx8fH0VGRuo3v/mNiouLW+zbltcOAOh6+IoeANDlHDx4UBMnTtRVV12la6+91uy+PnfuXAUEBOiee+5RQECAvv76az300EMqKyvTU089ddLj/uc//1F5ebl+85vfyGaz6cknn9Rll12mzMzMk7aqf/fdd/roo4902223KTAwUM8//7ymTJminJwchYWFSZLWr1+vCRMmKDo6Wo888ogaGxv16KOPKjw8/PTflJ/MnTtX119/vYYNG6bZs2ersLBQzz33nFasWKH169crODhYkjRlyhRt3bpVd9xxhxISElRUVKTFixcrJyfHfHzBBRcoPDxc999/v4KDg7Vnzx599NFHJ30fDh06pLvvvlvu7u7t9rqapaena9q0afrNb36jm266SX369NHUqVP18MMPq6CgQFFRUS1q2bdvn6666ipz2W9+8xvzPbrzzjuVlZWlF198UevXr9eKFSvk6enZ5tcOAOiCDAAAXNTMmTONn/+qO+eccwxJxiuvvHLU9lVVVUct+81vfmP4+fkZNTU15rLp06cbPXr0MB9nZWUZkoywsDDj0KFD5vKPP/7YkGR88skn5rI//elPR9UkyfDy8jJ27dplLtu4caMhyXjhhRfMZZMmTTL8/PyMvLw8c1lGRobh4eFx1DGPZfr06Ya/v/9x19fV1RkRERHGgAEDjOrqanP5p59+akgyHnroIcMwDKO4uNiQZDz11FPHPdb8+fMNScaaNWtOWteRnnvuOUOSMX/+/FZtf6z30zAM44033jAkGVlZWeayHj16GJKMzz//vMW26enpR73XhmEYt912mxEQEGCeF99++60hyZg3b16L7T7//PMWy9v62gEAXQ9d1gEAXY63t7euv/76o5YfeS1xeXm5Dhw4oLPPPltVVVXasWPHSY87depUhYSEmI/PPvtsSVJmZuZJ9x03bpySkpLMx4MGDZLdbjf3bWxs1FdffaVLLrlEMTEx5nbJycmaOHHiSY/fGmvXrlVRUZFuu+22FoPOXXTRRUpJSdH//vc/SYffJy8vLy1duvSortrNmlvSP/30U9XX17e6hrKyMklSYGBgG1/FiSUmJmr8+PEtlvXu3VtnnHGG3nvvPXNZY2OjPvzwQ02aNMk8Lz744AMFBQXp/PPP14EDB8wpNTVVAQEB+uabbyS1/bUDALoeAjkAoMvp3r27vLy8jlq+detWXXrppQoKCpLdbld4eLg5IFxpaelJjxsfH9/icXM4P15oPdG+zfs371tUVKTq6molJycftd2xlrVFdna2JKlPnz5HrUtJSTHXe3t764knntCiRYsUGRmp0aNH68knn1RBQYG5/TnnnKMpU6bokUceUbdu3TR58mS98cYbqq2tPWENdrtd0uEvRDpCYmLiMZdPnTpVK1asMK+VX7p0qYqKijR16lRzm4yMDJWWlioiIkLh4eEtpoqKChUVFUlq+2sHAHQ9BHIAQJdzrFG1S0pKdM4552jjxo169NFH9cknn2jx4sV64oknJB0ezOtkjnfNs9GKO4yezr5WuPvuu7Vz507Nnj1bPj4+evDBB9W3b1+tX79e0uGB6j788EOtXLlSt99+u/Ly8nTDDTcoNTX1hLddS0lJkSRt3ry5VXUcbzC7nw/E1+x4I6pPnTpVhmHogw8+kCS9//77CgoK0oQJE8xtmpqaFBERocWLFx9zevTRR82a2vLaAQBdD4EcAAAdbhE9ePCg5s6dq7vuuksXX3yxxo0b16ILupUiIiLk4+OjXbt2HbXuWMvaokePHpIOD3z2c+np6eb6ZklJSbr33nv15ZdfasuWLaqrq9PTTz/dYpuzzjpLf/nLX7R27VrNmzdPW7du1bvvvnvcGn7xi18oJCRE77zzznFD9ZGa/39KSkpaLG9uzW+txMREDR8+XO+9954aGhr00Ucf6ZJLLmlxr/mkpCQdPHhQo0aN0rhx446aBg8e3OKYp/raAQBdD4EcAAD9/xbqI1uk6+rq9Pe//92qklpwd3fXuHHjtGDBAu3bt89cvmvXLi1atKhdnmPo0KGKiIjQK6+80qJ79aJFi7R9+3ZddNFFkg7ft72mpqbFvklJSQoMDDT3Ky4uPqp1/4wzzpCkE3bd9vPz06xZs7R9+3bNmjXrmD0E/v3vf+uHH34wn1eSli9fbq6vrKzUm2++2dqXbZo6dapWrVqlf/3rXzpw4ECL7uqSdOWVV6qxsVGPPfbYUfs2NDSYXwq09bUDALoebnsGAICkkSNHKiQkRNOnT9edd94pm82mt99+26G6jD/88MP68ssvNWrUKN16661qbGzUiy++qAEDBmjDhg2tOkZ9fb3+/Oc/H7U8NDRUt912m5544gldf/31OuecczRt2jTztmcJCQn67W9/K0nauXOnxo4dqyuvvFL9+vWTh4eH5s+fr8LCQvMWYW+++ab+/ve/69JLL1VSUpLKy8v12muvyW6368ILLzxhjb/73e+0detWPf300/rmm290+eWXKyoqSgUFBVqwYIF++OEHff/995KkCy64QPHx8brxxhv1u9/9Tu7u7vrXv/6l8PBw5eTknMK7ezhw33fffbrvvvsUGhqqcePGtVh/zjnn6De/+Y1mz56tDRs26IILLpCnp6cyMjL0wQcf6LnnntPll19+Wq8dANC1EMgBAJAUFhamTz/9VPfee6/++Mc/KiQkRNdee63Gjh171KjcVklNTdWiRYt033336cEHH1RcXJweffRRbd++vVWjwEuHW/0ffPDBo5YnJSXptttu04wZM+Tn56fHH39cs2bNkr+/vy699FI98cQT5ujhcXFxmjZtmpYsWaK3335bHh4eSklJ0fvvv68pU6ZIOhxef/jhB7377rsqLCxUUFCQhg8frnnz5h13YLVmbm5ueuuttzR58mS9+uqrmjNnjsrKyhQeHm4OIJeWliZJ8vT01Pz583XbbbfpwQcfVFRUlO6++26FhIQccyT9E4mNjdXIkSO1YsUK/frXvz7mveNfeeUVpaam6h//+Id+//vfy8PDQwkJCbr22ms1atSo037tAICuxWY40lf/AADglF1yySXaunWrMjIyrC4FAACcAq4hBwDAiVRXV7d4nJGRoc8++0xjxoyxpiAAANBmtJADAOBEoqOjNWPGDPXs2VPZ2dl6+eWXVVtbq/Xr16tXr15WlwcAAE4B15ADAOBEJkyYoHfeeUcFBQXy9vZWWlqa/vrXvxLGAQBwQrSQAwAAAABgAa4hBwAAAADAAgRyAAAAAAAs4PLXkDc1NWnfvn0KDAyUzWazuhwAAAAAgIszDEPl5eWKiYmRm9vx28FdPpDv27dPcXFxVpcBAAAAAOhicnNzFRsbe9z1Lh/IAwMDJR1+I+x2u8XVAAAAAABcXVlZmeLi4sw8ejwuH8ibu6nb7XYCOQAAAACg05zssmkGdQMAAAAAwAIEcgAAAAAALEAgBwAAAADAAi5/DTkAAAAAnArDMNTQ0KDGxkarS4GDcnd3l4eHx2nfWptADgAAAAA/qaurU35+vqqqqqwuBQ7Oz89P0dHR8vLyavMxCOQAAAAAIKmpqUlZWVlyd3dXTEyMvLy8TrsFFK7HMAzV1dVp//79ysrKUq9eveTm1rarwQnkAAAAAKDDreNNTU2Ki4uTn5+f1eXAgfn6+srT01PZ2dmqq6uTj49Pm47DoG4AAAAAcIS2tnaia2mP84QzDQAAAAAACxDIAQAAAACwAIEcAAAAAHCUhIQEPfvss63efunSpbLZbCopKemwmlwNgRwAAAAAnJjNZjvh9PDDD7fpuGvWrNHNN9/c6u1Hjhyp/Px8BQUFten5WsuVgj+jrAMAAACAE8vPzzfn33vvPT300ENKT083lwUEBJjzhmGosbFRHh4nj4Lh4eGnVIeXl5eioqJOaZ+ujhZyAAAAAHBiUVFR5hQUFCSbzWY+3rFjhwIDA7Vo0SKlpqbK29tb3333nXbv3q3JkycrMjJSAQEBGjZsmL766qsWx/15l3WbzabXX39dl156qfz8/NSrVy8tXLjQXP/zluu5c+cqODhYX3zxhfr27auAgABNmDChxRcIDQ0NuvPOOxUcHKywsDDNmjVL06dP1yWXXNLm96O4uFjXXXedQkJC5Ofnp4kTJyojI8Ncn52drUmTJikkJET+/v7q37+/PvvsM3Pfa665RuHh4fL19VWvXr30xhtvtLmWk6GFHAAAAABOYOjQoSooKOj0542KitLatWvb5Vj333+/5syZo549eyokJES5ubm68MIL9Ze//EXe3t566623NGnSJKWnpys+Pv64x3nkkUf05JNP6qmnntILL7yga665RtnZ2QoNDT3m9lVVVZozZ47efvttubm56dprr9V9992nefPmSZKeeOIJzZs3T2+88Yb69u2r5557TgsWLNC5557b5tc6Y8YMZWRkaOHChbLb7Zo1a5YuvPBCbdu2TZ6enpo5c6bq6uq0fPly+fv7a9u2bWYvggcffFDbtm3TokWL1K1bN+3atUvV1dVtruVkCOQOpLGxUe7u7laXAQAAAOAIBQUFysvLs7qM0/Loo4/q/PPPNx+HhoZq8ODB5uPHHntM8+fP18KFC3X77bcf9zgzZszQtGnTJEl//etf9fzzz+uHH37QhAkTjrl9fX29XnnlFSUlJUmSbr/9dj366KPm+hdeeEEPPPCALr30UknSiy++aLZWt0VzEF+xYoVGjhwpSZo3b57i4uK0YMECXXHFFcrJydGUKVM0cOBASVLPnj3N/XNycnTmmWdq6NChkg73EuhIBHIHkJ2drddff11z587VwoULdeaZZ1pdEgAAAICfWHVddHs+b3PAbFZRUaGHH35Y//vf/5Sfn6+GhgZVV1crJyfnhMcZNGiQOe/v7y+73a6ioqLjbu/n52eGcUmKjo42ty8tLVVhYaGGDx9urnd3d1dqaqqamppO6fU12759uzw8PDRixAhzWVhYmPr06aPt27dLku68807deuut+vLLLzVu3DhNmTLFfF233nqrpkyZoh9//FEXXHCBLrnkEjPYdwQCuQP4/PPP9ec//1mS9M9//lMvvviixRUBAAAAaNZe3cat5O/v3+Lxfffdp8WLF2vOnDlKTk6Wr6+vLr/8ctXV1Z3wOJ6eni0e22y2E4bnY21vGMYpVt++fv3rX2v8+PH63//+py+//FKzZ8/W008/rTvuuEMTJ05Udna2PvvsMy1evFhjx47VzJkzNWfOnA6phUHdHMBVV10lX19fSYe7U9TU1FhcEQAAAABXtmLFCs2YMUOXXnqpBg4cqKioKO3Zs6dTawgKClJkZKTWrFljLmtsbNSPP/7Y5mP27dtXDQ0NWr16tbns4MGDSk9PV79+/cxlcXFxuuWWW/TRRx/p3nvv1WuvvWauCw8P1/Tp0/Xvf/9bzz77rF599dU213MytJA7gKCgIF1++eV6++23VVJSovnz55vXZQAAAABAe+vVq5c++ugjTZo0STabTQ8++GCbu4mfjjvuuEOzZ89WcnKyUlJS9MILL6i4uFg2m+2k+27evFmBgYHmY5vNpsGDB2vy5Mm66aab9I9//EOBgYG6//771b17d02ePFmSdPfdd2vixInq3bu3iouL9c0336hv376SpIceekipqanq37+/amtr9emnn5rrOgIt5A7ihhtuMOf/9a9/WVgJAAAAAFf3zDPPKCQkRCNHjtSkSZM0fvx4DRkypNPrmDVrlqZNm6brrrtOaWlpCggI0Pjx4+Xj43PSfUePHq0zzzzTnFJTUyVJb7zxhlJTU3XxxRcrLS1NhmHos88+M7vPNzY2aubMmerbt68mTJig3r176+9//7ukw/dSf+CBBzRo0CCNHj1a7u7uevfddzvs9dsMqzvwd7CysjIFBQWptLRUdrvd6nKOyzAM9erVS7t375bNZlNmZmaHj+gHAAAA4P+rqalRVlaWEhMTWxUI0f6amprUt29fXXnllXrsscesLueETnS+tDaH0kLuIGw2m66//npJh8P53LlzrS0IAAAAADpYdna2XnvtNe3cuVObN2/WrbfeqqysLF199dVWl9YpCOQOZPr06XJzO/xf8sYbb1hyDQcAAAAAdBY3NzfNnTtXw4YN06hRo7R582Z99dVXHXrdtiNhUDcHEhsbq/Hjx2vRokXKycnR0qVLdd5551ldFgAAAAB0iLi4OK1YscLqMixDC7mDueyyy8z5bdu2WVgJAAAAAKAjEcgdTGRkpDlfUlJiXSEAAABAF+Xi416jnbTHeUIgdzDBwcHmfHFxsXWFAAAAAF1M822xqqqqLK4EzqD5PGk+b9qCa8gdTEhIiDlPCzkAAADQedzd3RUcHKyioiJJkp+fn2w2m8VVwdEYhqGqqioVFRUpODhY7u7ubT4WgdzB0EIOAAAAWCcqKkqSzFAOHE9wcLB5vrQVgdzBHBnIaSEHAAAAOpfNZlN0dLQiIiJUX19vdTlwUJ6enqfVMt6MQO5g/P395eHhoYaGBgI5AAAAYBF3d/d2CVzAiTCom4Ox2WxmKzld1gEAAADAdRHIHVDzwG60kAMAAACA6yKQO6DmFvLS0lI1NTVZWwwAAAAAoEMQyB1QcyA3DENlZWXWFgMAAAAA6BAEcgfEvcgBAAAAwPURyB0Q9yIHAAAAANdHIHdAtJADAAAAgOsjkDsgWsgBAAAAwPURyB3QkYGcFnIAAAAAcE0EcgdEl3UAAAAAcH0EcgdEl3UAAAAAcH0OE8gff/xx2Ww23X333eaympoazZw5U2FhYQoICNCUKVNUWFhoXZGdhBZyAAAAAHB9DhHI16xZo3/84x8aNGhQi+W//e1v9cknn+iDDz7QsmXLtG/fPl122WUWVdl5aCEHAAAAANdneSCvqKjQNddco9dee61Fy3Bpaan++c9/6plnntF5552n1NRUvfHGG/r++++1atUqCyvueLSQAwAAAIDrszyQz5w5UxdddJHGjRvXYvm6detUX1/fYnlKSori4+O1cuXK4x6vtrZWZWVlLSZnExQUZM4TyAEAAADANXlY+eTvvvuufvzxR61Zs+aodQUFBfLy8mrRfVuSIiMjVVBQcNxjzp49W4888kh7l9qpvLy85Ofnp6qqKrqsAwAAAICLsqyFPDc3V3fddZfmzZsnHx+fdjvuAw88oNLSUnPKzc1tt2N3puZu67SQAwAAAIBrsiyQr1u3TkVFRRoyZIg8PDzk4eGhZcuW6fnnn5eHh4ciIyNVV1d3VCAtLCxUVFTUcY/r7e0tu93eYnJGzT0DaCEHAAAAANdkWZf1sWPHavPmzS2WXX/99UpJSdGsWbMUFxcnT09PLVmyRFOmTJEkpaenKycnR2lpaVaU3KmaW8irq6tVW1srb29viysCAAAAALQnywJ5YGCgBgwY0GKZv7+/wsLCzOU33nij7rnnHoWGhsput+uOO+5QWlqazjrrLCtK7lRHXjtfWlqqiIgI64oBAAAAALQ7Swd1O5m//e1vcnNz05QpU1RbW6vx48fr73//u9VldYqf34ucQA4AAAAArsWhAvnSpUtbPPbx8dFLL72kl156yZqCLMS9yAEAAADAtVl+H3Ic289byAEAAAAAroVA7qBoIQcAAAAA10Ygd1BHtpATyAEAAADA9RDIHdSRLeR0WQcAAAAA10Mgd1C0kAMAAACAayOQOygGdQMAAAAA10Ygd1AM6gYAAAAAro1A7qDosg4AAAAAro1A7qACAwPl5nb4v4cu6wAAAADgegjkDsrNzU1BQUGSaCEHAAAAAFdEIHdgzd3WaSEHAAAAANdDIHdgzQO7lZSUyDAMi6sBAAAAALQnArkDa24hb2xsVGVlpbXFAAAAAADaFYHcgR156zO6rQMAAACAayGQOzBufQYAAAAArotA7sC6detmzu/bt8/CSgAAAAAA7Y1A7sCSk5PN+V27dllYCQAAAACgvRHIHVivXr3M+YyMDAsrAQAAAAC0NwK5AyOQAwAAAIDrIpA7sOjoaPn5+UkikAMAAACAqyGQOzCbzWZeR56VlaWGhgaLKwIAAAAAtBcCuYNr7rbe0NCgPXv2WFsMAAAAAKDdEMgd3JHXkTPSOgAAAAC4DgK5g2NgNwAAAABwTQRyB0cgBwAAAADXRCB3cARyAAAAAHBNBHIHFxkZqYCAAEkEcgAAAABwJQRyB2ez2cxW8j179qi+vt7iigAAAAAA7YFA7gSa70Xe2NiorKwsi6sBAAAAALQHArkT4DpyAAAAAHA9BHInwL3IAQAAAMD1EMidAC3kAAAAAOB6COROgEAOAAAAAK6HQO4EwsPDZbfbJRHIAQAAAMBVEMidwJG3PsvOzlZdXZ3FFQEAAAAATheB3EkkJiZKkpqampSXl2dxNQAAAACA00UgdxLx8fHmfE5OjoWVAAAAAADaA4HcScTFxZnzubm5FlYCAAAAAGgPBHInQQs5AAAAALgWArmTOLKFnEAOAAAAAM6PQO4kjmwhp8s6AAAAADg/ArmTCA8Pl5eXlyRayAEAAADAFRDInYSbm5vZbZ0WcgAAAABwfgRyJ9IcyEtLS1VWVmZxNQAAAACA00EgdyJcRw4AAAAAroNA7kQYaR0AAAAAXAeB3InQQg4AAAAAroNA7kRoIQcAAAAA10EgdyK0kAMAAACA6yCQOxFayAEAAADAdRDInYjdbldQUJAkWsgBAAAAwNkRyJ1Mc7f13NxcNTU1WVwNAAAAAKCtCOROprnbel1dnfbv329xNQAAAACAtiKQO5kjB3bjOnIAAAAAcF4Ecidz5MBuXEcOAAAAAM6LQO5kaCEHAAAAANdAIHcytJADAAAAgGsgkDsZWsgBAAAAwDUQyJ1M9+7dZbPZJBHIAQAAAMCZEcidjJeXl6KjoyVJWVlZFlcDAAAAAGgrArkT6tWrlyRp//79Ki4utrgaAAAAAEBbEMidUEpKijmfnp5uYSUAAAAAgLYikDuhPn36mPMEcgAAAABwTgRyJ3RkC/mOHTssrAQAAAAA0FYEcidECzkAAAAAOD8CuRPq0aOHvL29JRHIAQAAAMBZEcidkLu7uznSekZGhhoaGiyuCAAAAABwqgjkTqq523p9fb327NljbTEAAAAAgFNGIHdSXEcOAAAAAM6NQO6kGGkdAAAAAJwbgdxJ0UIOAAAAAM6NQO6kCOQAAAAA4NwI5E4qKChIUVFRkuiyDgAAAADOiEDuxJpbyYuKilRcXGxxNQAAAACAU0Egd2JHDuxGt3UAAAAAcC4EcifGdeQAAAAA4LwI5E6MQA4AAAAAzotA7sTosg4AAAAAzotA7sTi4uLk5nb4vzA3N9fiagAAAAAAp4JA7sQ8PT3NW5/t3bvX4moAAAAAAKeCQO7kYmNjJUkFBQWqq6uzuBoAAAAAQGsRyJ1ccyA3DEP5+fkWVwMAAAAAaC0CuZNrDuQS3dYBAAAAwJkQyJ0cgRwAAAAAnBOB3MnFxcWZ8wRyAAAAAHAeBHInRws5AAAAADgnArmTI5ADAAAAgHOyNJC//PLLGjRokOx2u+x2u9LS0rRo0SJzfU1NjWbOnKmwsDAFBARoypQpKiwstLBixxMTE2POE8gBAAAAwHlYGshjY2P1+OOPa926dVq7dq3OO+88TZ48WVu3bpUk/fa3v9Unn3yiDz74QMuWLdO+fft02WWXWVmyw/Hy8lJkZKQkAjkAAAAAOBObYRiG1UUcKTQ0VE899ZQuv/xyhYeH6z//+Y8uv/xySdKOHTvUt29frVy5UmeddVarjldWVqagoCCVlpbKbrd3ZOmWGTp0qNatWyc3NzfV1tbKw8PD6pIAAAAAoMtqbQ51mGvIGxsb9e6776qyslJpaWlat26d6uvrNW7cOHOblJQUxcfHa+XKlcc9Tm1trcrKylpMrq75OvKmpiYVFBRYXA0AAAAAoDUsD+SbN29WQECAvL29dcstt2j+/Pnq16+fCgoK5OXlpeDg4BbbR0ZGnjB0zp49W0FBQeZ05G3BXBUDuwEAAACA87E8kPfp00cbNmzQ6tWrdeutt2r69Onatm1bm4/3wAMPqLS01Jxyc3PbsVrHRCAHAAAAAOdj+cXGXl5eSk5OliSlpqZqzZo1eu655zR16lTV1dWppKSkRSt5YWGhoqKijns8b29veXt7d3TZDoVADgAAAADOx/IW8p9rampSbW2tUlNT5enpqSVLlpjr0tPTlZOTo7S0NAsrdDwEcgAAAABwPpa2kD/wwAOaOHGi4uPjVV5erv/85z9aunSpvvjiCwUFBenGG2/UPffco9DQUNntdt1xxx1KS0tr9QjrXQWBHAAAAACcj6WBvKioSNddd53y8/MVFBSkQYMG6YsvvtD5558vSfrb3/4mNzc3TZkyRbW1tRo/frz+/ve/W1myQyKQAwAAAIDzcbj7kLe3rnAfckkKDw/XgQMH1KNHD+3Zs8fqcgAAAACgy3K6+5Dj9DS3kufl5amxsdHiagAAAAAAJ0MgdxHNgbyhoUFFRUUWVwMAAAAAOBkCuYvgOnIAAAAAcC4EchdBIAcAAAAA50IgdxEEcgAAAABwLgRyF3FkIM/OzrawEgAAAABAaxDIXURSUpI5v2vXLgsrAQAAAAC0BoHcRcTFxcnLy0uSlJGRYXE1AAAAAICTIZC7CHd3d7OVfPfu3WpqarK4IgAAAADAiRDIXUivXr0kSbW1tQzsBgAAAAAOjkDuQpoDuUS3dQAAAABwdARyF5KcnGzOE8gBAAAAwLERyF0ILeQAAAAA4DwI5C6EQA4AAAAAzoNA7kJiY2Pl4+MjiUAOAAAAAI6OQO5C3NzczFufZWZmqrGx0eKKAAAAAADHQyB3Mc3d1uvq6pSTk2NxNQAAAACA4yGQuxiuIwcAAAAA50AgdzFHBvJdu3ZZWAkAAAAA4EQI5C6GFnIAAAAAcA4EchdDIAcAAAAA50AgdzExMTHy9fWVRCAHAAAAAEdGIHcxNptNycnJkg7f+qyhocHiigAAAAAAx0Igd0HN3dYbGhqUnZ1tcTUAAAAAgGMhkLsgriMHAAAAAMdHIHdBBHIAAAAAcHwEchdEIAcAAAAAx0cgd0FHBvJdu3ZZWAkAAAAA4HgI5C4oKipKAQEBkmghBwAAAABHRSB3QUfe+iwrK0v19fUWVwQAAAAA+DkCuYtq7rbe2NioPXv2WFsMAAAAAOAoBHIXxcBuAAAAAODYCOQuikAOAAAAAI6NQO6imq8hlwjkAAAAAOCICOQuihZyAAAAAHBsBHIXFRERocDAQEkEcgAAAABwRARyF2Wz2cxW8uzsbNXV1VlcEQAAAADgSARyF9YcyJuampSVlWVxNQAAAACAIxHIXRjXkQMAAACA4yKQuzACOQAAAAA4LgK5CyOQAwAAAIDjIpC7MAI5AAAAADguArkLCwsLU3BwsCQCOQAAAAA4GgK5Czvy1mc5OTmqqamxuCIAAAAAQDMCuYtLTk6WJBmGod27d1tcDQAAAACgGYHcxfXr18+c37Jli4WVAAAAAACORCB3cQMHDjTnN2/ebGElAAAAAIAjEchd3KBBg8x5AjkAAAAAOA4CuYvr0aOHAgICJEmbNm2yuBoAAAAAQDMCuYtzc3Mzu63v2bNHZWVlFlcEAAAAAJAI5F3CkdeRM7AbAAAAADgGAnkXwHXkAAAAAOB4CORdACOtAwAAAIDjIZB3AUcGcgZ2AwAAAADHQCDvAkJCQhQbGyvpcAu5YRgWVwQAAAAAIJB3Ec2t5CUlJdq7d6/F1QAAAAAACORdBAO7AQAAAIBjIZB3EVxHDgAAAACOhUDeRTDSOgAAAAA4FgJ5F5GSkiIPDw9JBHIAAAAAcAQE8i7Cy8tLKSkpkqTt27eroaHB4ooAAAAAoGsjkHchSUlJkqSGhgYVFBRYXA0AAAAAdG0E8i4kLi7OnOfWZwAAAABgLQJ5FxIbG2vOE8gBAAAAwFptCuS5ubktAt0PP/ygu+++W6+++mq7FYb2RyAHAAAAAMfRpkB+9dVX65tvvpEkFRQU6Pzzz9cPP/ygP/zhD3r00UfbtUC0HwI5AAAAADiONgXyLVu2aPjw4ZKk999/XwMGDND333+vefPmae7cue1ZH9oRgRwAAAAAHEebAnl9fb28vb0lSV999ZV++ctfSjp8r+v8/Pz2qw7tqnv37uY8gRwAAAAArNWmQN6/f3+98sor+vbbb7V48WJNmDBBkrRv3z6FhYW1a4FoPz4+PurWrZukw+MAAAAAAACs06ZA/sQTT+gf//iHxowZo2nTpmnw4MGSpIULF5pd2eGYmrut79u3T42NjRZXAwAAAABdl0dbdhozZowOHDigsrIyhYSEmMtvvvlm+fn5tVtxaH9xcXHasGGDGhoaVFRUpOjoaKtLAgAAAIAuqU0t5NXV1aqtrTXDeHZ2tp599lmlp6crIiKiXQtE+2JgNwAAAABwDG0K5JMnT9Zbb70lSSopKdGIESP09NNP65JLLtHLL7/crgWifRHIAQAAAMAxtCmQ//jjjzr77LMlSR9++KEiIyOVnZ2tt956S88//3y7Foj2RSAHAAAAAMfQpkBeVVWlwMBASdKXX36pyy67TG5ubjrrrLOUnZ3drgWifRHIAQAAAMAxtCmQJycna8GCBcrNzdUXX3yhCy64QJJUVFQku93ergWifRHIAQAAAMAxtCmQP/TQQ7rvvvuUkJCg4cOHKy0tTdLh1vIzzzyzXQtE++revbs5z73IAQAAAMA6NsMwjLbsWFBQoPz8fA0ePFhubodz/Q8//CC73a6UlJR2LfJ0lJWVKSgoSKWlpbTe/yQ0NFTFxcVKTExUZmam1eUAAAAAgEtpbQ5t033IJSkqKkpRUVFmt+fY2FgNHz68rYdDJ4qNjVVxcbHy8vLU1NRkfqECAAAAAOg8bUpiTU1NevTRRxUUFKQePXqoR48eCg4O1mOPPaampqb2rhHtLC4uTpJUV1enAwcOWFwNAAAAAHRNbWoh/8Mf/qB//vOfevzxxzVq1ChJ0nfffaeHH35YNTU1+stf/tKuRaJ9/Xxgt4iICAurAQAAAICuqU2B/M0339Trr7+uX/7yl+ayQYMGqXv37rrtttsI5A7u54F8yJAhFlYDAAAAAF1Tm7qsHzp06JgDt6WkpOjQoUOnXRQ6Frc+AwAAAADrtSmQDx48WC+++OJRy1988UUNGjTotItCxyKQAwAAAID12tRl/cknn9RFF12kr776yrwH+cqVK5Wbm6vPPvusXQtE+yOQAwAAAID12tRCfs4552jnzp269NJLVVJSopKSEl122WXaunWr3n777fauEe3syECem5trYSUAAAAA0HXZDMMw2utgGzdu1JAhQ9TY2Nhehzxtrb0he1cTFBSksrIy9ezZU7t377a6HAAAAABwGa3NoW1qIW8vs2fP1rBhwxQYGKiIiAhdcsklSk9Pb7FNTU2NZs6cqbCwMAUEBGjKlCkqLCy0qGLXkZCQIOlwC7kjfYECAAAAAF2FpYF82bJlmjlzplatWqXFixervr5eF1xwgSorK81tfvvb3+qTTz7RBx98oGXLlmnfvn267LLLLKzaNSQmJkqS6uvrlZeXZ3E1AAAAAND1tGlQt/by+eeft3g8d+5cRUREaN26dRo9erRKS0v1z3/+U//5z3903nnnSZLeeOMN9e3bV6tWrdJZZ51lRdkuoTmQS9KePXsUHx9vYTUAAAAA0PWcUiA/Wct0SUnJ6dSi0tJSSVJoaKgkad26daqvr9e4cePMbVJSUhQfH6+VK1ceM5DX1taqtrbWfFxWVnZaNbmqIwN5VlaWRo8ebWE1AAAAAND1nFIgDwoKOun66667rk2FNDU16e6779aoUaM0YMAASVJBQYG8vLwUHBzcYtvIyEgVFBQc8zizZ8/WI4880qYaupLma8ilw4EcAAAAANC5TimQv/HGGx1Vh2bOnKktW7bou+++O63jPPDAA7rnnnvMx2VlZYqLizvd8lzOz1vIAQAAAACdy9JryJvdfvvt+vTTT7V8+fIW98iOiopSXV2dSkpKWrSSFxYWKioq6pjH8vb2lre3d0eX7PQI5AAAAABgLUtHWTcMQ7fffrvmz5+vr7/+ukVIlKTU1FR5enpqyZIl5rL09HTl5OQoLS2ts8t1KQEBAerWrZukw4O6AQAAAAA6l6Ut5DNnztR//vMfffzxxwoMDDSvCw8KCpKvr6+CgoJ044036p577lFoaKjsdrvuuOMOpaWlMcJ6O0hMTNSBAwe0d+9e1dXVycvLy+qSAAAAAKDLsLSF/OWXX1ZpaanGjBmj6Ohoc3rvvffMbf72t7/p4osv1pQpUzR69GhFRUXpo48+srBq19E8sJthGMrJybG2GAAAAADoYixtITcM46Tb+Pj46KWXXtJLL73UCRV1LT+/jjw5OdnCagAAAACga7G0hRzWOjKQcx05AAAAAHQuAnkXxkjrAAAAAGAdAnkX1nwNuUQgBwAAAIDORiDvwnr06GHOE8gBAAAAoHMRyLswHx8fxcTESCKQAwAAAEBnI5B3cc3XkRcVFamqqsriagAAAACg6yCQd3FHXkfOSOsAAAAA0HkI5F0cI60DAAAAgDUI5F0cgRwAAAAArEEg7+KODOR0WQcAAACAzkMg7+KODOSZmZkWVgIAAAAAXQuBvIuLjY2Vh4eHJAI5AAAAAHQmAnkX5+HhYY60vnv3bhmGYW1BAAAAANBFEMihnj17SpIqKiq0f/9+i6sBAAAAgK6BQA4lJSWZ83RbBwAAAIDOQSBHi0C+e/duCysBAAAAgK6DQA6zy7pEIAcAAACAzkIgB13WAQAAAMACBHLQQg4AAAAAFiCQQwEBAYqMjJREIAcAAACAzkIgh6T/30qen5+vqqoqi6sBAAAAANdHIIeklteRZ2VlWVgJAAAAAHQNBHJI4tZnAAAAANDZCOSQxMBuAAAAANDZCOSQxK3PAAAAAKCzEcghiS7rAAAAANDZCOSQJEVGRsrPz08SgRwAAAAAOgOBHJIkm81mXke+Z88eNTY2WlwRAAAAALg2AjlMzd3W6+rqlJeXZ3E1AAAAAODaCOQwcR05AAAAAHQeAjlM3PoMAAAAADoPgRymI1vId+3aZWElAAAAAOD6COQw9e7d25zPyMiwsBIAAAAAcH0Ecph69OghT09PSdLOnTstrgYAAAAAXBuBHCZ3d3clJydLOtxC3tTUZHFFAAAAAOC6CORooU+fPpKk2tpa5eTkWFwNAAAAALguAjlaOPI6crqtAwAAAEDHIZCjBQI5AAAAAHQOAjlaIJADAAAAQOcgkKMFAjkAAAAAdA4COVqIiIiQ3W6XRCAHAAAAgI5EIEcLNpvNbCXfs2ePamtrLa4IAAAAAFwTgRxHaQ7khmFo9+7dFlcDAAAAAK6JQI6jNN+LXJLS09MtrAQAAAAAXBeBHEdhYDcAAAAA6HgEchyFQA4AAAAAHY9AjqP06tXLnCeQAwAAAEDHIJDjKIGBgYqOjpZEIAcAAACAjkIgxzE1d1svKipSSUmJtcUAAAAAgAsikOOYjryOPCMjw8JKAAAAAMA1EchxTMnJyeZ8VlaWhZUAAAAAgGsikOOYIiMjzfkDBw5YWAkAAAAAuCYCOY6pW7du5jyBHAAAAADaH4Ecx0QgBwAAAICORSDHMRHIAQAAAKBjEchxTARyAAAAAOhYBHIck91ul4eHhyQCOQAAAAB0BAI5jslms5mt5ARyAAAAAGh/BHIcF4EcAAAAADoOgRzH1RzIq6urVVVVZXE1AAAAAOBaCOQ4LgZ2AwAAAICOQyDHcRHIAQAAAKDjEMhxXARyAAAAAOg4BHIcF4EcAAAAADoOgRzHRSAHAAAAgI5DIMdxEcgBAAAAoOMQyHFcBHIAAAAA6DgEchwXgRwAAAAAOg6BHMdFIAcAAACAjkMgx3H5+fnJx8dHEoEcAAAAANobgRzHZbPZzFZyAjkAAAAAtC8COU7oyEBuGIbF1QAAAACA6yCQ44SaA3l9fb3Ky8strgYAAAAAXAeBHCfEwG4AAAAA0DEI5DghAjkAAAAAdAwCOU6IQA4AAAAAHYNAjhMikAMAAABAxyCQ44QI5AAAAADQMQjkOCECOQAAAAB0DAI5TohADgAAAAAdg0COEyKQAwAAAEDHIJDjhMLCwsx5AjkAAAAAtB8COU7Ix8dHAQEBkgjkAAAAANCeCOQ4qeZu6wRyAAAAAGg/BHKcVHMgP3jwoJqamiyuBgAAAABcA4EcJ9UcyJuamlRSUmJtMQAAAADgIgjkOKkjR1rfv3+/hZUAAAAAgOsgkOOkIiIizPmioiILKwEAAAAA12FpIF++fLkmTZqkmJgY2Ww2LViwoMV6wzD00EMPKTo6Wr6+vho3bpwyMjKsKbYLi4yMNOcJ5AAAAADQPiwN5JWVlRo8eLBeeumlY65/8skn9fzzz+uVV17R6tWr5e/vr/Hjx6umpqaTK+3ajmwhLywstLASAAAAAHAdHlY++cSJEzVx4sRjrjMMQ88++6z++Mc/avLkyZKkt956S5GRkVqwYIGuuuqqY+5XW1ur2tpa83FZWVn7F97F0EIOAAAAAO3PYa8hz8rKUkFBgcaNG2cuCwoK0ogRI7Ry5crj7jd79mwFBQWZU1xcXGeU69JoIQcAAACA9uewgbygoEBSy9bZ5sfN647lgQceUGlpqTnl5uZ2aJ1dAS3kAAAAAND+LO2y3hG8vb3l7e1tdRkuJTw83JynhRwAAAAA2ofDtpBHRUVJOjoAFhYWmuvQOby9vRUcHCyJFnIAAAAAaC8OG8gTExMVFRWlJUuWmMvKysq0evVqpaWlWVhZ19R8HTkt5AAAAADQPiztsl5RUaFdu3aZj7OysrRhwwaFhoYqPj5ed999t/785z+rV69eSkxM1IMPPqiYmBhdcskl1hXdRUVGRmrnzp0qKytTTU2NfHx8rC4JAAAAAJyapYF87dq1Ovfcc83H99xzjyRp+vTpmjt3rv7v//5PlZWVuvnmm1VSUqJf/OIX+vzzzwmDFjhypPWioiLFx8dbWA0AAAAAOD9LA/mYMWNkGMZx19tsNj366KN69NFHO7EqHMvPR1onkAMAAADA6XHYa8jhWLgXOQAAAAC0LwI5WuXnXdYBAAAAAKeHQI5WObLLOi3kAAAAAHD6CORoFVrIAQAAAKB9EcjRKrSQAwAAAED7IpCjVWghBwAAAID2RSBHq9jtdnl7e0uihRwAAAAA2gOBHK1is9nMVnJayAEAAADg9BHI0WrN15Hv379fjY2NFlcDAAAAAM6NQI5Wa24hb2pq0qFDhyyuBgAAAACcG4EcrcZI6wAAAADQfgjkaDVGWgcAAACA9kMgR6vRQg4AAAAA7YdAjlajhRwAAAAA2g+BHK1GCzkAAAAAtB8COVqNFnIAAAAAaD8EcrQaLeQAAAAA0H4I5Gi1sLAw2Ww2SbSQAwAAAMDpIpCj1Tw8PNStWzdJBHIAAAAAOF0EcpyS5uvI8/PzVVNTY3E1AAAAAOC8COQ4JcOHD5ck1dbWatGiRRZXAwAAAADOi0COU3LllVea8++9956FlQAAAACAcyOQ45SMHTtWYWFhkqRPPvlElZWVFlcEAAAAAM6JQI5T4unpqSlTpkiSqqqq9Omnn1pcEQAAAAA4JwI5TtlVV11lzr/77rsWVgIAAAAAzotAjlM2evRoRUVFSZIWLVqk0tJSiysCAAAAAOdDIMcpc3d31xVXXCHp8GjrH3/8scUVAQAAAIDzIZCjTaZOnWrOz5s3z8JKAAAAAMA5EcjRJmlpaUpISJAkffnll0pPT7e2IAAAAABwMgRytImbm5tuv/128/Fzzz1nYTUAAAAA4HwI5GizG2+8Uf7+/pKkN998U4cOHbK4IgAAAABwHgRytFlwcLBuuOEGSYfvSf7aa69ZXBEAAAAAOA8COU7LnXfeKZvNJkl64YUXVF9fb3FFAAAAAOAcCOQ4LcnJyZo0aZIkKS8vT++//77FFQEAAACAcyCQ47Tdfffd5vy9996r/fv3W1cMAAAAADgJAjlO25gxYzRx4kRJUmFhoX7961/LMAyLqwIAAAAAx0Ygx2mz2Wz617/+pfDwcEnSwoUL9eqrr1pcFQAAAAA4NgI52kVUVJT+9a9/mY9/+9vf6sknn+RWaAAAAABwHARytJuLL75Yt956qySpurpas2bNUmxsrO666y5VVlZaXB0AAAAAOBYCOdrVnDlzdNVVV5mPq6ur9fzzz2vEiBHavn27hZUBAAAAgGMhkKNd+fn56Z133tHOnTt1xx13yM/PT5K0detWDRs2TM8++6wKCwstrhIAAAAArGczXHw47LKyMgUFBam0tFR2u93qcrqcHTt26IorrtCWLVvMZTabTWeffbZuu+02XXHFFXJz43shAAAAAK6jtTmUJIQOlZKSotWrV2vGjBnmMsMwtHz5cl111VUaPny4vv76a+sKBAAAAACL0EKOTrNhwwZ98MEH+u9//6v09PQW61JSUnT55Zfr4osvVlJSksLCwmSz2SyqFAAAAADarrU5lECOTmcYhr788kvNmjVLGzduPOY23t7eSklJ0eTJk3X55ZdrwIABBHQAAAAAToFA/hMCueNqamrSf/7zH7366qv67rvvdKJTMS4uTmeddZbOOussjRgxQkOGDJGvr28nVgsAAAAArUMg/wmB3DkUFBRowYIFWrt2rfLy8pSTk6Nt27Ydd3sPDw8NHjxYSUlJio2NNafu3bsrKSlJkZGRnVg9AAAAAPx/BPKfEMidV15enubPn68FCxZo5cqVqqqqavW+w4cP15QpUzRlyhQlJSV1YJUAAAAA0BKB/CcEctfQ0NCgrVu3avXq1Vq1apVWr159whb0Iw0ePFhTpkzRRRddpIEDB8rT07ODqwUAAADQlRHIf0Igd13V1dXat2+f9u7dq7y8PO3du1e5ubn69ttvjztYnK+vr1JTU3XhhRfquuuuU/fu3Tu5agAAAACujkD+EwJ517Rr1y7997//1X//+1+tWbPmmNu4ubnpggsu0NVXX61JkyYpODi4c4sEAAAA4JII5D8hkCMnJ0cLFy7U999/r1WrVikrK+uobTw9PXX++efrpptu0qRJk+Tu7m5BpQAAAABcAYH8JwRy/FxmZqbefPNNzZ07Vzk5OUetT0xM1J133qlbbrlFPj4+FlQIAAAAwJkRyH9CIMfxNDU1acWKFWbX9r1797ZY37NnTz333HO6+OKLLaoQAAAAgDNqbQ5168SaAIfi5uams88+W88++6yys7P1v//9T+PHjzfXZ2ZmatKkSZo8ebJKSkqsKxQAAACASyKQAzoczi+88EJ9/vnn2rhxo8455xxz3cKFC3XOOeeooKDAwgoBAAAAuBoCOfAzgwYN0jfffKN33nlH3bp1kyRt2rRJo0aNUmZmpsXVAQAAAHAVBHLgGGw2m6666iqtWLFC8fHxkg53YR85cqTWrVtncXUAAAAAXAGBHDiB3r17a8WKFerbt68kqbCwUKNHj9ann35qcWUAAAAAnB2BHDiJ2NhYffvttxo1apQkqaqqSpMnT9bvfvc7rV+/Xi5+owIAAAAAHYRADrRCWFiYvvrqK1111VWSDt8ybc6cORoyZIiSk5P173//2+IKAQAAADgbAjnQSj4+Ppo3b57+8Ic/yM3t///oZGZm6le/+pV+/etfq7q62sIKAQAAADgTAjlwCtzc3PTnP/9ZeXl5evnll3Xuueea6/75z3/qrLPO0s6dOy2sEAAAAICzIJADbRAVFaVbbrlFX3/9td566y35+flJOnx7tKFDh+r999+3uEIAAAAAjo5ADpymX/3qV1qzZo05Ent5ebmmTp2q2267Tfv27bO4OgAAAACOikAOtIN+/frphx9+0DXXXGMue/nllxUXF6eLLrpIn3zyCaOxAwAAAGiBQA60k4CAAL399tt69dVX5e3tLenwaOyfffaZfvnLX2ry5MnKy8uzuEoAAAAAjoJADrQjm82mm266STt27NCDDz6o+Ph4c90nn3yifv366cUXX1Rtba2FVQIAAABwBARyoAMkJCTo0UcfVVZWlt5//31FRkZKksrKynTHHXcoKSlJzz//PLdJAwAAALowAjnQgdzc3HTFFVdo27ZtmjFjhrk8Ly9Pd911lxITEzVnzhxVVFRYVyQAAAAAS9gMFx9pqqysTEFBQSotLZXdbre6HHRxa9as0Z///GctXLiwxfKQkBAlJyfLbrerR48e+r//+z/16dPHoioBAAAAnI7W5lACOWCBDRs26C9/+Yv++9//HnP0dX9/f7344ouaPn26bDabBRUCAAAAaCsC+U8I5HBk27Zt01//+ld99tlnKikpOSqcX3DBBYqJiZEk9enTRzfccIMiIiKsKBUAAABAKxHIf0Igh7NoampSSUmJZs2apddff/2Y23h5eWnatGmaNWuW+vbt28kVAgAAAGiN1uZQBnUDHISbm5tCQ0P12muv6d1331VISMhR29TV1enNN99UamqqPvnkEwuqBAAAANBeCOSAA5o6dary8/O1fft2bd++XT/++KPuu+8+BQcHS5Kqq6t1ySWX6LXXXjvm/i7e8QUAAABwCQRywEF5e3srJSVFKSkpOvPMM/XUU08pNzdXV111laTDXdxvvvlm3XrrrcrLy5NhGFq0aJGGDRsmHx8fJSUl6YILLtCf/vQnbqsGAAAAOCCuIQecTFNTk373u9/pmWeeMZd5eXmpf//+Wr9+/TH3SUlJ0Ycffqj+/ft3VpkAAABAl8U15ICLcnNz09NPP63nnntOvr6+kg5fW35kGI+Li1NgYKD5eMeOHRo+fLieeeYZbdmyRY2NjZ1eNwAAAICWCOSAk7rzzju1Z88ezZo1SwEBAZKk5ORkvf/++8rOzlZpaam2bt2qwYMHS5Kqqqp07733auDAgQoJCdG1116rzZs3W/kSAAAAgC6NLuuACyguLtb27ds1dOhQeXl5tVhXXV2tO++887i3Urv44ov1i1/8QuHh4YqJidHIkSP5WQEAAABOA/ch/wmBHDhs7dq1+uabb7Rq1SotXbpUhw4dOuZ2np6eGjNmjCZMmKAzzzxTAwcOVLdu3Tq5WgAAAMB5Ech/QiAHjlZZWanXX39dc+bM0d69e0+6vY+Pjzw8POTh4aHg4GBFRUUpMjJSNptNtbW1kqSRI0dq8uTJGjBggGw2W0e/BAAAAMBhEch/QiAHjq+urk5r1qxRfn6+9u/fry1btujTTz9VTk5Om4/ZvXt3hYeHy8/PT6GhoerVq5f69Omj6OhoeXl5ycPDQzt37tTatWu1bds2BQcHKzEx8agpNDS0RbBvaGiQm5ub3NwY+gIAAACOjUD+EwI5cGoMw9DWrVu1atUqbdq0SZs3b9bBgwfV2Nio+vp6HTp0SAcPHuzwOgIDA5WYmChfX1/l5uYqPz9fvr6+OuOMMzRkyBBFRESYrfbu7u7mv83zXl5eCgoKUnBwsMLDw5WQkCA/P78TPueBAwe0adMmZWZmavfu3XJ3d9d1112n3r17t7ruAwcOaNeuXbLb7QoLC1NYWJg8PDxO9+0AAACAEyGQ/4RADrS/uro6HThwQDabTd7e3iopKdH//vc/LViwQOvXr1dlZaXq6uqsLvMoERERioiIkJ+fn3x9fc1/JWnDhg3KzMw8ah83NzdNmzZN1113nWpqalRaWqqCggLt3btX+/btM4O/zWbTd999p02bNrXY39vbW7/4xS80duxYxcTEKDMzU9nZ2YqOjtakSZM0YsQIubu7q7S0VPn5+fLy8pKfn588PT1VU1OjqqoqVVdXq6qqSpWVlVq7dq0WL16s77//XsHBwTrvvPPMKSEhQdLhL1Wav1Tw8/NTYGCgAgICzMnPz++4lxXU1NSopKREYWFh8vT0PO57uW/fPrMOHx8fJSYmKiEhQSEhIS2eKzAwUD4+PjIMo8XU/N64u7u35b+yRR0vvfSS/ve//yk8PFznnXeezj33XJ1xxhny8fE5rWO3Rn19vXkehIeHt+nLl8bGRh08eFAhISEt3vO6ujodOnTIvDzE1ZWUlMjPz++ogSk7SvO5SK8bAEBHIJD/hEAOWKOhoUEFBQXKyMhQenq6Dh06pLq6OtXV1SkmJkZDhw7VoEGDVFFRoaysrGNO2dnZamhoUFRUlGJjY3Xw4EFlZWVZ/dLaVVhYmJqamlRcXHzax0pISNDgwYO1bt26E44N4OPjo7i4OMXFxcnd3V1VVVUqLy/Xvn37dODAAXO7iIgIs76mpiY1NjaaPSX27dt32vXabDYFBQUpJCREfn5+8vb2lqenp8rLy1VSUqK6ujolJCQoOTlZ3bt3l5ubmwzDUH19vaqqqlRYWKhFixapvr7+qGO7u7urT58+6tOnj9zd3c3am19HaGioBgwYoP79+8tms6mwsFD79++Xj4+P7Ha7fHx8dODAARUVFammpkaJiYlKTk5WfX29Vq9erdWrV2vnzp3Kzc1VU1OT+bzdunVTz5491bt3b8XExGjv3r3KzMxUaWmpYmNjlZCQIG9vb+Xl5ZlTQUGBGhsb5evrq2HDhmngwIHaunWrVq9ererqavXo0UOTJk3SmDFj5OXlpaamJtXW1qqsrEylpaXKzc3V7t27lZOTo4iICPXv31+9evVScXGx8vLyVFhYqNraWtXW1qqpqanFF1LN8926dVNcXJwiIiK0bds2rVy5Uunp6YqOjlavXr0UERGhffv2KScnR/X19UpKSlJycrKSk5PVq1cvJSQkKDMzU99++63Wrl2rqqoqNTY2ymazqUePHurVq5diY2NVW1ur6upqGYahgIAA+fr6atWqVfrvf/+rjRs3KigoSFdffbWuueYalZeXa+3atcrMzJSfn5/sdnuLL5MCAgLM/+PGxkZlZmYqJydH4eHhOuOMMxQfHy+bzabq6mqVlZWZ58DmzZv1wQcf6OOPP1Z1dbXS0tI0evRoJSUlyc3NTU1NTcrKylJ6err27t2rvn37avTo0TrrrLPk7+/foieOu7u7+bOTn59v/rt//37Fx8drxIgROuOMM1RZWanCwkJVV1erb9++CgoKkmEY2rRpkz7//HMVFRXJ09NTXl5eSkhI0FlnnaWUlBRlZ2dr+fLlSk9PV3x8vAYMGKCIiAjt2rVLO3bsUEVFhUJDQxUWFqZu3bqZvXK6detmvleVlZXKyMhQQUGBevTooeTkZNXU1GjRokVauHChDh06pN69eyslJUUJCQmKjIxUWFiYMjIytGbNGm3btk2NjY1yc3MzX7ubm5uCg4N17rnnasyYMfL19dW+ffv0448/KjMz0+zVlJCQoDFjxuiss85SeXm5eUvOxMRE9ezZUx4eHsrLy9OOHTskSX379lVMTIz5f9zY2KhNmzZp2bJl2rJli0JCQhQTE6OoqCgFBwcrKChItbW12r17tzIzM9XU1KS4uDjFxsYqNDRU/v7+8vHxUUlJiYqKinTw4EE1NDSooaFBVVVV2rdvn/bt26fi4mLzZyQqKkpjxozRmDFjZBiGdu7cqb1796pHjx4aOnSoevToYdZXUVGhjIwM7dy5U+Xl5QoICJC/v7/5hWTzvL+/v3x9fVVdXa3y8nJzKisrU0NDgwIDA2W32+Xr62t+Sblt2zZ9//332rBhgyIiIjR06FANHDhQ+/fv1+7du7V//34FBQUpLCzMPAeOnOx2uwzDUGVlpUpLS83Pi6qqKtntdoWEhMhut5uf7wUFBdq0aZO2bNkiX19fjR07ViNHjpSXl5dqampUWFgoNzc383V89913Wrp0qfLy8tSvXz+lpqYqNDTUfD9sNpsSEhLUo0cP1dfXq6ioSIWFhSoqKlJRUZH5BVxAQIBCQkKUlJSkXr16KTAwUAUFBSooKFBQUJCGDBmi/v37y9PTU1VVVSopKVFtba3q6urU0NAgLy8veXt7y83NTZWVlaqsrNSWLVu0dOlSrVy5UiEhIbr00ks1ZcoUNTU1aevWrcrOzlZUVJSSk5Pl6empRYsW6bPPPlNxcbHGjBmjiy++WGeffbb5hb10+AvSnJwcbd68WRs3blRmZqYCAwPNn7tu3bq1mA8LC5OXl5f5hXphYaHy8vKUnZ2tjRs3av369SosLNT555+ve+65R/369ZMk870JCwtTSEiIampqlJubq5ycHB04cEDFxcVmtomMjDS3KS8vV11dnfnZ7uHhofr6ejU0NJi/E38+NTY2mj8Px5o/cOCA+beYv7+/+vfvb06JiYlyd3dXbW2tNm/erJ07d5r/L/X19ebfezabTf7+/vLz81N4eLji4uIUExOjkpIS5eTkqKioyPx8Dw0NVXx8vEJCQo76EtowDO3fv1/p6enavn27duzYoaqqKr3yyiun/bdIR3KpQP7SSy/pqaeeUkFBgQYPHqwXXnhBw4cPb9W+BHLAeTX/AX1ki1lxcbE2bdqkioqKFr84jvy3sbHRbM0uKSlRfn6+MjMztWfPHpWUlKiqquqo5/Lx8dGQIUM0dOhQ9enTRz179tT69es1Z86c445I/3M2m01DhgzR8OHDVVVVpYMHD2rTpk2ndU3+8cTGxqq4uFiVlZXtfmzAFQQEBKi+vt4ceNKR9OzZU/X19crNzT3uNt7e3qdVu7e3twIDA1t8ySZJHh4ecnNza7deTM1fYhUVFZ3Sfh4eHvL29j7qM8xutyswMFC1tbWqqKhQTU1Nu9TZXgIDA2Wz2VRTU+OQPcGaubu7q6mpSafzZ76/v7+8vb1b/TuwozT3HDrWl68dyW63Kzw8XBUVFSosLOzQ5xoyZIj27t3b4ueo+QtCR+Tr66v4+HhlZma2+/+L3W5XVFSUPD095eHhobKyMuXl5R318+bl5aXKykqHvizQZQL5e++9p+uuu06vvPKKRowYoWeffVYffPCB0tPTFRERcdL9CeQAfs4wDNXW1prdwevq6hQbG3vMLtrl5eV6++23lZWVZbbIREZGqnv37oqJiVFDQ4PZ6jBgwACFhIQc9Vy7d+/WN998o6qqKvXs2VPx8fFav369Fi5cqOXLlysgIECJiYmKi4szW27q6urk4+NzVPf6Hj16aNy4cUpOTlZDQ4PWrFmjr7/+Wl9//bW+//571dbWytfXV6NGjVJqaqrq6+tVUVFhTuXl5SooKFBOTk6LP4Q9PT0VHR1ttizt37/fbDn6ecuYu7u74uPjdf7552vs2LFyd3dXVlaWcnJyVFZW1uL5KioqVF1dLZvN1mKSDo/2X1xcrOLiYlVXV6u2tlaNjY3y9/dXcHCw3NzctHfv3hP+QRkaGqpbbrlFM2fOVHV1tb7++mt999132rhxo7Zt29ahf8AFBwerZ8+eSkhIUH19vQoLC5Wfn3/Mmn18fI4KFjabTREREeZAiOnp6dqzZ4+5vkePHoqPj9eqVata9TqaWzzaS2f/MTh48GBlZGQc8wuzjhAQEKDQ0NAO+cIMgPU8PT1P6XdAZ3/mne6XbpB27typXr16WV3GcblMIB8xYoSGDRumF198UZLM7kh33HGH7r///pPuTyAH0FVUV1crJydHiYmJJ70O1zAMlZWVSZJ5zbojMAyjRVe12tpaZWZmtmjl8/DwMLvAxcfHH/e11tXVKT8//6gvFNzc3LRv3z5t3rxZ27dvl4eHhyIjIxUeHq76+nqVlZWpqqpKYWFhioyMlKenpzIzM5WRkSHDMDR06FCNGDFCcXFxx7y2u7q6Wrt371Z+fr66d++uxMRE+fj46ODBg8rOzlZ9fb26d+9utgAcqaCgQNu3b1dycrLi4uIkHf499sUXXyg9PV1ubm6y2Wzm2AXNLQlJSUmKjo7W/v37tXXrVmVlZSksLEyxsbGKioqSr6+v2a2zuQvlkWMTFBYWKjc3VwUFBWaX6f79++vgwYPatWuXDhw4oJiYGMXHx8vDw0O7du3Srl27lJGRoV27dikzM1MRERE6++yzNWrUKEVGRsrd3V319fXKzMzUzp07VVRUZH7JJB3+QqaiokIxMTGaPHmy4uLiVF5ervfff19LlixRVFSUhg4dqv79+7f44qv5PDlw4IB27typnTt3ysPDQz179lRcXJzy8vK0YcMG7dy5U76+vgoNDVVQUJDZMhwSEqKLLrpI48ePl4+Pj7Kzs/X999+ruLjYbFHs3r27UlJSFBUVpXXr1mn58uXatm1biy6dzZOvr69iYmLMKTo6WmFhYdq+fbtWr16tHTt2mLeLdHNzM7u8NjQ06LzzztPFF1+swYMHq6GhQdXV1dq8ebNWrlypLVu2KCEhQWeffbbOOOMM5ebmauvWrTpw4ICSk5OVkpKi0NBQc6DNgwcP6sCBAy3mS0tLFRMTY97pIisrS9u3b1dVVZXOP/98TZkyRX379lVGRoZ27NihvXv3mpdvdO/eXcOGDdOQIUPk7+/f4pKPpqYm7dy5U59//rm+/PJLVVVV6YwzzlBqaqr69u2r+Ph4RUREmN3NN23apLCwMMXHx8tut2v37t1KT09XZWWlevfurb59+8owDLMram1trXx8fOTj46N+/fpp9OjRGjFihNnNvLCwUKWlpSotLZWbm5t69uyppKQkeXh4KDc3V3v37lVZWZkqKytVXV1tDu4ZFhZmjl3h4+Oj6OhoxcTEKCwszLy959atW/XNN99o5cqV8vPzU+/evRUbG2veHSQjI0MeHh5mz4DmrtZhYWGqqqpSRUWFeW4f+W9VVZV8fX3NHgDNk4eHh8rLy1VaWmp+KdnY2Kju3btr5MiRGjZsmAoLC7V27Vrt3LlTkZGR6tmzp6Kjo1VaWqqDBw+2OAeap0OHDsnDw0N2u73F5Ofnp/Lych06dEgVFRXm56PdbtfAgQM1cOBAFRUV6YsvvtCyZcvk5uZmfl41f741NTUpNTVVY8aMUa9evbR582atXbtWlZWV5p1VbDab9uzZo5ycHHl7e5tjuDRPzV2tm1ufd+3apZ07d6qmpkZRUVGKiopSQUGB1q1bp40bN8rd3V2hoaEKDg6Wr6+vvLy85O7urrq6OvNynObfCzExMTrnnHM0fPhw5ebm6sMPP9RXX32loKAg9e/fX0lJSeYldSUlJTr77LN18cUXKzw8XF9++aU+++wzZWRkmN3r/f39FRsbq7i4OKWkpGjw4MFKSUlRTU2NDhw4YP7cNc83T82fD82XBcXGxqp79+7q16+fBg0aJMMw9M9//lPPPvuscnJy1K1bNw0ePFiRkZE6dOiQDhw4IG9vb8XHxys+Pt7som6321VaWqrCwkKz67+/v795eUFVVZUaGhrMFmZJLT6zmn+Gj7z0pnmQ3CMf2+12c3yYkpISbdmyRVu3btXWrVu1ZcsWZWdnKzk52bwEMSAgQF5eXi2mpqYm8+egsLBQOTk5ys/PV3BwsOLi4hQVFWX2aDxw4ICys7OVlZVlvn/19fXy8/Mz37ukpCT17dvXnKKiohx6jBWXCOR1dXXy8/PThx9+qEsuucRcPn36dJWUlOjjjz8+ap/ma4CalZWVKS4ujkAOAAAcQnNPhtMd1BCA8zMMQ+Xl5eblEHAdrQ3kDj20aPO3I5GRkS2WR0ZGqqCg4Jj7zJ49W0FBQebU3MIAAADgCJp7bACAzWaT3W4njHdhDh3I2+KBBx4wuzE1jz4LAAAAAICjcdxh6XT49jHu7u5HjWxYWFhoXsvyc97e3vL29u6M8gAAAAAAaDOHbiH38vJSamqqlixZYi5ramrSkiVLlJaWZmFlAAAAAACcHoduIZeke+65R9OnT9fQoUM1fPhwPfvss6qsrNT1119vdWkAAAAAALSZwwfyqVOnav/+/XrooYdUUFCgM844Q59//vlRA70BAAAAAOBMHPq2Z+2B+5ADAAAAADqTS9z2DAAAAAAAV0UgBwAAAADAAgRyAAAAAAAsQCAHAAAAAMACBHIAAAAAACxAIAcAAAAAwAIEcgAAAAAALEAgBwAAAADAAgRyAAAAAAAsQCAHAAAAAMACBHIAAAAAACzgYXUBHc0wDElSWVmZxZUAAAAAALqC5vzZnEePx+UDeXl5uSQpLi7O4koAAAAAAF1JeXm5goKCjrveZpwssju5pqYm7du3T4GBgbLZbFaXc1xlZWWKi4tTbm6u7Ha71eXASXDe4FRxzuBUcc6gLThvcKo4Z3CqHP2cMQxD5eXliomJkZvb8a8Ud/kWcjc3N8XGxlpdRqvZ7XaHPKHg2DhvcKo4Z3CqOGfQFpw3OFWcMzhVjnzOnKhlvBmDugEAAAAAYAECOQAAAAAAFiCQOwhvb2/96U9/kre3t9WlwIlw3uBUcc7gVHHOoC04b3CqOGdwqlzlnHH5Qd0AAAAAAHBEtJADAAAAAGABAjkAAAAAABYgkAMAAAAAYAECOQAAAAAAFiCQO4iXXnpJCQkJ8vHx0YgRI/TDDz9YXRIcxMMPPyybzdZiSklJMdfX1NRo5syZCgsLU0BAgKZMmaLCwkILK0ZnW758uSZNmqSYmBjZbDYtWLCgxXrDMPTQQw8pOjpavr6+GjdunDIyMlpsc+jQIV1zzTWy2+0KDg7WjTfeqIqKik58FehsJztvZsyYcdRnz4QJE1psw3nTtcyePVvDhg1TYGCgIiIidMkllyg9Pb3FNq35nZSTk6OLLrpIfn5+ioiI0O9+9zs1NDR05ktBJ2nNOTNmzJijPmtuueWWFttwznQdL7/8sgYNGiS73S673a60tDQtWrTIXO+KnzEEcgfw3nvv6Z577tGf/vQn/fjjjxo8eLDGjx+voqIiq0uDg+jfv7/y8/PN6bvvvjPX/fa3v9Unn3yiDz74QMuWLdO+fft02WWXWVgtOltlZaUGDx6sl1566Zjrn3zyST3//PN65ZVXtHr1avn7+2v8+PGqqakxt7nmmmu0detWLV68WJ9++qmWL1+um2++ubNeAixwsvNGkiZMmNDis+edd95psZ7zpmtZtmyZZs6cqVWrVmnx4sWqr6/XBRdcoMrKSnObk/1Oamxs1EUXXaS6ujp9//33evPNNzV37lw99NBDVrwkdLDWnDOSdNNNN7X4rHnyySfNdZwzXUtsbKwef/xxrVu3TmvXrtV5552nyZMna+vWrZJc9DPGgOWGDx9uzJw503zc2NhoxMTEGLNnz7awKjiKP/3pT8bgwYOPua6kpMTw9PQ0PvjgA3PZ9u3bDUnGypUrO6lCOBJJxvz5883HTU1NRlRUlPHUU0+Zy0pKSgxvb2/jnXfeMQzDMLZt22ZIMtasWWNus2jRIsNmsxl5eXmdVjus8/PzxjAMY/r06cbkyZOPuw/nDYqKigxJxrJlywzDaN3vpM8++8xwc3MzCgoKzG1efvllw263G7W1tZ37AtDpfn7OGIZhnHPOOcZdd9113H04ZxASEmK8/vrrLvsZQwu5xerq6rRu3TqNGzfOXObm5qZx48Zp5cqVFlYGR5KRkaGYmBj17NlT11xzjXJyciRJ69atU319fYvzJyUlRfHx8Zw/kCRlZWWpoKCgxTkSFBSkESNGmOfIypUrFRwcrKFDh5rbjBs3Tm5ublq9enWn1wzHsXTpUkVERKhPnz669dZbdfDgQXMd5w1KS0slSaGhoZJa9ztp5cqVGjhwoCIjI81txo8fr7KyMrMFDK7r5+dMs3nz5qlbt24aMGCAHnjgAVVVVZnrOGe6rsbGRr377ruqrKxUWlqay37GeFhdQFd34MABNTY2tjhpJCkyMlI7duywqCo4khEjRmju3Lnq06eP8vPz9cgjj+jss8/Wli1bVFBQIC8vLwUHB7fYJzIyUgUFBdYUDIfSfB4c6zOmeV1BQYEiIiJarPfw8FBoaCjnURc2YcIEXXbZZUpMTNTu3bv1+9//XhMnTtTKlSvl7u7OedPFNTU16e6779aoUaM0YMAASWrV76SCgoJjfh41r4PrOtY5I0lXX321evTooZiYGG3atEmzZs1Senq6PvroI0mcM13R5s2blZaWppqaGgUEBGj+/Pnq16+fNmzY4JKfMQRywMFNnDjRnB80aJBGjBihHj166P3335evr6+FlQFwZVdddZU5P3DgQA0aNEhJSUlaunSpxo4da2FlcAQzZ87Uli1bWoxpApzI8c6ZI8edGDhwoKKjozV27Fjt3r1bSUlJnV0mHECfPn20YcMGlZaW6sMPP9T06dO1bNkyq8vqMHRZt1i3bt3k7u5+1OiAhYWFioqKsqgqOLLg4GD17t1bu3btUlRUlOrq6lRSUtJiG84fNGs+D070GRMVFXXUIJINDQ06dOgQ5xFMPXv2VLdu3bRr1y5JnDdd2e23365PP/1U33zzjWJjY83lrfmdFBUVdczPo+Z1cE3HO2eOZcSIEZLU4rOGc6Zr8fLyUnJyslJTUzV79mwNHjxYzz33nMt+xhDILebl5aXU1FQtWbLEXNbU1KQlS5YoLS3NwsrgqCoqKrR7925FR0crNTVVnp6eLc6f9PR05eTkcP5AkpSYmKioqKgW50hZWZlWr15tniNpaWkqKSnRunXrzG2+/vprNTU1mX8YAXv37tXBgwcVHR0tifOmKzIMQ7fffrvmz5+vr7/+WomJiS3Wt+Z3UlpamjZv3tziy5zFixfLbrerX79+nfNC0GlOds4cy4YNGySpxWcN50zX1tTUpNraWtf9jLF6VDkYxrvvvmt4e3sbc+fONbZt22bcfPPNRnBwcIvRAdF13XvvvcbSpUuNrKwsY8WKFca4ceOMbt26GUVFRYZhGMYtt9xixMfHG19//bWxdu1aIy0tzUhLS7O4anSm8vJyY/369cb69esNScYzzzxjrF+/3sjOzjYMwzAef/xxIzg42Pj444+NTZs2GZMnTzYSExON6upq8xgTJkwwzjzzTGP16tXGd999Z/Tq1cuYNm2aVS8JneBE5015eblx3333GStXrjSysrKMr776yhgyZIjRq1cvo6amxjwG503XcuuttxpBQUHG0qVLjfz8fHOqqqoytznZ76SGhgZjwIABxgUXXGBs2LDB+Pzzz43w8HDjgQcesOIloYOd7JzZtWuX8eijjxpr1641srKyjI8//tjo2bOnMXr0aPMYnDNdy/33328sW7bMyMrKMjZt2mTcf//9hs1mM7788kvDMFzzM4ZA7iBeeOEFIz4+3vDy8jKGDx9urFq1yuqS4CCmTp1qREdHG15eXkb37t2NqVOnGrt27TLXV1dXG7fddpsREhJi+Pn5GZdeeqmRn59vYcXobN98840h6ahp+vTphmEcvvXZgw8+aERGRhre3t7G2LFjjfT09BbHOHjwoDFt2jQjICDAsNvtxvXXX2+Ul5db8GrQWU503lRVVRkXXHCBER4ebnh6eho9evQwbrrppqO+KOa86VqOdb5IMt544w1zm9b8TtqzZ48xceJEw9fX1+jWrZtx7733GvX19Z38atAZTnbO5OTkGKNHjzZCQ0MNb29vIzk52fjd735nlJaWtjgO50zXccMNNxg9evQwvLy8jPDwcGPs2LFmGDcM1/yMsRmGYXReezwAAAAAAJC4hhwAAAAAAEsQyAEAAAAAsACBHAAAAAAACxDIAQAAAACwAIEcAAAAAAALEMgBAAAAALAAgRwAAAAAAAsQyAEAAAAAsACBHAAAJ5OQkKBnn3221dsvXbpUNptNJSUlHVYTAAA4dQRyAAA6iM1mO+H08MMPt+m4a9as0c0339zq7UeOHKn8/HwFBQW16flOxWuvvabBgwcrICBAwcHBOvPMMzV79mxz/YwZM3TJJZd0eB0AADgDD6sLAADAVeXn55vz7733nh566CGlp6ebywICAsx5wzDU2NgoD4+T/2oODw8/pTq8vLwUFRV1Svu0xb/+9S/dfffdev7553XOOeeotrZWmzZt0pYtWzr8uQEAcEa0kAMA0EGioqLMKSgoSDabzXy8Y8cOBQYGatGiRUpNTZW3t7e+++477d69W5MnT1ZkZKQCAgI0bNgwffXVVy2O+/Mu6zabTa+//rouvfRS+fn5qVevXlq4cKG5/udd1ufOnavg4GB98cUX6tu3rwICAjRhwoQWXyA0NDTozjvvVHBwsMLCwjRr1ixNnz79hK3bCxcu1JVXXqkbb7xRycnJ6t+/v6ZNm6a//OUvkqSHH35Yb775pj7++GOzl8DSpUslSbm5ubryyisVHBys0NBQTZ48WXv27DGP3dyy/sgjjyg8PFx2u1233HKL6urqzG0+/PBDDRw4UL6+vgoLC9O4ceNUWVl5iv9rAAB0HgI5AAAWuv/++/X4449r+/btGjRokCoqKnThhRdqyZIlWr9+vSZMmKBJkyYpJyfnhMd55JFHdOWVV2rTpk268MILdc011+jQoUPH3b6qqkpz5szR22+/reXLlysnJ0f33Xefuf6JJ57QvHnz9MYbb2jFihUqKyvTggULTlhDVFSUVq1apezs7GOuv++++3TllVea4T8/P18jR45UfX29xo8fr8DAQH377bdasWKF+SXBkYF7yZIl2r59u5YuXap33nlHH330kR555BFJh3sjTJs2TTfccIO5zWWXXSbDME5YMwAAljIAAECHe+ONN4ygoCDz8TfffGNIMhYsWHDSffv372+88MIL5uMePXoYf/vb38zHkow//vGP5uOKigpDkrFo0aIWz1VcXGzWIsnYtWuXuc9LL71kREZGmo8jIyONp556ynzc0NBgxMfHG5MnTz5unfv27TPOOussQ5LRu3dvY/r06cZ7771nNDY2mttMnz79qGO8/fbbRp8+fYympiZzWW1treHr62t88cUX5n6hoaFGZWWluc3LL79sBAQEGI2Njca6desMScaePXuOWx8AAI6GFnIAACw0dOjQFo8rKip03333qW/fvgoODlZAQIC2b99+0hbyQYMGmfP+/v6y2+0qKio67vZ+fn5KSkoyH0dHR5vbl5aWqrCwUMOHDzfXu7u7KzU19YQ1REdHa+XKldq8ebPuuusuNTQ0aPr06ZowYYKampqOu9/GjRu1a9cuBQYGKiAgQAEBAQoNDVVNTY12795tbjd48GD5+fmZj9PS0lRRUaHc3FwNHjxYY8eO1cCBA3XFFVfotddeU3Fx8QnrBQDAagzqBgCAhfz9/Vs8vu+++7R48WLNmTNHycnJ8vX11eWXX96i6/axeHp6tnhss9lOGIKPtb3RTt27BwwYoAEDBui2227TLbfcorPPPlvLli3Tueeee8ztKyoqlJqaqnnz5h21rrUD2Lm7u2vx4sX6/vvv9eWXX+qFF17QH/7wB61evVqJiYmn9XoAAOgotJADAOBAVqxYoRkzZujSSy/VwIEDFRUV1WJws84QFBSkyMhIrVmzxlzW2NioH3/88ZSP1a9fP0kyB1fz8vJSY2Nji22GDBmijIwMRUREKDk5ucV05K3aNm7cqOrqavPxqlWrFBAQoLi4OEmHv1QYNWqUHnnkEa1fv15eXl6aP3/+KdcMAEBnIZADAOBAevXqpY8++kgbNmzQxo0bdfXVV5+wpbuj3HHHHZo9e7Y+/vhjpaen66677lJxcbFsNttx97n11lv12GOPacWKFcrOztaqVat03XXXKTw8XGlpaZIOjxC/adMmpaen68CBA6qvr9c111yjbt26afLkyfr222+VlZWlpUuX6s4779TevXvN49fV1enGG2/Utm3b9Nlnn+lPf/qTbr/9drm5uWn16tX661//qrVr1yonJ0cfffSR9u/fr759+3b4ewUAQFsRyAEAcCDPPPOMQkJCNHLkSE2aNEnjx4/XkCFDOr2OWbNmadq0abruuuuUlpamgIAAjR8/Xj4+PsfdZ9y4cVq1apWuuOIK9e7dW1OmTJGPj4+WLFmisLAwSdJNN92kPn36aOjQoQoPD9eKFSvk5+en5cuXKz4+Xpdddpn69u2rG2+8UTU1NbLb7ebxx44dq169emn06NGaOnWqfvnLX+rhhx+WJNntdi1fvlwXXnihevfurT/+8Y96+umnNXHixA59nwAAOB02o70uGAMAAC6rqalJffv21ZVXXqnHHnus059/xowZKikpOemt1wAAcCYM6gYAAI6SnZ2tL7/8Uuecc45qa2v14osvKisrS1dffbXVpQEA4DLosg4AAI7i5uamuXPnatiwYRo1apQ2b96sr776imuyAQBoR3RZBwAAAADAArSQAwAAAABgAQI5AAAAAAAWIJADAAAAAGABAjkAAAAAABYgkAMAAAAAYAECOQAAAAAAFiCQAwAAAABgAQI5AAAAAAAW+H+ynwLLgISwoAAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "log_history = lora_triner.state.log_history\n",
        "df = pd.DataFrame(log_history)\n",
        "\n",
        "if 'loss' in df.columns:\n",
        "    df_filtered = df.dropna(subset=['loss'], how='all')\n",
        "    df_filtered.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(df_filtered['loss'], lw=2, c='k', label='Training Loss')\n",
        "\n",
        "    plt.title('Training Loss Curves')\n",
        "    plt.xlabel('Training Steps')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.savefig(\"outputs/flan-t5-base_lora.svg\", format=\"svg\", dpi=150, transparent=True, bbox_inches='tight')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OI_jVHiByNgL"
      },
      "source": [
        "### Evaluation on the fine-tuned model\n",
        "\n",
        "Load the saved fine-tuned model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-03-21T13:14:21.301063Z",
          "iopub.status.busy": "2024-03-21T13:14:21.300654Z",
          "iopub.status.idle": "2024-03-21T13:14:23.716898Z",
          "shell.execute_reply": "2024-03-21T13:14:23.716192Z",
          "shell.execute_reply.started": "2024-03-21T13:14:21.301029Z"
        },
        "id": "crgwJ7gatZS4",
        "outputId": "57f704ce-8846-4bbe-feaf-492fdda279d4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "from peft import PeftModel, PeftConfig\n",
        "tokenizer, base_model = load_model(model_name)\n",
        "peft_model = PeftModel.from_pretrained(base_model,\n",
        "                                       lora_model_name,\n",
        "                                       torch_dtype=torch.bfloat16,\n",
        "                                       is_trainnable=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6qOUZUwJA-R"
      },
      "source": [
        "ROUGE Scores:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-03-21T13:14:23.718501Z",
          "iopub.status.busy": "2024-03-21T13:14:23.718055Z",
          "iopub.status.idle": "2024-03-21T13:14:37.156296Z",
          "shell.execute_reply": "2024-03-21T13:14:37.155490Z",
          "shell.execute_reply.started": "2024-03-21T13:14:23.718465Z"
        },
        "id": "1WBoL-PhKjJp",
        "outputId": "d96970e8-e5b6-4b43-9ce4-5c96cc45a68b",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (744 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Target: Customer is waiting over 3 weeks for compensation that was promised . Agent informed that he will get back to him with further  information.\n",
            "Predict: Customer is complaining about the delay in paying mandatory compensation. Agent is asking for an additional gesture of goodwill.\n",
            "{'rouge1': Score(precision=0.2631578947368421, recall=0.21739130434782608, fmeasure=0.23809523809523808)}\n",
            "\n",
            "Target: Customer is complaining about the new updates IOS11 and can't even use some apps on phone. Agent asks to send a DM and work from there URL.\n",
            "Predict: Customer is complaining about the new update ios11 sucks.\n",
            "{'rouge1': Score(precision=0.8888888888888888, recall=0.2857142857142857, fmeasure=0.43243243243243246)}\n",
            "\n",
            "Target: Customer is complaining about issues with claiming train delay compensation. Agent states to claim the compensation for the entire journey.\n",
            "Predict: Customer is complaining about the delay on both companies service.\n",
            "{'rouge1': Score(precision=0.6, recall=0.3, fmeasure=0.4)}\n",
            "\n",
            "Target: Customer is complaining about customer service. Agent updated that to DM so they can talk about this .\n",
            "Predict: Customer service is one of their main priorities. Agents are not able to provide feedback on the agent that placed them on hold for so long.\n",
            "{'rouge1': Score(precision=0.2692307692307692, recall=0.4117647058823529, fmeasure=0.3255813953488372)}\n",
            "\n",
            "Target: Customer is complaining about the app is not able to open in the iphone. Agent suggested the new version of iOS which can update the Appstores.\n",
            "Predict: Customer is complaining about the new update made it so my car cant control my 115888.\n",
            "{'rouge1': Score(precision=0.4375, recall=0.2692307692307692, fmeasure=0.33333333333333337)}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "scorer = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)\n",
        "for item in random.choices(list(tokenized_datasets['test']), k = 5):\n",
        "    prompt = \"Summarize: \" + item['inputs']\n",
        "    output = generate_output(tokenizer, peft_model, prompt)\n",
        "    scores = scorer.score(item['summaries'], output)\n",
        "    print(\"Target:\", item['summaries'])\n",
        "    print(\"Predict:\", output)\n",
        "    print(scores)\n",
        "    print()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "saturn (Python 3)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "state": {}
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
