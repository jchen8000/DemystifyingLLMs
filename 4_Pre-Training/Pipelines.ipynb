{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jchen8000/DemystifyingLLMs/blob/main/4_Pre-Training/Pipelines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8FtcWXfMpry"
      },
      "source": [
        "# 4. Pre-Training\n",
        "\n",
        "This script uses the HuggingFace datases, as a prerequisite you need a HuggingFace account and obtain a access token, see https://huggingface.co/docs/hub/security-tokens. You should add the token to Colab Secrets as HF_TOKEN.\n",
        "\n",
        "\n",
        "## 4.10 Pipelines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rApA085SQ1IY",
        "outputId": "3e4f4384-c627-4e5c-e7cd-6e0d50b1f9ae"
      },
      "outputs": [],
      "source": [
        "%pip install -q transformers==4.57.3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MM1ZngSQ_17"
      },
      "source": [
        "### Translation Example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5D6tzbO9Mo6p",
        "outputId": "63b97c42-3432-43cf-8e9e-28cefeef8951"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to google-t5/t5-base and revision 686f1db (https://huggingface.co/google-t5/t5-base).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5_fast.py:171: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on google-t5/t5-base automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load the translation pipeline\n",
        "translator = pipeline(\"translation_en_to_fr\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlQQkYz9NNgA",
        "outputId": "901b34df-3b1f-4074-fff8-eee80295c240"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "English: Will you help me with my homework?\n",
            "Frenchn: Avez-vous de l'aide pour mes devoirs?\n"
          ]
        }
      ],
      "source": [
        "# Input text to translate\n",
        "text = \"Will you help me with my homework?\"\n",
        "\n",
        "# Translate the text\n",
        "translation = translator(text)[0][\"translation_text\"]\n",
        "\n",
        "print(f\"English: {text}\")\n",
        "print(f\"Frenchn: {translation}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O25TeZCeQ7xJ"
      },
      "source": [
        "### Question-Answer Example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNaos7CrQ67h",
        "outputId": "749298c5-b789-4e33-bb05-56b4fbd66e9c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        }
      ],
      "source": [
        "qa_pipeline = pipeline(\"question-answering\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91DVRgAzRQHu",
        "outputId": "07146706-10e1-456b-ce65-afd13d2ced9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: What is the Great Wall of China made of?\n",
            "Answer: stone, brick, tamped earth, wood, and other materials\n",
            "Score: 0.7061177492141724\n"
          ]
        }
      ],
      "source": [
        "context = \"\"\"\n",
        "The Great Wall of China is a series of fortifications made of stone, brick, tamped earth, wood, and other materials,\n",
        "generally built along an east-to-west line across the historical northern borders of China in part to protect the\n",
        "Chinese states and empires against the raids and invasions of the various nomadic groups from the Eurasian Steppe.\n",
        "\"\"\"\n",
        "\n",
        "question = \"What is the Great Wall of China made of?\"\n",
        "\n",
        "# Use the pipeline to answer the question\n",
        "answer = qa_pipeline(question=question, context=context)\n",
        "\n",
        "print(f\"Question: {question}\")\n",
        "print(f\"Answer: {answer['answer']}\")\n",
        "print(f\"Score: {answer['score']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-kZVVdTdvSd"
      },
      "source": [
        "### Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E20gTtdud3Ci",
        "outputId": "b6137708-1a1b-4b23-dcae-7c989ac994bd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "# sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
        "sentiment_pipeline = pipeline(model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJDf0TVTeZJu",
        "outputId": "e1ea106b-9d21-45c4-95ef-6143119367a4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'label': 'positive', 'score': 0.9825846552848816}]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt1 = f\"\"\"\n",
        "Customer Review: 'The shipping was quick and the item was perfect. Totally satisfied!'.\n",
        "\"\"\"\n",
        "sentiment_pipeline(prompt1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYwCzdXEe1Gn",
        "outputId": "3e442156-61a3-46ed-a680-02ee3640f654"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'label': 'negative', 'score': 0.9405812621116638}]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt2 = f\"\"\"\n",
        "Customer Review: 'The restaurant was terrible, and the service was even worse. Not going back there again.'\n",
        "\"\"\"\n",
        "sentiment_pipeline(prompt2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8M5DBduPe94B",
        "outputId": "ff78eb47-8c6e-427f-958a-e7f812e9c9ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'label': 'neutral', 'score': 0.5042181015014648}]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt3 = f\"\"\"\n",
        "Customer Review: 'This restaurant was clean in general, but it took a while to get my foods served.'\n",
        "\"\"\"\n",
        "sentiment_pipeline(prompt3)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyOx20iHw40r6+PURqH3w4j2",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
