{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jchen8000/DemystifyingLLMs/blob/main/3_Transformer/Transformer_From_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pOZYVPlaZKc"
      },
      "source": [
        "# 3. Transformer\n",
        "\n",
        "**Implement a Transformer from scratch**\n",
        "\n",
        "*   3.1 Dataset and Tokenization\n",
        "*   3.3 Positional Encoding\n",
        "*   3.4 Layer Normalization\n",
        "*   3.5 Feed Forward\n",
        "*   3.6 Scaled Dot-Product Attention\n",
        "*   3.7 Mask\n",
        "*   3.8 Multi-Head Attention\n",
        "*   3.9 Encoder Layer and Encoder\n",
        "*   3.10 Decoder Layer and Decoder\n",
        "*   3.11 Transformer\n",
        "*   3.12 Training\n",
        "*   3.13 Inference\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install \\\n",
        "  numpy==2.0.2 \\\n",
        "  torch==2.9.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-07T15:34:32.884111Z",
          "iopub.status.busy": "2024-02-07T15:34:32.883611Z",
          "iopub.status.idle": "2024-02-07T15:34:33.439490Z",
          "shell.execute_reply": "2024-02-07T15:34:33.438856Z",
          "shell.execute_reply.started": "2024-02-07T15:34:32.884070Z"
        },
        "id": "KEfH4u-FhLXL"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as Data\n",
        "from torch.nn.utils.rnn import pad_sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-07T15:34:33.441304Z",
          "iopub.status.busy": "2024-02-07T15:34:33.440944Z",
          "iopub.status.idle": "2024-02-07T15:34:33.626221Z",
          "shell.execute_reply": "2024-02-07T15:34:33.625190Z",
          "shell.execute_reply.started": "2024-02-07T15:34:33.441284Z"
        },
        "id": "lSmV26jwhZUp"
      },
      "outputs": [],
      "source": [
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "epochs = 100\n",
        "torch.manual_seed(999)\n",
        "batch_size = 8\n",
        "learning_rate=1e-3\n",
        "d_model = 512\n",
        "d_ff = 2048\n",
        "d_k = d_v = 64\n",
        "n_layers = 6\n",
        "n_heads = 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xi73ByZMhcS0"
      },
      "source": [
        "## 3.1\tDataset and Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-07T15:34:33.627713Z",
          "iopub.status.busy": "2024-02-07T15:34:33.627404Z",
          "iopub.status.idle": "2024-02-07T15:34:33.637258Z",
          "shell.execute_reply": "2024-02-07T15:34:33.636562Z",
          "shell.execute_reply.started": "2024-02-07T15:34:33.627690Z"
        },
        "id": "2SzlBKRlDkge"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# Question and Answer Dataset\n",
        "# https://www.kaggle.com/datasets/rtatman/questionanswer-dataset/\n",
        "# File: S08_question_answer_pairs.txt\n",
        "#\n",
        "question_answer = [\n",
        "  ['What are the similarities between the beetles and the grasshoppers?',  'Beetles have the mouthparts that are similar to those of the grasshoppers.'],\n",
        "  ['What land animal is larger than an elephant?',  'None, the elephant is the largest land animal in the world.'],\n",
        "  ['How often do turtles breed?',  'Every few years or more.'],\n",
        "  ['Where do sea turtles lay their eggs?',  'Holes dug into mud or sand.'],\n",
        "  ['How do otters keep themselves warm without blubber?',  'A layer of air trapped in their fur.'],\n",
        "  ['How much time to penguins spend on land?',  'They spend half of their life on land.'],\n",
        "  ['What are the three sections of a beetle?',  'The head, the thorax, and the abdomen.'],\n",
        "  ['Can polar bears be seen under infrared photography?',  'Polar bears are nearly invisible under infrared photography.'],\n",
        "  ['What do fossil and DNA evidence tell us?',  'The polar bear diverged from the brown bear roughly 200 thousand years ago.'],\n",
        "  ['On average are cougar males heavier than females?',\t'On average the cougar males are heavier than the females.'],\n",
        "  ['How are Isabelline penguins different from most penguins?',  'Because they are born with brown rather than black plumage.'],\n",
        "  ['What do beetles eat?',  'They often feed on plants and fungi, break down animal and plant debris, and eat other invertebrates.'],\n",
        "  ['What are the similarities between beetles and grasshoppers?',  'Beetles have mouthparts similar to those of grasshoppers.'],\n",
        "  ['How much do elephants weight at birth?',  'At birth it is common for an elephant calf to weigh 120 kilograms or 265 lb.'],\n",
        "  ['How do elephants communicate over long distances?',  'By producing and receiving low-frequency sound or infrasound.'],\n",
        "  ['What makes penguins so agile in the water?',  'Smooth plumage preserves a layer of air, ensuring buoyancy, wings are flippers.'],\n",
        "]\n",
        "\n",
        "texts = []\n",
        "for que_text, ans_text in question_answer:\n",
        "  text = que_text.replace('?', ' ?')\n",
        "  texts.extend(text.split())\n",
        "  text = ans_text.replace('.', ' .')\n",
        "  texts.extend(text.split())\n",
        "\n",
        "# Special tokens:\n",
        "#   <PAD>: Padding token\n",
        "#   <UNK>: Unknown token\n",
        "#   <SOS>: Start-of-Sequence token\n",
        "#   <EOS>: End-of-Sequence token\n",
        "words = sorted(list(set(texts)))\n",
        "words = ['<PAD>', '<UNK>','<SOS>','<EOS>'] + words\n",
        "\n",
        "class Tokenizer():\n",
        "    def __init__(self, vocabulary):\n",
        "      self.idx2word = {index:word for index, word in enumerate(vocabulary)}\n",
        "      self.word2idx = {word:index for index, word in enumerate(vocabulary)}\n",
        "\n",
        "    def get_vocab_size(self):\n",
        "      return len(self.idx2word)\n",
        "\n",
        "    def encode(self, text):\n",
        "      return [self.word2idx[w] for w in text.split()]\n",
        "\n",
        "    def encode_word(self, char):\n",
        "      return self.word2idx[char]\n",
        "\n",
        "    def decode(self, encoded_text):\n",
        "      return [self.idx2word[i] for i in encoded_text]\n",
        "\n",
        "    def decode_text(self, encoded_text):\n",
        "      s = self.decode(encoded_text)\n",
        "      return (\" \".join(s))\n",
        "\n",
        "tokenizer = Tokenizer(words)\n",
        "\n",
        "vocab_size = tokenizer.get_vocab_size()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-07T15:34:33.638532Z",
          "iopub.status.busy": "2024-02-07T15:34:33.638202Z",
          "iopub.status.idle": "2024-02-07T15:34:33.645310Z",
          "shell.execute_reply": "2024-02-07T15:34:33.644692Z",
          "shell.execute_reply.started": "2024-02-07T15:34:33.638509Z"
        },
        "id": "DqYpyC-hx32X"
      },
      "outputs": [],
      "source": [
        "def make_data(sentences):\n",
        "    enc_inputs, dec_inputs, dec_outputs = [], [], []\n",
        "\n",
        "    for i in range(len(sentences)):\n",
        "        que_text = sentences[i][0].replace('?', ' ?')\n",
        "        ans_text_inp = '<SOS> ' + sentences[i][1].replace('.', ' .')\n",
        "        ans_text_out = sentences[i][1].replace('.', ' .') + ' <EOS>'\n",
        "\n",
        "        enc_input = tokenizer.encode(que_text)\n",
        "        dec_input = tokenizer.encode(ans_text_inp)\n",
        "        dec_output = tokenizer.encode(ans_text_out)\n",
        "\n",
        "        enc_inputs.append(torch.LongTensor(enc_input))\n",
        "        dec_inputs.append(torch.LongTensor(dec_input))\n",
        "        dec_outputs.append(torch.LongTensor(dec_output))\n",
        "\n",
        "    return pad_sequence(enc_inputs, batch_first=True), pad_sequence(dec_inputs, batch_first=True), pad_sequence(dec_outputs, batch_first=True)\n",
        "\n",
        "enc_inputs, dec_inputs, dec_outputs = make_data(question_answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-07T15:34:33.646453Z",
          "iopub.status.busy": "2024-02-07T15:34:33.646190Z",
          "iopub.status.idle": "2024-02-07T15:34:33.651417Z",
          "shell.execute_reply": "2024-02-07T15:34:33.650722Z",
          "shell.execute_reply.started": "2024-02-07T15:34:33.646433Z"
        },
        "id": "FiCnFu94bLvR"
      },
      "outputs": [],
      "source": [
        "class DataSet(Data.Dataset):\n",
        "    def __init__(self, data):\n",
        "        super(DataSet, self).__init__()\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data[0].shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return [x[idx] for x in self.data]\n",
        "\n",
        "loader = Data.DataLoader( DataSet([enc_inputs, dec_inputs, dec_outputs]), batch_size, True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDNliX5jkzBW"
      },
      "source": [
        "## 3.3\tPositional Encoding\n",
        "\n",
        "Based on the paper [Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf), Positional Encoding is defined as:\n",
        "\n",
        "$PE_{(pos, 2i)}=\\sin{\\left( \\frac{pos}{10000^{2i/d_{model}}} \\right)}$\n",
        "\n",
        "$PE_{pos, 2i+1}=\\cos{\\left( \\frac{pos}{10000^{2i/d_{model}}} \\right)}$\n",
        "\n",
        "where:\n",
        "\n",
        "$pos$: is the position of an item in the input sequence, $0 \\leqslant  pos \\lt  \\frac{len(input)}{2}$\n",
        "\n",
        "$d_{model}$: Dimension of the embedding space\n",
        "\n",
        "It's implemented as below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-07T15:34:33.657631Z",
          "iopub.status.busy": "2024-02-07T15:34:33.657382Z",
          "iopub.status.idle": "2024-02-07T15:34:33.663297Z",
          "shell.execute_reply": "2024-02-07T15:34:33.662715Z",
          "shell.execute_reply.started": "2024-02-07T15:34:33.657611Z"
        },
        "id": "THZpnXDWkzj8"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000, dropout=0.1):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe_table', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe_table[:, :x.size(1), :]\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqMmq8I4qmPO"
      },
      "source": [
        "## 3.4\tLayer Normalization\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jptWah-wgSv"
      },
      "source": [
        "**Layer Normalization** is based on the paper of [Layer Normalization](https://arxiv.org/abs/1607.06450), it can be implemented with *torch.nn.LayerNorm()*.\n",
        "\n",
        "Here we do our implementation, it is defined as:\n",
        "\n",
        "$$y = \\displaystyle \\frac{x-E\\left[ x \\right]}{\\sqrt{Var\\left[ x \\right]+\\epsilon}}\\ast \\gamma + \\beta$$\n",
        "\n",
        "\n",
        "\n",
        "$E$ is the mean of $x$,\n",
        "\n",
        "$Var$ is the standard-deviation of $x$\n",
        "\n",
        "Both mean and standard-deviation are calculated over the last dimension of $x$, and calculated by:\n",
        "\n",
        "```\n",
        "mean = x.mean(dim = -1, keepdim = True),\n",
        "std = x.std(dim = -1, keepdim = True)\n",
        "```\n",
        "\n",
        "$\\gamma$ and $\\beta$ are learnable parameters.\n",
        "\n",
        "$\\epsilon$ is to prevent dividing by zero or when std is near zero, default is 1e-5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-07T15:34:33.664936Z",
          "iopub.status.busy": "2024-02-07T15:34:33.664262Z",
          "iopub.status.idle": "2024-02-07T15:34:33.671214Z",
          "shell.execute_reply": "2024-02-07T15:34:33.670509Z",
          "shell.execute_reply.started": "2024-02-07T15:34:33.664905Z"
        },
        "id": "sm4M8wj3wWXX"
      },
      "outputs": [],
      "source": [
        "class LayerNorm(nn.Module):\n",
        "\n",
        "    def __init__(self, features, eps=1e-5) -> None:\n",
        "        super(LayerNorm, self).__init__()\n",
        "        self.eps = eps\n",
        "        self.gamma = nn.Parameter(torch.ones(features)) # gamma is a learnable parameter\n",
        "        self.beta = nn.Parameter(torch.zeros(features)) # beta is a learnable parameter\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim = -1, keepdim = True)\n",
        "        std = x.std(dim = -1, keepdim = True)\n",
        "        return self.gamma * (x - mean) / (std + self.eps) + self.beta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVdh0F150UG6"
      },
      "source": [
        "## 3.5\tFeed Forward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ts89I1gq10V6"
      },
      "source": [
        "**Position-wise Feed-Forward Networks**, based on the paper [Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf), is defined as:\n",
        "\n",
        "$$FFN(x) = \\max(0, xW_1 + b_1)W_2 + b_2$$\n",
        "\n",
        "This consists of two linear transformations with a *ReLU* activation in between.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-07T15:34:33.672527Z",
          "iopub.status.busy": "2024-02-07T15:34:33.672216Z",
          "iopub.status.idle": "2024-02-07T15:34:33.678661Z",
          "shell.execute_reply": "2024-02-07T15:34:33.677834Z",
          "shell.execute_reply.started": "2024-02-07T15:34:33.672498Z"
        },
        "id": "9kltvC5jq1vA"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_ff, dropout=0.2):\n",
        "        super(FeedForward, self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(d_model, d_ff, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(d_ff, d_model, bias=False)\n",
        "        )\n",
        "        self.ln = LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        output = self.fc(x)\n",
        "        return self.ln(output+residual)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZn6k7tg0c6W"
      },
      "source": [
        "## 3.6\tScaled Dot-Product Attention\n",
        "\n",
        "Based on the paper [Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf), the input consists of queries and keys of dimension $d_k$, and values of dimension $d_v$. We compute the dot products of the query with all keys, divide each by $\\sqrt{d_k}$, and apply a softmax function to obtain the weights on the\n",
        "values.\n",
        "\n",
        "In practice, we compute the attention function on a set of queries simultaneously, packed together into a matrix $Q$. The keys and values are also packed together into matrices $K$ and $V$. We compute\n",
        "the matrix of outputs as:\n",
        "\n",
        "$$Attention(Q, K, V)=softmax \\left( \\frac{QK^T}{\\sqrt{d_k}} \\right) V$$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-07T15:34:33.679878Z",
          "iopub.status.busy": "2024-02-07T15:34:33.679587Z",
          "iopub.status.idle": "2024-02-07T15:34:33.685676Z",
          "shell.execute_reply": "2024-02-07T15:34:33.685098Z",
          "shell.execute_reply.started": "2024-02-07T15:34:33.679858Z"
        },
        "id": "VSURuVsU0j7l"
      },
      "outputs": [],
      "source": [
        "class ScaledDotProductAttention(nn.Module):\n",
        "    def __init__(self, dropout=0.2):\n",
        "        super(ScaledDotProductAttention, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, Q, K, V, mask=None):\n",
        "        attn_logits = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k)\n",
        "        if mask is not None:\n",
        "            attn_logits = attn_logits.masked_fill_(mask, -float('inf'))\n",
        "        scores = nn.Softmax(dim=-1)(attn_logits)\n",
        "        scores = self.dropout(scores)\n",
        "        attention = torch.matmul(scores, V)\n",
        "        return attention, scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lYaxaPoVxjO"
      },
      "source": [
        "## 3.7\tMask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgCQGtwqVxO_"
      },
      "outputs": [],
      "source": [
        "class Mask(nn.Module):\n",
        "    def get_attn_pad_mask(self, seq_q, seq_k, pad=0):\n",
        "        batch_size, len_q = seq_q.size()\n",
        "        batch_size, len_k = seq_k.size()\n",
        "        pad_attn_mask = seq_k.data.eq(pad).unsqueeze(1)\n",
        "        return pad_attn_mask.expand(batch_size, len_q, len_k)\n",
        "\n",
        "    def get_attn_subsequence_mask(self, seq):\n",
        "        attn_shape = [seq.size(0), seq.size(1), seq.size(1)]\n",
        "        subsequence_mask = torch.triu(torch.ones(attn_shape), diagonal=1)\n",
        "        subsequence_mask.bool()\n",
        "        return subsequence_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiKOvwnl7QLO"
      },
      "source": [
        "## 3.8\tMulti-Head Attention\n",
        "\n",
        "Multi-head Attention is a module for attention mechanisms which runs through an attention mechanism several times in parallel. The independent attention outputs are then concatenated and linearly transformed into the expected dimension. It's defined as:\n",
        "\n",
        "$$Multihead(Q, K, V) = Concat(head_1, ..., head_h)\\cdot W$$\n",
        "\n",
        "where: $head_i = Attention(QW_i^Q, KW_i^K, VW_i^V)$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-07T15:34:33.687237Z",
          "iopub.status.busy": "2024-02-07T15:34:33.686920Z",
          "iopub.status.idle": "2024-02-07T15:34:33.697511Z",
          "shell.execute_reply": "2024-02-07T15:34:33.696783Z",
          "shell.execute_reply.started": "2024-02-07T15:34:33.687207Z"
        },
        "id": "y0SecFdX7evW"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model=d_model, n_heads=n_heads, d_k=d_k, d_v=d_v, dropout=0.2):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.d_model, self.n_heads = d_model, n_heads\n",
        "        self.d_k, self.d_v = d_k, d_v\n",
        "\n",
        "        self.W_Q = nn.Linear(d_model, self.d_k * self.n_heads, bias=False)\n",
        "        self.W_K = nn.Linear(d_model, self.d_k * self.n_heads, bias=False)\n",
        "        self.W_V = nn.Linear(d_model, self.d_v * self.n_heads, bias=False)\n",
        "\n",
        "        self.fc = nn.Linear(self.n_heads * self.d_v, d_model, bias=False)\n",
        "        self.ln = LayerNorm(self.d_model)\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, input_Q, input_K, input_V, attn_mask):\n",
        "        n_heads, d_k, d_v = self.n_heads, self.d_k, self.d_v\n",
        "        residual, batch_size = input_Q, input_Q.size(0)\n",
        "        Q = self.W_Q(input_Q).view(batch_size, -1, n_heads, d_k).transpose(1, 2)\n",
        "        K = self.W_K(input_K).view(batch_size, -1, n_heads, d_k).transpose(1, 2)\n",
        "        V = self.W_V(input_V).view(batch_size, -1, n_heads, d_v).transpose(1, 2)\n",
        "\n",
        "        attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1)\n",
        "        context, attn = ScaledDotProductAttention()(Q, K, V, attn_mask)\n",
        "        context = context.transpose(1, 2).reshape(batch_size, -1, n_heads * d_v)\n",
        "        output = self.dropout(self.fc(context))\n",
        "        return self.ln(output + residual), attn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJYWZb4FV-EB"
      },
      "source": [
        "## 3.9\tEncoder Layer and Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-07T15:34:33.699189Z",
          "iopub.status.busy": "2024-02-07T15:34:33.698628Z",
          "iopub.status.idle": "2024-02-07T15:34:33.716025Z",
          "shell.execute_reply": "2024-02-07T15:34:33.715446Z",
          "shell.execute_reply.started": "2024-02-07T15:34:33.699158Z"
        },
        "id": "etGtAasoaRwK"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.enc_self_attn = MultiHeadAttention()\n",
        "        self.pos_ffn = FeedForward(d_ff)\n",
        "\n",
        "    def forward(self, enc_inputs, enc_self_attn_mask):\n",
        "        enc_outputs, _i = self.enc_self_attn(enc_inputs, enc_inputs, enc_inputs, enc_self_attn_mask)\n",
        "        enc_outputs = self.pos_ffn(enc_outputs)\n",
        "        return enc_outputs\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.src_emb = nn.Embedding(vocab_size, d_model)\n",
        "        self.pos_emb = PositionalEncoding( d_model, max_len = vocab_size )\n",
        "        self.layers = nn.ModuleList([EncoderLayer() for _ in range(n_layers)])\n",
        "        self.mask = Mask()\n",
        "\n",
        "    def forward(self, enc_inputs):\n",
        "        enc_outputs = self.src_emb(enc_inputs)\n",
        "        enc_outputs = self.pos_emb(enc_outputs).to(device)\n",
        "        enc_self_attn_mask = self.mask.get_attn_pad_mask(enc_inputs, enc_inputs).to(device)\n",
        "        for layer in self.layers:\n",
        "            enc_outputs = layer(enc_outputs, enc_self_attn_mask)\n",
        "        return enc_outputs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrMQl7uwWLME"
      },
      "source": [
        "## 3.10\tDecoder Layer and Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuVtlgbiWFPj"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.dec_self_attn = MultiHeadAttention()\n",
        "        self.dec_enc_attn = MultiHeadAttention()\n",
        "        self.pos_ffn = FeedForward(d_ff)\n",
        "\n",
        "    def forward(self, dec_inputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask):\n",
        "        dec_outputs, _ = self.dec_self_attn(dec_inputs,\n",
        "                                            dec_inputs,\n",
        "                                            dec_inputs,\n",
        "                                            dec_self_attn_mask)\n",
        "\n",
        "        dec_outputs, _ = self.dec_enc_attn(dec_outputs,\n",
        "                                           enc_outputs,\n",
        "                                           enc_outputs,\n",
        "                                           dec_enc_attn_mask)\n",
        "\n",
        "        dec_outputs = self.pos_ffn(dec_outputs)\n",
        "        return dec_outputs\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.tgt_emb = nn.Embedding(vocab_size, d_model)\n",
        "        self.pos_emb = PositionalEncoding(d_model, max_len = vocab_size )\n",
        "        self.layers = nn.ModuleList([DecoderLayer() for _ in range(n_layers)])\n",
        "        self.mask = Mask()\n",
        "\n",
        "    def forward(self, dec_inputs, enc_inputs, enc_outputs):\n",
        "        dec_outputs = self.tgt_emb(dec_inputs)\n",
        "        dec_outputs = self.pos_emb(dec_outputs).to(device)\n",
        "        dec_self_attn_pad_mask = self.mask.get_attn_pad_mask(dec_inputs, dec_inputs).to(device)\n",
        "        dec_self_attn_subsequence_mask = self.mask.get_attn_subsequence_mask(dec_inputs).to(device)\n",
        "        dec_self_attn_mask = torch.gt((dec_self_attn_pad_mask + dec_self_attn_subsequence_mask), 0).to(device)\n",
        "        dec_enc_attn_mask = self.mask.get_attn_pad_mask(dec_inputs, enc_inputs)\n",
        "\n",
        "        for layer in self.layers:\n",
        "            dec_outputs = layer(dec_outputs, enc_outputs,\n",
        "                                dec_self_attn_mask, dec_enc_attn_mask)\n",
        "        return dec_outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3b61_LmWTNF"
      },
      "source": [
        "## 3.11\tTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDEnH3ryWXBx"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.encoder = Encoder().to(device)\n",
        "        self.decoder = Decoder().to(device)\n",
        "        self.projection = nn.Linear(\n",
        "            d_model, vocab_size, bias=False).to(device)\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, enc_inputs, dec_inputs):\n",
        "        enc_outputs = self.encoder(enc_inputs)\n",
        "        dec_outputs = self.decoder(dec_inputs, enc_inputs, enc_outputs)\n",
        "        dec_logits = self.projection(dec_outputs)\n",
        "        return dec_logits.view(-1, dec_logits.size(-1))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_Gu656Lh-41"
      },
      "source": [
        "## 3.12\tTraining"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-02-07T15:34:33.717475Z",
          "iopub.status.busy": "2024-02-07T15:34:33.716858Z",
          "iopub.status.idle": "2024-02-07T15:34:36.936404Z",
          "shell.execute_reply": "2024-02-07T15:34:36.935476Z",
          "shell.execute_reply.started": "2024-02-07T15:34:33.717442Z"
        },
        "id": "imxC3WKqsect",
        "outputId": "c7e3920a-2d3a-4726-8210-2ec01068f8f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameters of the model: 44,324,352\n"
          ]
        }
      ],
      "source": [
        "model = Transformer().to(device)\n",
        "# print the number of parameters in the model\n",
        "total_parameter = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Parameters of the model: {total_parameter:,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LETt98SbL2qg",
        "outputId": "33a07130-0ef6-40f4-e408-9196f6651fee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transformer(\n",
            "  (encoder): Encoder(\n",
            "    (src_emb): Embedding(165, 512)\n",
            "    (pos_emb): PositionalEncoding(\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (layers): ModuleList(\n",
            "      (0-5): 6 x EncoderLayer(\n",
            "        (enc_self_attn): MultiHeadAttention(\n",
            "          (W_Q): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (W_K): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (W_V): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (fc): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (ln): LayerNorm()\n",
            "          (dropout): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (pos_ffn): FeedForward(\n",
            "          (fc): Sequential(\n",
            "            (0): Linear(in_features=512, out_features=2048, bias=False)\n",
            "            (1): ReLU()\n",
            "            (2): Dropout(p=0.2, inplace=False)\n",
            "            (3): Linear(in_features=2048, out_features=512, bias=False)\n",
            "          )\n",
            "          (ln): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (mask): Mask()\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (tgt_emb): Embedding(165, 512)\n",
            "    (pos_emb): PositionalEncoding(\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (layers): ModuleList(\n",
            "      (0-5): 6 x DecoderLayer(\n",
            "        (dec_self_attn): MultiHeadAttention(\n",
            "          (W_Q): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (W_K): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (W_V): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (fc): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (ln): LayerNorm()\n",
            "          (dropout): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (dec_enc_attn): MultiHeadAttention(\n",
            "          (W_Q): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (W_K): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (W_V): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (fc): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (ln): LayerNorm()\n",
            "          (dropout): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (pos_ffn): FeedForward(\n",
            "          (fc): Sequential(\n",
            "            (0): Linear(in_features=512, out_features=2048, bias=False)\n",
            "            (1): ReLU()\n",
            "            (2): Dropout(p=0.2, inplace=False)\n",
            "            (3): Linear(in_features=2048, out_features=512, bias=False)\n",
            "          )\n",
            "          (ln): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (mask): Mask()\n",
            "  )\n",
            "  (projection): Linear(in_features=512, out_features=165, bias=False)\n",
            "  (softmax): Softmax(dim=-1)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Print out the structure of the Transformer model\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cD3MvOPjLz0k"
      },
      "outputs": [],
      "source": [
        "# Loss function to ignore the word \"<P>\" which marks the end of a sentance.\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.encode_word(\"<PAD>\"))\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.99)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-02-07T15:34:36.938024Z",
          "iopub.status.busy": "2024-02-07T15:34:36.937721Z",
          "iopub.status.idle": "2024-02-07T15:34:48.692417Z",
          "shell.execute_reply": "2024-02-07T15:34:48.691439Z",
          "shell.execute_reply.started": "2024-02-07T15:34:36.938000Z"
        },
        "id": "H3owjVGGh-TS",
        "outputId": "90cd30e9-07c9-44ca-f21d-e254cbe6e9af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1/1 loss = 5.287929\n",
            "Epoch: 2/1 loss = 5.311439\n",
            "Epoch: 1/2 loss = 5.269698\n",
            "Epoch: 2/2 loss = 5.221197\n",
            "Epoch: 1/3 loss = 5.091483\n",
            "Epoch: 2/3 loss = 4.971140\n",
            "Epoch: 1/4 loss = 4.875039\n",
            "Epoch: 2/4 loss = 4.724355\n",
            "Epoch: 1/5 loss = 4.603537\n",
            "Epoch: 2/5 loss = 4.648115\n",
            "Epoch: 1/6 loss = 4.632385\n",
            "Epoch: 2/6 loss = 4.540625\n",
            "Epoch: 1/7 loss = 4.617230\n",
            "Epoch: 2/7 loss = 4.416563\n",
            "Epoch: 1/8 loss = 4.468247\n",
            "Epoch: 2/8 loss = 4.396354\n",
            "Epoch: 1/9 loss = 4.325214\n",
            "Epoch: 2/9 loss = 4.272070\n",
            "Epoch: 1/10 loss = 4.106295\n",
            "Epoch: 2/10 loss = 4.223099\n",
            "Epoch: 1/11 loss = 4.048274\n",
            "Epoch: 2/11 loss = 4.176879\n",
            "Epoch: 1/12 loss = 4.253008\n",
            "Epoch: 2/12 loss = 4.038174\n",
            "Epoch: 1/13 loss = 4.061224\n",
            "Epoch: 2/13 loss = 4.140215\n",
            "Epoch: 1/14 loss = 3.923703\n",
            "Epoch: 2/14 loss = 4.102123\n",
            "Epoch: 1/15 loss = 4.010431\n",
            "Epoch: 2/15 loss = 3.888305\n",
            "Epoch: 1/16 loss = 3.996034\n",
            "Epoch: 2/16 loss = 3.572001\n",
            "Epoch: 1/17 loss = 3.788305\n",
            "Epoch: 2/17 loss = 3.476843\n",
            "Epoch: 1/18 loss = 3.626752\n",
            "Epoch: 2/18 loss = 3.450371\n",
            "Epoch: 1/19 loss = 3.259271\n",
            "Epoch: 2/19 loss = 3.525586\n",
            "Epoch: 1/20 loss = 3.184514\n",
            "Epoch: 2/20 loss = 3.315380\n",
            "Epoch: 1/21 loss = 3.204475\n",
            "Epoch: 2/21 loss = 3.051541\n",
            "Epoch: 1/22 loss = 2.770556\n",
            "Epoch: 2/22 loss = 3.142549\n",
            "Epoch: 1/23 loss = 2.992424\n",
            "Epoch: 2/23 loss = 2.556006\n",
            "Epoch: 1/24 loss = 2.799628\n",
            "Epoch: 2/24 loss = 2.494216\n",
            "Epoch: 1/25 loss = 2.573174\n",
            "Epoch: 2/25 loss = 2.489640\n",
            "Epoch: 1/26 loss = 2.568467\n",
            "Epoch: 2/26 loss = 2.206557\n",
            "Epoch: 1/27 loss = 2.247065\n",
            "Epoch: 2/27 loss = 2.220347\n",
            "Epoch: 1/28 loss = 2.101354\n",
            "Epoch: 2/28 loss = 2.117148\n",
            "Epoch: 1/29 loss = 1.886189\n",
            "Epoch: 2/29 loss = 2.059917\n",
            "Epoch: 1/30 loss = 1.845963\n",
            "Epoch: 2/30 loss = 1.808671\n",
            "Epoch: 1/31 loss = 1.640157\n",
            "Epoch: 2/31 loss = 1.772881\n",
            "Epoch: 1/32 loss = 1.456914\n",
            "Epoch: 2/32 loss = 1.630389\n",
            "Epoch: 1/33 loss = 1.648644\n",
            "Epoch: 2/33 loss = 1.219104\n",
            "Epoch: 1/34 loss = 1.518416\n",
            "Epoch: 2/34 loss = 1.245993\n",
            "Epoch: 1/35 loss = 1.187993\n",
            "Epoch: 2/35 loss = 1.340905\n",
            "Epoch: 1/36 loss = 1.176254\n",
            "Epoch: 2/36 loss = 1.143967\n",
            "Epoch: 1/37 loss = 1.191800\n",
            "Epoch: 2/37 loss = 1.022474\n",
            "Epoch: 1/38 loss = 1.088858\n",
            "Epoch: 2/38 loss = 0.804135\n",
            "Epoch: 1/39 loss = 0.937076\n",
            "Epoch: 2/39 loss = 0.855595\n",
            "Epoch: 1/40 loss = 0.896591\n",
            "Epoch: 2/40 loss = 0.824058\n",
            "Epoch: 1/41 loss = 0.784449\n",
            "Epoch: 2/41 loss = 0.779253\n",
            "Epoch: 1/42 loss = 0.661985\n",
            "Epoch: 2/42 loss = 0.729432\n",
            "Epoch: 1/43 loss = 0.687736\n",
            "Epoch: 2/43 loss = 0.533219\n",
            "Epoch: 1/44 loss = 0.522538\n",
            "Epoch: 2/44 loss = 0.603397\n",
            "Epoch: 1/45 loss = 0.489567\n",
            "Epoch: 2/45 loss = 0.555553\n",
            "Epoch: 1/46 loss = 0.472481\n",
            "Epoch: 2/46 loss = 0.501816\n",
            "Epoch: 1/47 loss = 0.474101\n",
            "Epoch: 2/47 loss = 0.461981\n",
            "Epoch: 1/48 loss = 0.431965\n",
            "Epoch: 2/48 loss = 0.425920\n",
            "Epoch: 1/49 loss = 0.360771\n",
            "Epoch: 2/49 loss = 0.440516\n",
            "Epoch: 1/50 loss = 0.353846\n",
            "Epoch: 2/50 loss = 0.361045\n",
            "Epoch: 1/51 loss = 0.322202\n",
            "Epoch: 2/51 loss = 0.346188\n",
            "Epoch: 1/52 loss = 0.329961\n",
            "Epoch: 2/52 loss = 0.269555\n",
            "Epoch: 1/53 loss = 0.316618\n",
            "Epoch: 2/53 loss = 0.235680\n",
            "Epoch: 1/54 loss = 0.276313\n",
            "Epoch: 2/54 loss = 0.236808\n",
            "Epoch: 1/55 loss = 0.256006\n",
            "Epoch: 2/55 loss = 0.285598\n",
            "Epoch: 1/56 loss = 0.254297\n",
            "Epoch: 2/56 loss = 0.250445\n",
            "Epoch: 1/57 loss = 0.260586\n",
            "Epoch: 2/57 loss = 0.194334\n",
            "Epoch: 1/58 loss = 0.208097\n",
            "Epoch: 2/58 loss = 0.194574\n",
            "Epoch: 1/59 loss = 0.206853\n",
            "Epoch: 2/59 loss = 0.175436\n",
            "Epoch: 1/60 loss = 0.192244\n",
            "Epoch: 2/60 loss = 0.142999\n",
            "Epoch: 1/61 loss = 0.197726\n",
            "Epoch: 2/61 loss = 0.128614\n",
            "Epoch: 1/62 loss = 0.131353\n",
            "Epoch: 2/62 loss = 0.162500\n",
            "Epoch: 1/63 loss = 0.157177\n",
            "Epoch: 2/63 loss = 0.128365\n",
            "Epoch: 1/64 loss = 0.134771\n",
            "Epoch: 2/64 loss = 0.119200\n",
            "Epoch: 1/65 loss = 0.146782\n",
            "Epoch: 2/65 loss = 0.128344\n",
            "Epoch: 1/66 loss = 0.144906\n",
            "Epoch: 2/66 loss = 0.114640\n",
            "Epoch: 1/67 loss = 0.124875\n",
            "Epoch: 2/67 loss = 0.120901\n",
            "Epoch: 1/68 loss = 0.128059\n",
            "Epoch: 2/68 loss = 0.103824\n",
            "Epoch: 1/69 loss = 0.104504\n",
            "Epoch: 2/69 loss = 0.123268\n",
            "Epoch: 1/70 loss = 0.079715\n",
            "Epoch: 2/70 loss = 0.120156\n",
            "Epoch: 1/71 loss = 0.099544\n",
            "Epoch: 2/71 loss = 0.096966\n",
            "Epoch: 1/72 loss = 0.099707\n",
            "Epoch: 2/72 loss = 0.084047\n",
            "Epoch: 1/73 loss = 0.110094\n",
            "Epoch: 2/73 loss = 0.074824\n",
            "Epoch: 1/74 loss = 0.072290\n",
            "Epoch: 2/74 loss = 0.092359\n",
            "Epoch: 1/75 loss = 0.114285\n",
            "Epoch: 2/75 loss = 0.058999\n",
            "Epoch: 1/76 loss = 0.092696\n",
            "Epoch: 2/76 loss = 0.060570\n",
            "Epoch: 1/77 loss = 0.069796\n",
            "Epoch: 2/77 loss = 0.067762\n",
            "Epoch: 1/78 loss = 0.060657\n",
            "Epoch: 2/78 loss = 0.064434\n",
            "Epoch: 1/79 loss = 0.043216\n",
            "Epoch: 2/79 loss = 0.078731\n",
            "Epoch: 1/80 loss = 0.066734\n",
            "Epoch: 2/80 loss = 0.051932\n",
            "Epoch: 1/81 loss = 0.055470\n",
            "Epoch: 2/81 loss = 0.052142\n",
            "Epoch: 1/82 loss = 0.057437\n",
            "Epoch: 2/82 loss = 0.056823\n",
            "Epoch: 1/83 loss = 0.043306\n",
            "Epoch: 2/83 loss = 0.070773\n",
            "Epoch: 1/84 loss = 0.044780\n",
            "Epoch: 2/84 loss = 0.051216\n",
            "Epoch: 1/85 loss = 0.070910\n",
            "Epoch: 2/85 loss = 0.036528\n",
            "Epoch: 1/86 loss = 0.058736\n",
            "Epoch: 2/86 loss = 0.032676\n",
            "Epoch: 1/87 loss = 0.048161\n",
            "Epoch: 2/87 loss = 0.039298\n",
            "Epoch: 1/88 loss = 0.044150\n",
            "Epoch: 2/88 loss = 0.045202\n",
            "Epoch: 1/89 loss = 0.050738\n",
            "Epoch: 2/89 loss = 0.037626\n",
            "Epoch: 1/90 loss = 0.038353\n",
            "Epoch: 2/90 loss = 0.035622\n",
            "Epoch: 1/91 loss = 0.044055\n",
            "Epoch: 2/91 loss = 0.033469\n",
            "Epoch: 1/92 loss = 0.032956\n",
            "Epoch: 2/92 loss = 0.049349\n",
            "Epoch: 1/93 loss = 0.029021\n",
            "Epoch: 2/93 loss = 0.042390\n",
            "Epoch: 1/94 loss = 0.052200\n",
            "Epoch: 2/94 loss = 0.028652\n",
            "Epoch: 1/95 loss = 0.024939\n",
            "Epoch: 2/95 loss = 0.033353\n",
            "Epoch: 1/96 loss = 0.036572\n",
            "Epoch: 2/96 loss = 0.049452\n",
            "Epoch: 1/97 loss = 0.029343\n",
            "Epoch: 2/97 loss = 0.036125\n",
            "Epoch: 1/98 loss = 0.030349\n",
            "Epoch: 2/98 loss = 0.026917\n",
            "Epoch: 1/99 loss = 0.022779\n",
            "Epoch: 2/99 loss = 0.037383\n",
            "Epoch: 1/100 loss = 0.033631\n",
            "Epoch: 2/100 loss = 0.024829\n"
          ]
        }
      ],
      "source": [
        "history_loss = []\n",
        "for epoch in range(epochs):\n",
        "    for i, [enc_inputs, dec_inputs, dec_outputs] in enumerate(loader):\n",
        "        enc_inputs =  enc_inputs.to(device)\n",
        "        dec_inputs =  dec_inputs.to(device)\n",
        "        dec_outputs = dec_outputs.to(device)\n",
        "        outputs = model(enc_inputs, dec_inputs)\n",
        "        loss = criterion(outputs, dec_outputs.view(-1))\n",
        "\n",
        "        print('Epoch:', '%d/%d' % (i+1, epoch+1), 'loss =', '{:.6f}'.format(loss))\n",
        "        history_loss.append(loss.item())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKBRspyrDrgG"
      },
      "source": [
        "### Visualize the train losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "execution": {
          "iopub.execute_input": "2024-02-07T15:34:48.694683Z",
          "iopub.status.busy": "2024-02-07T15:34:48.693769Z",
          "iopub.status.idle": "2024-02-07T15:34:49.519319Z",
          "shell.execute_reply": "2024-02-07T15:34:49.518483Z",
          "shell.execute_reply.started": "2024-02-07T15:34:48.694651Z"
        },
        "id": "wUnc4Qq0gQc8",
        "outputId": "e022131b-f9dc-43b0-f893-8d98924040f9"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.title(\"Loss During Training\")\n",
        "plt.plot(history_loss, label=\"Train Loss\", c='k', lw=2)\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.savefig(\"Training.svg\", format=\"svg\", dpi=150, transparent=True, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYE6AmJKiFbO"
      },
      "source": [
        "## 3.13\tInference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-07T15:34:49.521350Z",
          "iopub.status.busy": "2024-02-07T15:34:49.520543Z",
          "iopub.status.idle": "2024-02-07T15:34:49.528747Z",
          "shell.execute_reply": "2024-02-07T15:34:49.527950Z",
          "shell.execute_reply.started": "2024-02-07T15:34:49.521323Z"
        },
        "id": "1E5HTj2DexJq",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def Greedy(logits):\n",
        "    return torch.argmax(logits, dim=-1, keepdim=False)\n",
        "\n",
        "def RandomSampling(logits, k=5):\n",
        "    top_k_probs, _ = torch.topk(logits, k, dim=-1)\n",
        "    kth_highest_prob = top_k_probs[:, -1].unsqueeze(-1)\n",
        "    mask = logits < kth_highest_prob\n",
        "    probs = logits.masked_fill(mask, 0)\n",
        "    return torch.multinomial(probs, num_samples=1).squeeze(-1)\n",
        "\n",
        "def Inference(model, enc_input, start_token, end_token, max_len=32, topk=None):\n",
        "    enc_outputs = model.encoder(enc_input)\n",
        "    dec_input = torch.zeros(1, 0).type_as(enc_input.data)\n",
        "    next_token = start_token\n",
        "    cnt = 0\n",
        "    while next_token != end_token and cnt < max_len:\n",
        "        dec_input = torch.cat([dec_input.to(device),\n",
        "                               torch.tensor([[next_token]], dtype=enc_input.dtype).to(device)], -1)\n",
        "        dec_outputs = model.decoder(dec_input, enc_input, enc_outputs)\n",
        "        projected = model.projection(dec_outputs)\n",
        "        projected = model.softmax(projected)\n",
        "        if topk == None:\n",
        "          prob = Greedy(projected.squeeze(0))\n",
        "        else:\n",
        "          prob = RandomSampling(projected.squeeze(0), topk)\n",
        "        next_word = prob.data[-1]\n",
        "        next_token = next_word\n",
        "        cnt += 1\n",
        "    return prob\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-02-07T15:34:49.530069Z",
          "iopub.status.busy": "2024-02-07T15:34:49.529772Z",
          "iopub.status.idle": "2024-02-07T15:34:51.925457Z",
          "shell.execute_reply": "2024-02-07T15:34:51.924397Z",
          "shell.execute_reply.started": "2024-02-07T15:34:49.530050Z"
        },
        "id": "piRD2M7gbFFI",
        "outputId": "bc0cb590-9536-40dc-844b-a4f722dae055",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Where turtles lay eggs? -> Holes dug into mud or sand. \n",
            "How Isabelline penguins different? -> Because they are born with brown rather than black plumage. \n",
            "How do otters keep warm? -> A layer of air trapped in their fur. \n",
            "How similar between the beetles and the grasshoppers? -> Beetles have mouthparts mouthparts that are similar to those of the grasshoppers. \n",
            "Can infrared photography seen polar bears? -> Polar bears are nearly invisible under infrared photography. \n",
            "How long do penguins on land? -> They spend half of their life on land. \n",
            "DNA evidence and fossil tell us What? -> The polar bear diverged from the brown bear roughly 200 thousand years ago. \n",
            "What years do turtles breed? -> Every few years or more. \n",
            "are cougar males heavier than females? -> On average the cougar males are heavier than the females. \n",
            "Beetles eat What? -> They often feed on plants and fungi, break down animal and plant debris, and eat other invertebrates. \n",
            "How similar between beetles and grasshoppers? -> Beetles have mouthparts similar to those of grasshoppers. \n",
            "How do elephants communicate over distances? -> By producing and receiving low-frequency sound or infrasound. \n",
            "What do penguins agile in water? -> Smooth plumage preserves a layer of air, ensuring buoyancy, wings are flippers. \n",
            "What sections do beetles have? -> They often feed on plants and fungi, break down animal and plant debris, and eat other invertebrates. \n",
            "What animal larger than elephant? -> None, the elephant is the largest land animal in the world. \n",
            "What elephants weight at birth? -> At birth it is common for an elephant calf to weigh 120 kilograms or 265 lb. \n"
          ]
        }
      ],
      "source": [
        "evaluation = [\n",
        "  ['How similar between the beetles and the grasshoppers?', ''],\n",
        "  ['What animal larger than elephant?', ''],\n",
        "  ['What years do turtles breed?',  ''],\n",
        "  ['Where turtles lay eggs?', ''],\n",
        "  ['How do otters keep warm?', ''],\n",
        "  ['How long do penguins on land?', ''],\n",
        "  ['What sections do beetles have?', ''],\n",
        "  ['Can infrared photography seen polar bears?', ''],\n",
        "  ['DNA evidence and fossil tell us What?', ''],\n",
        "  ['are cougar males heavier than females?', ''],\n",
        "  ['How Isabelline penguins different?', ''],\n",
        "  ['Beetles eat What?', ''],\n",
        "  ['How similar between beetles and grasshoppers?', ''],\n",
        "  ['What elephants weight at birth?', ''],\n",
        "  ['How do elephants communicate over distances?', ''],\n",
        "  ['What do penguins agile in water?', ''],\n",
        "]\n",
        "\n",
        "evl_enc_inputs, _, _ = make_data(evaluation)\n",
        "evl_loader = Data.DataLoader(DataSet([evl_enc_inputs]), 16, True)\n",
        "[evl_enc_inputs] = next(iter(evl_loader))\n",
        "\n",
        "for i in range(len(evl_enc_inputs)):\n",
        "    predict = Inference(model,\n",
        "                        evl_enc_inputs[i].view(1, -1).to(device),\n",
        "                        start_token=tokenizer.encode_word(\"<SOS>\"),\n",
        "                        end_token=tokenizer.encode_word(\"<EOS>\"),\n",
        "                        topk=None)\n",
        "    q = evl_enc_inputs[i].tolist()\n",
        "    q = [x for x in q if x != tokenizer.encode_word(\"<PAD>\")]\n",
        "    question = tokenizer.decode_text(q)\n",
        "    answer = tokenizer.decode_text(predict.tolist())\n",
        "    question = question.replace(\" ?\", \"?\")\n",
        "    answer = answer.replace(\" .\", \".\").replace(\"<EOS>\", \"\")\n",
        "    print(question, '->', answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvV7q0mcreU9"
      },
      "source": [
        "## References:\n",
        "\n",
        "1.   *https://nlp.seas.harvard.edu/annotated-transformer/*\n",
        "1.   *https://github.com/jadore801120/attention-is-all-you-need-pytorch*\n",
        "2.   *https://github.com/JayParks/transformer*\n",
        "3.   *https://www.freecodecamp.org/news/how-to-build-a-large-language-model-from-scratch-using-python/*\n",
        "4.   *https://mdnice.com/writing/fc0b920d4ca84837a5712df1a46865d2*"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "saturn (Python 3)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
