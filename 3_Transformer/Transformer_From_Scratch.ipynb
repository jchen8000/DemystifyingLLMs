{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jchen8000/GenerativeAI/blob/main/3_Transformer/Transformer_From_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pOZYVPlaZKc"
      },
      "source": [
        "# 3. Transformer\n",
        "\n",
        "Implementation from scratch\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-07T15:34:32.884111Z",
          "iopub.status.busy": "2024-02-07T15:34:32.883611Z",
          "iopub.status.idle": "2024-02-07T15:34:33.439490Z",
          "shell.execute_reply": "2024-02-07T15:34:33.438856Z",
          "shell.execute_reply.started": "2024-02-07T15:34:32.884070Z"
        },
        "id": "KEfH4u-FhLXL"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as Data\n",
        "from torch.nn.utils.rnn import pad_sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-07T15:34:33.441304Z",
          "iopub.status.busy": "2024-02-07T15:34:33.440944Z",
          "iopub.status.idle": "2024-02-07T15:34:33.626221Z",
          "shell.execute_reply": "2024-02-07T15:34:33.625190Z",
          "shell.execute_reply.started": "2024-02-07T15:34:33.441284Z"
        },
        "id": "lSmV26jwhZUp"
      },
      "outputs": [],
      "source": [
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "epochs = 100\n",
        "torch.manual_seed(999)\n",
        "batch_size = 8\n",
        "learning_rate=1e-3\n",
        "d_model = 512\n",
        "d_ff = 2048\n",
        "d_k = d_v = 64\n",
        "n_layers = 6\n",
        "n_heads = 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xi73ByZMhcS0"
      },
      "source": [
        "## 3.1\tDataset and Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-07T15:34:33.627713Z",
          "iopub.status.busy": "2024-02-07T15:34:33.627404Z",
          "iopub.status.idle": "2024-02-07T15:34:33.637258Z",
          "shell.execute_reply": "2024-02-07T15:34:33.636562Z",
          "shell.execute_reply.started": "2024-02-07T15:34:33.627690Z"
        },
        "id": "2SzlBKRlDkge"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# Question and Answer Dataset\n",
        "# https://www.kaggle.com/datasets/rtatman/questionanswer-dataset/\n",
        "# File: S08_question_answer_pairs.txt\n",
        "#\n",
        "question_answer = [\n",
        "  ['What are the similarities between the beetles and the grasshoppers?',  'Beetles have the mouthparts that are similar to those of the grasshoppers.'],\n",
        "  ['What land animal is larger than an elephant?',  'None, the elephant is the largest land animal in the world.'],\n",
        "  ['How often do turtles breed?',  'Every few years or more.'],\n",
        "  ['Where do sea turtles lay their eggs?',  'Holes dug into mud or sand.'],\n",
        "  ['How do otters keep themselves warm without blubber?',  'A layer of air trapped in their fur.'],\n",
        "  ['How much time to penguins spend on land?',  'They spend half of their life on land.'],\n",
        "  ['What are the three sections of a beetle?',  'The head, the thorax, and the abdomen.'],\n",
        "  ['Can polar bears be seen under infrared photography?',  'Polar bears are nearly invisible under infrared photography.'],\n",
        "  ['What do fossil and DNA evidence tell us?',  'The polar bear diverged from the brown bear roughly 200 thousand years ago.'],\n",
        "  ['On average are cougar males heavier than females?',\t'On average the cougar males are heavier than the females.'],\n",
        "  ['How are Isabelline penguins different from most penguins?',  'Because they are born with brown rather than black plumage.'],\n",
        "  ['What do beetles eat?',  'They often feed on plants and fungi, break down animal and plant debris, and eat other invertebrates.'],\n",
        "  ['What are the similarities between beetles and grasshoppers?',  'Beetles have mouthparts similar to those of grasshoppers.'],\n",
        "  ['How much do elephants weight at birth?',  'At birth it is common for an elephant calf to weigh 120 kilograms or 265 lb.'],\n",
        "  ['How do elephants communicate over long distances?',  'By producing and receiving low-frequency sound or infrasound.'],\n",
        "  ['What makes penguins so agile in the water?',  'Smooth plumage preserves a layer of air, ensuring buoyancy, wings are flippers.'],\n",
        "]\n",
        "\n",
        "texts = []\n",
        "for que_text, ans_text in question_answer:\n",
        "  text = que_text.replace('?', ' ?')\n",
        "  texts.extend(text.split())\n",
        "  text = ans_text.replace('.', ' .')\n",
        "  texts.extend(text.split())\n",
        "\n",
        "# Special tokens:\n",
        "#   <PAD>: Padding token\n",
        "#   <UNK>: Unknown token\n",
        "#   <SOS>: Start-of-Sequence token\n",
        "#   <EOS>: End-of-Sequence token\n",
        "words = sorted(list(set(texts)))\n",
        "words = ['<PAD>', '<UNK>','<SOS>','<EOS>'] + words\n",
        "\n",
        "class Tokenizer():\n",
        "    def __init__(self, vocabulary):\n",
        "      self.idx2word = {index:word for index, word in enumerate(vocabulary)}\n",
        "      self.word2idx = {word:index for index, word in enumerate(vocabulary)}\n",
        "\n",
        "    def get_vocab_size(self):\n",
        "      return len(self.idx2word)\n",
        "\n",
        "    def encode(self, text):\n",
        "      return [self.word2idx[w] for w in text.split()]\n",
        "\n",
        "    def encode_word(self, char):\n",
        "      return self.word2idx[char]\n",
        "\n",
        "    def decode(self, encoded_text):\n",
        "      return [self.idx2word[i] for i in encoded_text]\n",
        "\n",
        "    def decode_text(self, encoded_text):\n",
        "      s = self.decode(encoded_text)\n",
        "      return (\" \".join(s))\n",
        "\n",
        "tokenizer = Tokenizer(words)\n",
        "\n",
        "vocab_size = tokenizer.get_vocab_size()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-07T15:34:33.638532Z",
          "iopub.status.busy": "2024-02-07T15:34:33.638202Z",
          "iopub.status.idle": "2024-02-07T15:34:33.645310Z",
          "shell.execute_reply": "2024-02-07T15:34:33.644692Z",
          "shell.execute_reply.started": "2024-02-07T15:34:33.638509Z"
        },
        "id": "DqYpyC-hx32X"
      },
      "outputs": [],
      "source": [
        "def make_data(sentences):\n",
        "    enc_inputs, dec_inputs, dec_outputs = [], [], []\n",
        "\n",
        "    for i in range(len(sentences)):\n",
        "        que_text = sentences[i][0].replace('?', ' ?')\n",
        "        ans_text_inp = '<SOS> ' + sentences[i][1].replace('.', ' .')\n",
        "        ans_text_out = sentences[i][1].replace('.', ' .') + ' <EOS>'\n",
        "\n",
        "        enc_input = tokenizer.encode(que_text)\n",
        "        dec_input = tokenizer.encode(ans_text_inp)\n",
        "        dec_output = tokenizer.encode(ans_text_out)\n",
        "\n",
        "        enc_inputs.append(torch.LongTensor(enc_input))\n",
        "        dec_inputs.append(torch.LongTensor(dec_input))\n",
        "        dec_outputs.append(torch.LongTensor(dec_output))\n",
        "\n",
        "    return pad_sequence(enc_inputs, batch_first=True), pad_sequence(dec_inputs, batch_first=True), pad_sequence(dec_outputs, batch_first=True)\n",
        "\n",
        "enc_inputs, dec_inputs, dec_outputs = make_data(question_answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-07T15:34:33.646453Z",
          "iopub.status.busy": "2024-02-07T15:34:33.646190Z",
          "iopub.status.idle": "2024-02-07T15:34:33.651417Z",
          "shell.execute_reply": "2024-02-07T15:34:33.650722Z",
          "shell.execute_reply.started": "2024-02-07T15:34:33.646433Z"
        },
        "id": "FiCnFu94bLvR"
      },
      "outputs": [],
      "source": [
        "class DataSet(Data.Dataset):\n",
        "    def __init__(self, data):\n",
        "        super(DataSet, self).__init__()\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data[0].shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return [x[idx] for x in self.data]\n",
        "\n",
        "loader = Data.DataLoader( DataSet([enc_inputs, dec_inputs, dec_outputs]), batch_size, True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDNliX5jkzBW"
      },
      "source": [
        "## 3.3\tPositional Encoding\n",
        "\n",
        "Based on the paper [Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf), Positional Encoding is defined as:\n",
        "\n",
        "$PE_{(pos, 2i)}=\\sin{\\left( \\frac{pos}{10000^{2i/d_{model}}} \\right)}$\n",
        "\n",
        "$PE_{pos, 2i+1}=\\cos{\\left( \\frac{pos}{10000^{2i/d_{model}}} \\right)}$\n",
        "\n",
        "where:\n",
        "\n",
        "$pos$: is the position of an item in the input sequence, $0 \\leqslant  pos \\lt  \\frac{len(input)}{2}$\n",
        "\n",
        "$d_{model}$: Dimension of the embedding space\n",
        "\n",
        "It's implemented as below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-07T15:34:33.657631Z",
          "iopub.status.busy": "2024-02-07T15:34:33.657382Z",
          "iopub.status.idle": "2024-02-07T15:34:33.663297Z",
          "shell.execute_reply": "2024-02-07T15:34:33.662715Z",
          "shell.execute_reply.started": "2024-02-07T15:34:33.657611Z"
        },
        "id": "THZpnXDWkzj8"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000, dropout=0.1):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe_table', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe_table[:, :x.size(1), :]\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqMmq8I4qmPO"
      },
      "source": [
        "## 3.4\tLayer Normalization\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jptWah-wgSv"
      },
      "source": [
        "**Layer Normalization** is based on the paper of [Layer Normalization](https://arxiv.org/abs/1607.06450), it can be implemented with *torch.nn.LayerNorm()*.\n",
        "\n",
        "Here we do our implementation, it is defined as:\n",
        "\n",
        "$$y = \\displaystyle \\frac{x-E\\left[ x \\right]}{\\sqrt{Var\\left[ x \\right]+\\epsilon}}\\ast \\gamma + \\beta$$\n",
        "\n",
        "\n",
        "\n",
        "$E$ is the mean of $x$,\n",
        "\n",
        "$Var$ is the standard-deviation of $x$\n",
        "\n",
        "Both mean and standard-deviation are calculated over the last dimension of $x$, and calculated by:\n",
        "\n",
        "```\n",
        "mean = x.mean(dim = -1, keepdim = True),\n",
        "std = x.std(dim = -1, keepdim = True)\n",
        "```\n",
        "\n",
        "$\\gamma$ and $\\beta$ are learnable parameters.\n",
        "\n",
        "$\\epsilon$ is to prevent dividing by zero or when std is near zero, default is 1e-5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-07T15:34:33.664936Z",
          "iopub.status.busy": "2024-02-07T15:34:33.664262Z",
          "iopub.status.idle": "2024-02-07T15:34:33.671214Z",
          "shell.execute_reply": "2024-02-07T15:34:33.670509Z",
          "shell.execute_reply.started": "2024-02-07T15:34:33.664905Z"
        },
        "id": "sm4M8wj3wWXX"
      },
      "outputs": [],
      "source": [
        "class LayerNorm(nn.Module):\n",
        "\n",
        "    def __init__(self, features, eps=1e-5) -> None:\n",
        "        super(LayerNorm, self).__init__()\n",
        "        self.eps = eps\n",
        "        self.gamma = nn.Parameter(torch.ones(features)) # gamma is a learnable parameter\n",
        "        self.beta = nn.Parameter(torch.zeros(features)) # beta is a learnable parameter\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim = -1, keepdim = True)\n",
        "        std = x.std(dim = -1, keepdim = True)\n",
        "        return self.gamma * (x - mean) / (std + self.eps) + self.beta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVdh0F150UG6"
      },
      "source": [
        "## 3.5\tFeed Forward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ts89I1gq10V6"
      },
      "source": [
        "**Position-wise Feed-Forward Networks**, based on the paper [Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf), is defined as:\n",
        "\n",
        "$$FFN(x) = \\max(0, xW_1 + b_1)W_2 + b_2$$\n",
        "\n",
        "This consists of two linear transformations with a *ReLU* activation in between.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-07T15:34:33.672527Z",
          "iopub.status.busy": "2024-02-07T15:34:33.672216Z",
          "iopub.status.idle": "2024-02-07T15:34:33.678661Z",
          "shell.execute_reply": "2024-02-07T15:34:33.677834Z",
          "shell.execute_reply.started": "2024-02-07T15:34:33.672498Z"
        },
        "id": "9kltvC5jq1vA"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_ff, dropout=0.2):\n",
        "        super(FeedForward, self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(d_model, d_ff, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(d_ff, d_model, bias=False)\n",
        "        )\n",
        "        self.ln = LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        output = self.fc(x)\n",
        "        return self.ln(output+residual)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZn6k7tg0c6W"
      },
      "source": [
        "## 3.6\tScaled Dot-Product Attention\n",
        "\n",
        "Based on the paper [Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf), the input consists of queries and keys of dimension $d_k$, and values of dimension $d_v$. We compute the dot products of the query with all keys, divide each by $\\sqrt{d_k}$, and apply a softmax function to obtain the weights on the\n",
        "values.\n",
        "\n",
        "In practice, we compute the attention function on a set of queries simultaneously, packed together into a matrix $Q$. The keys and values are also packed together into matrices $K$ and $V$. We compute\n",
        "the matrix of outputs as:\n",
        "\n",
        "$$Attention(Q, K, V)=softmax \\left( \\frac{QK^T}{\\sqrt{d_k}} \\right) V$$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-07T15:34:33.679878Z",
          "iopub.status.busy": "2024-02-07T15:34:33.679587Z",
          "iopub.status.idle": "2024-02-07T15:34:33.685676Z",
          "shell.execute_reply": "2024-02-07T15:34:33.685098Z",
          "shell.execute_reply.started": "2024-02-07T15:34:33.679858Z"
        },
        "id": "VSURuVsU0j7l"
      },
      "outputs": [],
      "source": [
        "class ScaledDotProductAttention(nn.Module):\n",
        "    def __init__(self, dropout=0.2):\n",
        "        super(ScaledDotProductAttention, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, Q, K, V, mask=None):\n",
        "        attn_logits = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k)\n",
        "        if mask is not None:\n",
        "            attn_logits = attn_logits.masked_fill_(mask, -float('inf'))\n",
        "        scores = nn.Softmax(dim=-1)(attn_logits)\n",
        "        scores = self.dropout(scores)\n",
        "        attention = torch.matmul(scores, V)\n",
        "        return attention, scores"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.7\tMask"
      ],
      "metadata": {
        "id": "4lYaxaPoVxjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Mask(nn.Module):\n",
        "    def get_attn_pad_mask(self, seq_q, seq_k, pad=0):\n",
        "        batch_size, len_q = seq_q.size()\n",
        "        batch_size, len_k = seq_k.size()\n",
        "        pad_attn_mask = seq_k.data.eq(pad).unsqueeze(1)\n",
        "        return pad_attn_mask.expand(batch_size, len_q, len_k)\n",
        "\n",
        "    def get_attn_subsequence_mask(self, seq):\n",
        "        attn_shape = [seq.size(0), seq.size(1), seq.size(1)]\n",
        "        subsequence_mask = torch.triu(torch.ones(attn_shape), diagonal=1)\n",
        "        subsequence_mask.bool()\n",
        "        return subsequence_mask"
      ],
      "metadata": {
        "id": "hgCQGtwqVxO_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiKOvwnl7QLO"
      },
      "source": [
        "## 3.8\tMulti-Head Attention\n",
        "\n",
        "Multi-head Attention is a module for attention mechanisms which runs through an attention mechanism several times in parallel. The independent attention outputs are then concatenated and linearly transformed into the expected dimension. It's defined as:\n",
        "\n",
        "$$Multihead(Q, K, V) = Concat(head_1, ..., head_h)\\cdot W$$\n",
        "\n",
        "where: $head_i = Attention(QW_i^Q, KW_i^K, VW_i^V)$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-07T15:34:33.687237Z",
          "iopub.status.busy": "2024-02-07T15:34:33.686920Z",
          "iopub.status.idle": "2024-02-07T15:34:33.697511Z",
          "shell.execute_reply": "2024-02-07T15:34:33.696783Z",
          "shell.execute_reply.started": "2024-02-07T15:34:33.687207Z"
        },
        "id": "y0SecFdX7evW"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model=d_model, n_heads=n_heads, d_k=d_k, d_v=d_v, dropout=0.2):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.d_model, self.n_heads = d_model, n_heads\n",
        "        self.d_k, self.d_v = d_k, d_v\n",
        "\n",
        "        self.W_Q = nn.Linear(d_model, self.d_k * self.n_heads, bias=False)\n",
        "        self.W_K = nn.Linear(d_model, self.d_k * self.n_heads, bias=False)\n",
        "        self.W_V = nn.Linear(d_model, self.d_v * self.n_heads, bias=False)\n",
        "\n",
        "        self.fc = nn.Linear(self.n_heads * self.d_v, d_model, bias=False)\n",
        "        self.ln = LayerNorm(self.d_model)\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, input_Q, input_K, input_V, attn_mask):\n",
        "        n_heads, d_k, d_v = self.n_heads, self.d_k, self.d_v\n",
        "        residual, batch_size = input_Q, input_Q.size(0)\n",
        "        Q = self.W_Q(input_Q).view(batch_size, -1, n_heads, d_k).transpose(1, 2)\n",
        "        K = self.W_K(input_K).view(batch_size, -1, n_heads, d_k).transpose(1, 2)\n",
        "        V = self.W_V(input_V).view(batch_size, -1, n_heads, d_v).transpose(1, 2)\n",
        "\n",
        "        attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1)\n",
        "        context, attn = ScaledDotProductAttention()(Q, K, V, attn_mask)\n",
        "        context = context.transpose(1, 2).reshape(batch_size, -1, n_heads * d_v)\n",
        "        output = self.dropout(self.fc(context))\n",
        "        return self.ln(output + residual), attn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.9\tEncoder Layer and Encoder"
      ],
      "metadata": {
        "id": "RJYWZb4FV-EB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-07T15:34:33.699189Z",
          "iopub.status.busy": "2024-02-07T15:34:33.698628Z",
          "iopub.status.idle": "2024-02-07T15:34:33.716025Z",
          "shell.execute_reply": "2024-02-07T15:34:33.715446Z",
          "shell.execute_reply.started": "2024-02-07T15:34:33.699158Z"
        },
        "id": "etGtAasoaRwK"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.enc_self_attn = MultiHeadAttention()\n",
        "        self.pos_ffn = FeedForward(d_ff)\n",
        "\n",
        "    def forward(self, enc_inputs, enc_self_attn_mask):\n",
        "        enc_outputs, _i = self.enc_self_attn(enc_inputs, enc_inputs, enc_inputs, enc_self_attn_mask)\n",
        "        enc_outputs = self.pos_ffn(enc_outputs)\n",
        "        return enc_outputs\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.src_emb = nn.Embedding(vocab_size, d_model)\n",
        "        self.pos_emb = PositionalEncoding( d_model, max_len = vocab_size )\n",
        "        self.layers = nn.ModuleList([EncoderLayer() for _ in range(n_layers)])\n",
        "        self.mask = Mask()\n",
        "\n",
        "    def forward(self, enc_inputs):\n",
        "        enc_outputs = self.src_emb(enc_inputs)\n",
        "        enc_outputs = self.pos_emb(enc_outputs).to(device)\n",
        "        enc_self_attn_mask = self.mask.get_attn_pad_mask(enc_inputs, enc_inputs).to(device)\n",
        "        for layer in self.layers:\n",
        "            enc_outputs = layer(enc_outputs, enc_self_attn_mask)\n",
        "        return enc_outputs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.10\tDecoder Layer and Decoder"
      ],
      "metadata": {
        "id": "UrMQl7uwWLME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.dec_self_attn = MultiHeadAttention()\n",
        "        self.dec_enc_attn = MultiHeadAttention()\n",
        "        self.pos_ffn = FeedForward(d_ff)\n",
        "\n",
        "    def forward(self, dec_inputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask):\n",
        "        dec_outputs, _ = self.dec_self_attn(dec_inputs,\n",
        "                                            dec_inputs,\n",
        "                                            dec_inputs,\n",
        "                                            dec_self_attn_mask)\n",
        "\n",
        "        dec_outputs, _ = self.dec_enc_attn(dec_outputs,\n",
        "                                           enc_outputs,\n",
        "                                           enc_outputs,\n",
        "                                           dec_enc_attn_mask)\n",
        "\n",
        "        dec_outputs = self.pos_ffn(dec_outputs)\n",
        "        return dec_outputs\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.tgt_emb = nn.Embedding(vocab_size, d_model)\n",
        "        self.pos_emb = PositionalEncoding(d_model, max_len = vocab_size )\n",
        "        self.layers = nn.ModuleList([DecoderLayer() for _ in range(n_layers)])\n",
        "        self.mask = Mask()\n",
        "\n",
        "    def forward(self, dec_inputs, enc_inputs, enc_outputs):\n",
        "        dec_outputs = self.tgt_emb(dec_inputs)\n",
        "        dec_outputs = self.pos_emb(dec_outputs).to(device)\n",
        "        dec_self_attn_pad_mask = self.mask.get_attn_pad_mask(dec_inputs, dec_inputs).to(device)\n",
        "        dec_self_attn_subsequence_mask = self.mask.get_attn_subsequence_mask(dec_inputs).to(device)\n",
        "        dec_self_attn_mask = torch.gt((dec_self_attn_pad_mask + dec_self_attn_subsequence_mask), 0).to(device)\n",
        "        dec_enc_attn_mask = self.mask.get_attn_pad_mask(dec_inputs, enc_inputs)\n",
        "\n",
        "        for layer in self.layers:\n",
        "            dec_outputs = layer(dec_outputs, enc_outputs,\n",
        "                                dec_self_attn_mask, dec_enc_attn_mask)\n",
        "        return dec_outputs"
      ],
      "metadata": {
        "id": "PuVtlgbiWFPj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.11\tTransformer"
      ],
      "metadata": {
        "id": "X3b61_LmWTNF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.encoder = Encoder().to(device)\n",
        "        self.decoder = Decoder().to(device)\n",
        "        self.projection = nn.Linear(\n",
        "            d_model, vocab_size, bias=False).to(device)\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, enc_inputs, dec_inputs):\n",
        "        enc_outputs = self.encoder(enc_inputs)\n",
        "        dec_outputs = self.decoder(dec_inputs, enc_inputs, enc_outputs)\n",
        "        dec_logits = self.projection(dec_outputs)\n",
        "        return dec_logits.view(-1, dec_logits.size(-1))\n",
        "\n"
      ],
      "metadata": {
        "id": "FDEnH3ryWXBx"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_Gu656Lh-41"
      },
      "source": [
        "## 3.12\tTraining"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-02-07T15:34:33.717475Z",
          "iopub.status.busy": "2024-02-07T15:34:33.716858Z",
          "iopub.status.idle": "2024-02-07T15:34:36.936404Z",
          "shell.execute_reply": "2024-02-07T15:34:36.935476Z",
          "shell.execute_reply.started": "2024-02-07T15:34:33.717442Z"
        },
        "id": "imxC3WKqsect",
        "outputId": "4e918e36-12f9-4775-a121-2824a4679861"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters of the model: 44,324,352\n"
          ]
        }
      ],
      "source": [
        "model = Transformer().to(device)\n",
        "# print the number of parameters in the model\n",
        "total_parameter = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Parameters of the model: {total_parameter:,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print out the structure of the Transformer model\n",
        "print(model)"
      ],
      "metadata": {
        "id": "LETt98SbL2qg",
        "outputId": "53728b01-e32f-4789-8b96-8321f653f58a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformer(\n",
            "  (encoder): Encoder(\n",
            "    (src_emb): Embedding(165, 512)\n",
            "    (pos_emb): PositionalEncoding(\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (layers): ModuleList(\n",
            "      (0-5): 6 x EncoderLayer(\n",
            "        (enc_self_attn): MultiHeadAttention(\n",
            "          (W_Q): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (W_K): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (W_V): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (fc): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (ln): LayerNorm()\n",
            "          (dropout): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (pos_ffn): FeedForward(\n",
            "          (fc): Sequential(\n",
            "            (0): Linear(in_features=512, out_features=2048, bias=False)\n",
            "            (1): ReLU()\n",
            "            (2): Dropout(p=0.2, inplace=False)\n",
            "            (3): Linear(in_features=2048, out_features=512, bias=False)\n",
            "          )\n",
            "          (ln): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (mask): Mask()\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (tgt_emb): Embedding(165, 512)\n",
            "    (pos_emb): PositionalEncoding(\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (layers): ModuleList(\n",
            "      (0-5): 6 x DecoderLayer(\n",
            "        (dec_self_attn): MultiHeadAttention(\n",
            "          (W_Q): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (W_K): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (W_V): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (fc): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (ln): LayerNorm()\n",
            "          (dropout): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (dec_enc_attn): MultiHeadAttention(\n",
            "          (W_Q): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (W_K): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (W_V): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (fc): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (ln): LayerNorm()\n",
            "          (dropout): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (pos_ffn): FeedForward(\n",
            "          (fc): Sequential(\n",
            "            (0): Linear(in_features=512, out_features=2048, bias=False)\n",
            "            (1): ReLU()\n",
            "            (2): Dropout(p=0.2, inplace=False)\n",
            "            (3): Linear(in_features=2048, out_features=512, bias=False)\n",
            "          )\n",
            "          (ln): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (mask): Mask()\n",
            "  )\n",
            "  (projection): Linear(in_features=512, out_features=165, bias=False)\n",
            "  (softmax): Softmax(dim=-1)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function to ignore the word \"<P>\" which marks the end of a sentance.\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.encode_word(\"<PAD>\"))\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.99)"
      ],
      "metadata": {
        "id": "cD3MvOPjLz0k"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-02-07T15:34:36.938024Z",
          "iopub.status.busy": "2024-02-07T15:34:36.937721Z",
          "iopub.status.idle": "2024-02-07T15:34:48.692417Z",
          "shell.execute_reply": "2024-02-07T15:34:48.691439Z",
          "shell.execute_reply.started": "2024-02-07T15:34:36.938000Z"
        },
        "id": "H3owjVGGh-TS",
        "outputId": "101eeb86-81ac-49b3-863d-81a530de61fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/1 loss = 5.287929\n",
            "Epoch: 2/1 loss = 5.311439\n",
            "Epoch: 1/2 loss = 5.269698\n",
            "Epoch: 2/2 loss = 5.221197\n",
            "Epoch: 1/3 loss = 5.091483\n",
            "Epoch: 2/3 loss = 4.971140\n",
            "Epoch: 1/4 loss = 4.875039\n",
            "Epoch: 2/4 loss = 4.724355\n",
            "Epoch: 1/5 loss = 4.603537\n",
            "Epoch: 2/5 loss = 4.648116\n",
            "Epoch: 1/6 loss = 4.632385\n",
            "Epoch: 2/6 loss = 4.540625\n",
            "Epoch: 1/7 loss = 4.617231\n",
            "Epoch: 2/7 loss = 4.416563\n",
            "Epoch: 1/8 loss = 4.468247\n",
            "Epoch: 2/8 loss = 4.396354\n",
            "Epoch: 1/9 loss = 4.325215\n",
            "Epoch: 2/9 loss = 4.272070\n",
            "Epoch: 1/10 loss = 4.106296\n",
            "Epoch: 2/10 loss = 4.223099\n",
            "Epoch: 1/11 loss = 4.048276\n",
            "Epoch: 2/11 loss = 4.176880\n",
            "Epoch: 1/12 loss = 4.253010\n",
            "Epoch: 2/12 loss = 4.038179\n",
            "Epoch: 1/13 loss = 4.061227\n",
            "Epoch: 2/13 loss = 4.140214\n",
            "Epoch: 1/14 loss = 3.923707\n",
            "Epoch: 2/14 loss = 4.102126\n",
            "Epoch: 1/15 loss = 4.010428\n",
            "Epoch: 2/15 loss = 3.888299\n",
            "Epoch: 1/16 loss = 3.996034\n",
            "Epoch: 2/16 loss = 3.572006\n",
            "Epoch: 1/17 loss = 3.788320\n",
            "Epoch: 2/17 loss = 3.476848\n",
            "Epoch: 1/18 loss = 3.626778\n",
            "Epoch: 2/18 loss = 3.450387\n",
            "Epoch: 1/19 loss = 3.259319\n",
            "Epoch: 2/19 loss = 3.525593\n",
            "Epoch: 1/20 loss = 3.184549\n",
            "Epoch: 2/20 loss = 3.315412\n",
            "Epoch: 1/21 loss = 3.204533\n",
            "Epoch: 2/21 loss = 3.051605\n",
            "Epoch: 1/22 loss = 2.770664\n",
            "Epoch: 2/22 loss = 3.142617\n",
            "Epoch: 1/23 loss = 2.992534\n",
            "Epoch: 2/23 loss = 2.556187\n",
            "Epoch: 1/24 loss = 2.799778\n",
            "Epoch: 2/24 loss = 2.494276\n",
            "Epoch: 1/25 loss = 2.573189\n",
            "Epoch: 2/25 loss = 2.489694\n",
            "Epoch: 1/26 loss = 2.568518\n",
            "Epoch: 2/26 loss = 2.206563\n",
            "Epoch: 1/27 loss = 2.247156\n",
            "Epoch: 2/27 loss = 2.220434\n",
            "Epoch: 1/28 loss = 2.101375\n",
            "Epoch: 2/28 loss = 2.117283\n",
            "Epoch: 1/29 loss = 1.886273\n",
            "Epoch: 2/29 loss = 2.060025\n",
            "Epoch: 1/30 loss = 1.846014\n",
            "Epoch: 2/30 loss = 1.808694\n",
            "Epoch: 1/31 loss = 1.640113\n",
            "Epoch: 2/31 loss = 1.772808\n",
            "Epoch: 1/32 loss = 1.456943\n",
            "Epoch: 2/32 loss = 1.630343\n",
            "Epoch: 1/33 loss = 1.648678\n",
            "Epoch: 2/33 loss = 1.219222\n",
            "Epoch: 1/34 loss = 1.518483\n",
            "Epoch: 2/34 loss = 1.246200\n",
            "Epoch: 1/35 loss = 1.188051\n",
            "Epoch: 2/35 loss = 1.340960\n",
            "Epoch: 1/36 loss = 1.176219\n",
            "Epoch: 2/36 loss = 1.143926\n",
            "Epoch: 1/37 loss = 1.191843\n",
            "Epoch: 2/37 loss = 1.022550\n",
            "Epoch: 1/38 loss = 1.088887\n",
            "Epoch: 2/38 loss = 0.804077\n",
            "Epoch: 1/39 loss = 0.937249\n",
            "Epoch: 2/39 loss = 0.855606\n",
            "Epoch: 1/40 loss = 0.896693\n",
            "Epoch: 2/40 loss = 0.824006\n",
            "Epoch: 1/41 loss = 0.784505\n",
            "Epoch: 2/41 loss = 0.779170\n",
            "Epoch: 1/42 loss = 0.661889\n",
            "Epoch: 2/42 loss = 0.729476\n",
            "Epoch: 1/43 loss = 0.687664\n",
            "Epoch: 2/43 loss = 0.533135\n",
            "Epoch: 1/44 loss = 0.522554\n",
            "Epoch: 2/44 loss = 0.603451\n",
            "Epoch: 1/45 loss = 0.489589\n",
            "Epoch: 2/45 loss = 0.555729\n",
            "Epoch: 1/46 loss = 0.472468\n",
            "Epoch: 2/46 loss = 0.501912\n",
            "Epoch: 1/47 loss = 0.474098\n",
            "Epoch: 2/47 loss = 0.462020\n",
            "Epoch: 1/48 loss = 0.431948\n",
            "Epoch: 2/48 loss = 0.426015\n",
            "Epoch: 1/49 loss = 0.360672\n",
            "Epoch: 2/49 loss = 0.440602\n",
            "Epoch: 1/50 loss = 0.353842\n",
            "Epoch: 2/50 loss = 0.361163\n",
            "Epoch: 1/51 loss = 0.322263\n",
            "Epoch: 2/51 loss = 0.346262\n",
            "Epoch: 1/52 loss = 0.330055\n",
            "Epoch: 2/52 loss = 0.269617\n",
            "Epoch: 1/53 loss = 0.316717\n",
            "Epoch: 2/53 loss = 0.235736\n",
            "Epoch: 1/54 loss = 0.276418\n",
            "Epoch: 2/54 loss = 0.236801\n",
            "Epoch: 1/55 loss = 0.256041\n",
            "Epoch: 2/55 loss = 0.285571\n",
            "Epoch: 1/56 loss = 0.254310\n",
            "Epoch: 2/56 loss = 0.250423\n",
            "Epoch: 1/57 loss = 0.260550\n",
            "Epoch: 2/57 loss = 0.194246\n",
            "Epoch: 1/58 loss = 0.208074\n",
            "Epoch: 2/58 loss = 0.194505\n",
            "Epoch: 1/59 loss = 0.206841\n",
            "Epoch: 2/59 loss = 0.175425\n",
            "Epoch: 1/60 loss = 0.192249\n",
            "Epoch: 2/60 loss = 0.142961\n",
            "Epoch: 1/61 loss = 0.197727\n",
            "Epoch: 2/61 loss = 0.128638\n",
            "Epoch: 1/62 loss = 0.131402\n",
            "Epoch: 2/62 loss = 0.162487\n",
            "Epoch: 1/63 loss = 0.157193\n",
            "Epoch: 2/63 loss = 0.128420\n",
            "Epoch: 1/64 loss = 0.134793\n",
            "Epoch: 2/64 loss = 0.119163\n",
            "Epoch: 1/65 loss = 0.146831\n",
            "Epoch: 2/65 loss = 0.128307\n",
            "Epoch: 1/66 loss = 0.144891\n",
            "Epoch: 2/66 loss = 0.114571\n",
            "Epoch: 1/67 loss = 0.124852\n",
            "Epoch: 2/67 loss = 0.120879\n",
            "Epoch: 1/68 loss = 0.128046\n",
            "Epoch: 2/68 loss = 0.103781\n",
            "Epoch: 1/69 loss = 0.104491\n",
            "Epoch: 2/69 loss = 0.123251\n",
            "Epoch: 1/70 loss = 0.079696\n",
            "Epoch: 2/70 loss = 0.120110\n",
            "Epoch: 1/71 loss = 0.099462\n",
            "Epoch: 2/71 loss = 0.096890\n",
            "Epoch: 1/72 loss = 0.099640\n",
            "Epoch: 2/72 loss = 0.084056\n",
            "Epoch: 1/73 loss = 0.110053\n",
            "Epoch: 2/73 loss = 0.074761\n",
            "Epoch: 1/74 loss = 0.072329\n",
            "Epoch: 2/74 loss = 0.092342\n",
            "Epoch: 1/75 loss = 0.114316\n",
            "Epoch: 2/75 loss = 0.058971\n",
            "Epoch: 1/76 loss = 0.092658\n",
            "Epoch: 2/76 loss = 0.060601\n",
            "Epoch: 1/77 loss = 0.069841\n",
            "Epoch: 2/77 loss = 0.067762\n",
            "Epoch: 1/78 loss = 0.060666\n",
            "Epoch: 2/78 loss = 0.064492\n",
            "Epoch: 1/79 loss = 0.043224\n",
            "Epoch: 2/79 loss = 0.078751\n",
            "Epoch: 1/80 loss = 0.066673\n",
            "Epoch: 2/80 loss = 0.051936\n",
            "Epoch: 1/81 loss = 0.055413\n",
            "Epoch: 2/81 loss = 0.052146\n",
            "Epoch: 1/82 loss = 0.057349\n",
            "Epoch: 2/82 loss = 0.056840\n",
            "Epoch: 1/83 loss = 0.043285\n",
            "Epoch: 2/83 loss = 0.070768\n",
            "Epoch: 1/84 loss = 0.044797\n",
            "Epoch: 2/84 loss = 0.051179\n",
            "Epoch: 1/85 loss = 0.070908\n",
            "Epoch: 2/85 loss = 0.036523\n",
            "Epoch: 1/86 loss = 0.058670\n",
            "Epoch: 2/86 loss = 0.032678\n",
            "Epoch: 1/87 loss = 0.048150\n",
            "Epoch: 2/87 loss = 0.039323\n",
            "Epoch: 1/88 loss = 0.044149\n",
            "Epoch: 2/88 loss = 0.045221\n",
            "Epoch: 1/89 loss = 0.050737\n",
            "Epoch: 2/89 loss = 0.037604\n",
            "Epoch: 1/90 loss = 0.038338\n",
            "Epoch: 2/90 loss = 0.035641\n",
            "Epoch: 1/91 loss = 0.044015\n",
            "Epoch: 2/91 loss = 0.033477\n",
            "Epoch: 1/92 loss = 0.032944\n",
            "Epoch: 2/92 loss = 0.049331\n",
            "Epoch: 1/93 loss = 0.029001\n",
            "Epoch: 2/93 loss = 0.042414\n",
            "Epoch: 1/94 loss = 0.052180\n",
            "Epoch: 2/94 loss = 0.028630\n",
            "Epoch: 1/95 loss = 0.024928\n",
            "Epoch: 2/95 loss = 0.033359\n",
            "Epoch: 1/96 loss = 0.036582\n",
            "Epoch: 2/96 loss = 0.049432\n",
            "Epoch: 1/97 loss = 0.029375\n",
            "Epoch: 2/97 loss = 0.036143\n",
            "Epoch: 1/98 loss = 0.030372\n",
            "Epoch: 2/98 loss = 0.026929\n",
            "Epoch: 1/99 loss = 0.022789\n",
            "Epoch: 2/99 loss = 0.037397\n",
            "Epoch: 1/100 loss = 0.033618\n",
            "Epoch: 2/100 loss = 0.024889\n"
          ]
        }
      ],
      "source": [
        "history_loss = []\n",
        "for epoch in range(epochs):\n",
        "    for i, [enc_inputs, dec_inputs, dec_outputs] in enumerate(loader):\n",
        "        enc_inputs =  enc_inputs.to(device)\n",
        "        dec_inputs =  dec_inputs.to(device)\n",
        "        dec_outputs = dec_outputs.to(device)\n",
        "        outputs = model(enc_inputs, dec_inputs)\n",
        "        loss = criterion(outputs, dec_outputs.view(-1))\n",
        "\n",
        "        print('Epoch:', '%d/%d' % (i+1, epoch+1), 'loss =', '{:.6f}'.format(loss))\n",
        "        history_loss.append(loss.item())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKBRspyrDrgG"
      },
      "source": [
        "### Visualize the train losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "execution": {
          "iopub.execute_input": "2024-02-07T15:34:48.694683Z",
          "iopub.status.busy": "2024-02-07T15:34:48.693769Z",
          "iopub.status.idle": "2024-02-07T15:34:49.519319Z",
          "shell.execute_reply": "2024-02-07T15:34:49.518483Z",
          "shell.execute_reply.started": "2024-02-07T15:34:48.694651Z"
        },
        "id": "wUnc4Qq0gQc8",
        "outputId": "11b24110-4a1a-4cdb-b2ec-7dc1ede75541"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.title(\"Loss During Training\")\n",
        "plt.plot(history_loss, label=\"Train Loss\", c='k', lw=2)\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.savefig(\"Training.svg\", format=\"svg\", dpi=150, transparent=True, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYE6AmJKiFbO"
      },
      "source": [
        "## 3.13\tInference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-07T15:34:49.521350Z",
          "iopub.status.busy": "2024-02-07T15:34:49.520543Z",
          "iopub.status.idle": "2024-02-07T15:34:49.528747Z",
          "shell.execute_reply": "2024-02-07T15:34:49.527950Z",
          "shell.execute_reply.started": "2024-02-07T15:34:49.521323Z"
        },
        "id": "1E5HTj2DexJq",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def Greedy(logits):\n",
        "    return torch.argmax(logits, dim=-1, keepdim=False)\n",
        "\n",
        "def RandomSampling(logits, k=5):\n",
        "    top_k_probs, _ = torch.topk(logits, k, dim=-1)\n",
        "    kth_highest_prob = top_k_probs[:, -1].unsqueeze(-1)\n",
        "    mask = logits < kth_highest_prob\n",
        "    probs = logits.masked_fill(mask, 0)\n",
        "    return torch.multinomial(probs, num_samples=1).squeeze(-1)\n",
        "\n",
        "def Inference(model, enc_input, start_token, end_token, max_len=32, topk=None):\n",
        "    enc_outputs = model.encoder(enc_input)\n",
        "    dec_input = torch.zeros(1, 0).type_as(enc_input.data)\n",
        "    next_token = start_token\n",
        "    cnt = 0\n",
        "    while next_token != end_token and cnt < max_len:\n",
        "        dec_input = torch.cat([dec_input.to(device),\n",
        "                               torch.tensor([[next_token]], dtype=enc_input.dtype).to(device)], -1)\n",
        "        dec_outputs = model.decoder(dec_input, enc_input, enc_outputs)\n",
        "        projected = model.projection(dec_outputs)\n",
        "        projected = model.softmax(projected)\n",
        "        if topk == None:\n",
        "          prob = Greedy(projected.squeeze(0))\n",
        "        else:\n",
        "          prob = RandomSampling(projected.squeeze(0), topk)\n",
        "        next_word = prob.data[-1]\n",
        "        next_token = next_word\n",
        "        cnt += 1\n",
        "    return prob\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-02-07T15:34:49.530069Z",
          "iopub.status.busy": "2024-02-07T15:34:49.529772Z",
          "iopub.status.idle": "2024-02-07T15:34:51.925457Z",
          "shell.execute_reply": "2024-02-07T15:34:51.924397Z",
          "shell.execute_reply.started": "2024-02-07T15:34:49.530050Z"
        },
        "id": "piRD2M7gbFFI",
        "outputId": "98203fd6-e628-4107-ee4d-b84cd54b1722",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Where turtles lay eggs? -> Holes dug into mud or sand. \n",
            "How Isabelline penguins different? -> Because they are born with brown rather than black plumage. \n",
            "How do otters keep warm? -> A layer of air trapped in their fur. \n",
            "How similar between the beetles and the grasshoppers? -> Beetles have mouthparts mouthparts that are similar to those of the grasshoppers. \n",
            "Can infrared photography seen polar bears? -> Polar bears are nearly invisible under infrared photography. \n",
            "How long do penguins on land? -> They spend half of their life on land. \n",
            "DNA evidence and fossil tell us What? -> The polar bear diverged from the brown bear roughly 200 thousand years ago. \n",
            "What years do turtles breed? -> Every few years or more. \n",
            "are cougar males heavier than females? -> On average the cougar males are heavier than the females. \n",
            "Beetles eat What? -> They often feed on plants and fungi, break down animal and plant debris, and eat other invertebrates. \n",
            "How similar between beetles and grasshoppers? -> Beetles have mouthparts similar to those of grasshoppers. \n",
            "How do elephants communicate over distances? -> By producing and receiving low-frequency sound or infrasound. \n",
            "What do penguins agile in water? -> Smooth plumage preserves a layer of air, ensuring buoyancy, wings are flippers. \n",
            "What sections do beetles have? -> They often feed on plants and fungi, break down animal and plant debris, and eat other invertebrates. \n",
            "What animal larger than elephant? -> None, the elephant is the largest land animal in the world. \n",
            "What elephants weight at birth? -> At birth it is common for an elephant calf to weigh 120 kilograms or 265 lb. \n"
          ]
        }
      ],
      "source": [
        "evaluation = [\n",
        "  ['How similar between the beetles and the grasshoppers?', ''],\n",
        "  ['What animal larger than elephant?', ''],\n",
        "  ['What years do turtles breed?',  ''],\n",
        "  ['Where turtles lay eggs?', ''],\n",
        "  ['How do otters keep warm?', ''],\n",
        "  ['How long do penguins on land?', ''],\n",
        "  ['What sections do beetles have?', ''],\n",
        "  ['Can infrared photography seen polar bears?', ''],\n",
        "  ['DNA evidence and fossil tell us What?', ''],\n",
        "  ['are cougar males heavier than females?', ''],\n",
        "  ['How Isabelline penguins different?', ''],\n",
        "  ['Beetles eat What?', ''],\n",
        "  ['How similar between beetles and grasshoppers?', ''],\n",
        "  ['What elephants weight at birth?', ''],\n",
        "  ['How do elephants communicate over distances?', ''],\n",
        "  ['What do penguins agile in water?', ''],\n",
        "]\n",
        "\n",
        "evl_enc_inputs, _, _ = make_data(evaluation)\n",
        "evl_loader = Data.DataLoader(DataSet([evl_enc_inputs]), 16, True)\n",
        "[evl_enc_inputs] = next(iter(evl_loader))\n",
        "\n",
        "for i in range(len(evl_enc_inputs)):\n",
        "    predict = Inference(model,\n",
        "                        evl_enc_inputs[i].view(1, -1).to(device),\n",
        "                        start_token=tokenizer.encode_word(\"<SOS>\"),\n",
        "                        end_token=tokenizer.encode_word(\"<EOS>\"),\n",
        "                        topk=None)\n",
        "    q = evl_enc_inputs[i].tolist()\n",
        "    q = [x for x in q if x != tokenizer.encode_word(\"<PAD>\")]\n",
        "    question = tokenizer.decode_text(q)\n",
        "    answer = tokenizer.decode_text(predict.tolist())\n",
        "    question = question.replace(\" ?\", \"?\")\n",
        "    answer = answer.replace(\" .\", \".\").replace(\"<EOS>\", \"\")\n",
        "    print(question, '->', answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvV7q0mcreU9"
      },
      "source": [
        "## References:\n",
        "\n",
        "1.   *https://nlp.seas.harvard.edu/annotated-transformer/*\n",
        "1.   *https://github.com/jadore801120/attention-is-all-you-need-pytorch*\n",
        "2.   *https://github.com/JayParks/transformer*\n",
        "3.   *https://www.freecodecamp.org/news/how-to-build-a-large-language-model-from-scratch-using-python/*\n",
        "4.   *https://mdnice.com/writing/fc0b920d4ca84837a5712df1a46865d2*"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "saturn (Python 3)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}