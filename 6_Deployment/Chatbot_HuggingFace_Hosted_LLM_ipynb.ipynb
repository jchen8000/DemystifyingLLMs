{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jchen8000/DemystifyingLLMs/blob/main/6_Deployment/Chatbot_HuggingFace_Hosted_LLM_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BK74JIJAraMz"
      },
      "source": [
        "# 6. Deployment of LLMs\n",
        "\n",
        "# 6.11 Chatbot, Example of LLM-Powered Application\n",
        "\n",
        "### **Simple Chatbot Using Hugging Face Hosted LLM (Without LangChain)**\n",
        "\n",
        "This notebook demonstrates how to build a minimal chatbot using the **Hugging Face Inference Client** directly, without relying on LangChain or other orchestration frameworks.  \n",
        "It shows how to authenticate securely, send chat-formatted messages to a hosted large language model, maintain conversation history, and produce responses using a fully remote, cloud‚Äëhosted LLM.  \n",
        "The example uses the instruction‚Äëtuned **Qwen2.5‚Äë7B‚ÄëInstruct** model served through Hugging Face‚Äôs hosted inference API.\n",
        "\n",
        "A **Hugging Face access token** is required to run this notebook.  \n",
        "If you do not already have one, you can obtain it here:  \n",
        "üîó https://huggingface.co/docs/hub/security-tokens  \n",
        "The token should be stored securely as `HF_TOKEN` in **Colab Secrets** or another protected environment variable.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚ö†Ô∏è **Compatibility Note**\n",
        "\n",
        "This notebook is confirmed working as of **January 2026**, including the currently available `Qwen/Qwen2.5-7B-Instruct` model. However, Hugging Face client libraries, model endpoints, and hosted model availability evolve rapidly, and future updates or model deprecations may require adjustments to this notebook. This example serves as a learning-oriented reference illustrating current best practices, not a permanently stable API contract.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QFE-0dfUMeC"
      },
      "outputs": [],
      "source": [
        "%pip install -q \\\n",
        "  huggingface_hub==0.36.0 \\\n",
        "  transformers==4.57.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "eRN563dwZz87"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from huggingface_hub import InferenceClient\n",
        "\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = userdata.get(\"HF_TOKEN\")\n",
        "client = InferenceClient()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "oE-IHnQym4Mu"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"Qwen/Qwen2.5-7B-Instruct\"\n",
        "\n",
        "def ask_model(message, history, temperature=0.7, max_tokens=512):\n",
        "    messages = [{\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"}]\n",
        "\n",
        "    for user_msg, bot_msg in history:\n",
        "        messages.append({\"role\": \"user\", \"content\": user_msg})\n",
        "        messages.append({\"role\": \"assistant\", \"content\": bot_msg})\n",
        "\n",
        "    messages.append({\"role\": \"user\", \"content\": message})\n",
        "\n",
        "    try:\n",
        "        # We pass the model ID here instead of in the Client constructor\n",
        "        # This allows the 'auto' provider system to work best\n",
        "        response = client.chat.completions.create(\n",
        "            model=MODEL_ID,\n",
        "            messages=messages,\n",
        "            max_tokens=max_tokens,\n",
        "            temperature=temperature,\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        return f\"System Busy: {str(e)}. Please try again in a moment.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMZQA2OqmRAI",
        "outputId": "9917c418-ef6f-48d5-ab7b-d69c04e0b5ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chatbot initialized. You can start chatting now (type 'quit' to stop)!\n",
            "\n",
            "You: Hello, How are you?\n",
            "\n",
            "AI: Hello! I'm just a computer program, so I don't have feelings or emotions. But I'm here and ready to help you with any questions or information you need. How can I assist you today?\n",
            "\n",
            "You: What are the top 5 largest cities in Canada?\n",
            "\n",
            "AI: Certainly! Here are the top 5 largest cities in Canada by population:\n",
            "\n",
            "1. **Toronto** - Population: Approximately 3 million (city proper)\n",
            "2. **Montreal** - Population: Approximately 1.7 million (city proper)\n",
            "3. **Vancouver** - Population: Approximately 680,000 (city proper), but the Greater Vancouver Area has over 2.5 million people\n",
            "4. **Calgary** - Population: Approximately 1.2 million (city proper)\n",
            "5. **Ottawa** - Population: Approximately 1 million (city proper)\n",
            "\n",
            "These figures are based on the city proper populations, but if you include the metropolitan areas, the rankings can change. For example, the Greater Toronto Area has over 6.5 million people, making it significantly larger when considering the broader urban area.\n",
            "\n",
            "You: What is the next largest city?\n",
            "\n",
            "AI: The next largest city after Toronto, Montreal, Vancouver, and Calgary is Ottawa. Here's the list again with the next largest city highlighted:\n",
            "\n",
            "1. **Toronto** - Population: Approximately 3 million (city proper)\n",
            "2. **Montreal** - Population: Approximately 1.7 million (city proper)\n",
            "3. **Vancouver** - Population: Approximately 680,000 (city proper), but the Greater Vancouver Area has over 2.5 million people\n",
            "4. **Calgary** - Population: Approximately 1.2 million (city proper)\n",
            "5. **Ottawa** - Population: Approximately 1 million (city proper)\n",
            "\n",
            "So, the next largest city after Toronto, Montreal, Vancouver, and Calgary is **Ottawa**.\n",
            "\n",
            "You: What is the population of them, again?\n",
            "\n",
            "AI: Certainly! Here are the populations of the top five largest cities in Canada by city proper:\n",
            "\n",
            "1. **Toronto** - Population: Approximately 3 million\n",
            "2. **Montreal** - Population: Approximately 1.7 million\n",
            "3. **Vancouver** - Population: Approximately 680,000\n",
            "4. **Calgary** - Population: Approximately 1.2 million\n",
            "5. **Ottawa** - Population: Approximately 1 million\n",
            "\n",
            "So, the population of Ottawa is approximately **1 million**.\n",
            "\n",
            "You: Where is the third largest city located?\n",
            "\n",
            "AI: The third largest city in Canada by population (city proper) is **Vancouver**. Vancouver is located on the west coast of British Columbia, in the province of British Columbia, Canada. It is situated on the mainland and is known for its beautiful coastal scenery and diverse population.\n",
            "\n",
            "You: quit\n"
          ]
        }
      ],
      "source": [
        "def chatbot():\n",
        "    print(\"Chatbot initialized. You can start chatting now (type 'quit' to stop)!\\n\")\n",
        "    history = []\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() in [\"quit\", \"exit\"]:\n",
        "            break\n",
        "\n",
        "        answer = ask_model(user_input, history)\n",
        "        print(f\"\\nAI: {answer}\\n\")\n",
        "        history.append([user_input, answer])\n",
        "\n",
        "chatbot()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}