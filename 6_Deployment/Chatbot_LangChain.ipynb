{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jchen8000/DemystifyingLLMs/blob/main/6_Deployment/Chatbot_LangChain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upspEbuBxYTd"
      },
      "source": [
        "# 6. Deployment of LLMs\n",
        "\n",
        "## 6.11 Chatbot, Example of LLM-Powered Application\n",
        "\n",
        "### **Building a Simple Chatbot with LangChain and HuggingFace Endpoints**\n",
        "\n",
        "This notebook demonstrates how to build a lightweight chatbot using **LangChain‚Äôs LCEL pipeline** and **HuggingFace‚Äôs Inference Endpoint API**.  \n",
        "It shows how to authenticate securely, construct a prompt-driven pipeline, interface with a remotely hosted model, and build a simple interactive text-based chatbot.  \n",
        "\n",
        "A **Hugging Face access token** is required to run this notebook.\n",
        "If you do not already have one, you can obtain it at:  \n",
        "üîó https://huggingface.co/docs/hub/security-tokens  \n",
        "The token should be saved as `HF_TOKEN` in Colab Secrets or another secured environment variable before running the example.\n",
        "\n",
        "---\n",
        "\n",
        "###‚ö†Ô∏è **Compatibility Note**\n",
        "\n",
        "This notebook is confirmed working as of **January 2026**, including the currently available `google/gemma-2-9b-it` model. However, LangChain, Hugging Face APIs, and hosted models evolve rapidly, and future updates or model deprecations may require adjustments to this notebook.\n",
        "\n",
        "**This example is for learning and reference purposes and reflects the current best practices, but the APIs used here may change over time.**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQ3585RWsgnk"
      },
      "outputs": [],
      "source": [
        "%pip install -q \\\n",
        "  langchain==1.2.3 \\\n",
        "  langchain-core==1.2.6 \\\n",
        "  langchain-huggingface==1.2.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rxLDptd4tNeW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# Load HF_TOKEN from Colab\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = userdata.get(\"HF_TOKEN\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "K5Q3NSnHtQQ1"
      },
      "outputs": [],
      "source": [
        "# Build prompt\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=\"Please answer the question: {question}\\n\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "79Nh4viMSgkt"
      },
      "outputs": [],
      "source": [
        "# HuggingFace endpoint wrapper\n",
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id=\"google/gemma-2-9b-it\"\n",
        ")\n",
        "\n",
        "chat_model = ChatHuggingFace(llm=llm)\n",
        "chain = prompt | chat_model | StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbJRxaZcujF3",
        "outputId": "6c0042dc-67dc-43d9-c39d-5e92c4cb401e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chatbot initialized. You can start chatting now (type 'quit' to stop)!\n",
            "\n",
            "You: How are you\n",
            "Chatbot: As a large language model, I don't have feelings or experiences like humans do. However, I'm here and ready to assist you with any questions or tasks you may have.\n",
            "\n",
            "How can I help you today?\n",
            "\n",
            "\n",
            "You: Which is the capital city of Japan?\n",
            "Chatbot: The capital city of Japan is **Tokyo**. \n",
            "\n",
            "\n",
            "You: What do turtles eat?\n",
            "Chatbot: That depends on the type of turtle! üê¢ \n",
            "\n",
            "Here's a breakdown:\n",
            "\n",
            "* **Aquatic Turtles:** These turtles live in water and primarily eat fish, insects, worms, and plants. Some larger species even eat small amphibians or crustaceans.\n",
            "\n",
            "* **Terrestrial Turtles:** These turtles live on land and their diet varies depending on the species. Some eat mostly plants like grasses, leaves, and fruits, while others are omnivores, enjoying a mix of plants and insects.\n",
            "\n",
            "* **Omnivorous Turtles:** As their name suggests, these turtles eat both plants and animals. Their diet might include insects, worms, snails, fruits, vegetables, and even carrion.\n",
            "\n",
            "\n",
            "Do you have a specific type of turtle in mind? I can tell you more about its diet if you do! üòä \n",
            "\n",
            "\n",
            "You: How much do elephants weight at birth?\n",
            "Chatbot: Elephant calves typically weigh between **90 and 120 kilograms (200 and 260 pounds)** at birth. \n",
            "\n",
            "\n",
            "You: How much time to penguins spend on land?\n",
            "Chatbot: Penguins spend a **significant** amount of time on land, but it varies depending on the species and their life cycle. \n",
            "\n",
            "Here's a general breakdown:\n",
            "\n",
            "* **Breeding season:** Penguins spend the majority of their time on land during breeding season, which usually involves nesting, incubating eggs, and caring for their chicks. This can last for several months.\n",
            "\n",
            "* **Non-breeding season:** During the rest of the year, penguins spend more time at sea foraging for food. However, they still return to land periodically to rest, molt, and sometimes even breed in warmer climates.\n",
            "\n",
            " **Some species, like Emperor penguins, spend months at a time on land during breeding season, while others, like Little penguins, may only spend a few weeks on land before returning to the ocean.** \n",
            "\n",
            "\n",
            "It's important to remember that these are just general guidelines, and individual penguins may vary in their time allocation between land and sea.\n",
            "\n",
            "\n",
            "\n",
            "You: Thanks\n",
            "Chatbot: You're welcome! üòä\n",
            "\n",
            "Is there anything else I can help you with?\n",
            "\n",
            "\n",
            "You: quit\n"
          ]
        }
      ],
      "source": [
        "def chatbot():\n",
        "\n",
        "    print(\"Chatbot initialized. You can start chatting now (type 'quit' to stop)!\\n\")\n",
        "\n",
        "    while True:\n",
        "        # Get user input\n",
        "        user_input = input(\"You: \")\n",
        "\n",
        "        # Check if the user wants to quit\n",
        "        if user_input.lower() == \"quit\":\n",
        "            break\n",
        "\n",
        "        answer = chain.invoke({\"question\": user_input})\n",
        "        print(f\"Chatbot: {answer}\\n\")\n",
        "\n",
        "# Run the chatbot\n",
        "chatbot()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}