{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNDoUt8oRjpOzL2SVoxzMyk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jchen8000/DemystifyingLLMs/blob/main/6_Deployment/Chatbot_LangChain_Groq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Deployment of LLMs\n",
        "\n",
        "## 6.11 Chatbot, Example of LLM-Powered Application\n",
        "\n",
        "\n",
        "**LangChain Chatbot, using API to chat with GroqCloud with chat history, https://console.groq.com/playground**"
      ],
      "metadata": {
        "id": "odFnqwh7JiX-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Install required packages"
      ],
      "metadata": {
        "id": "HX3UexDhKnTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install groq\n",
        "!pip install langchain\n",
        "!pip install langchain_groq"
      ],
      "metadata": {
        "id": "x6HaHQZaGa_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. API Key From Groq Cloud\n",
        "\n",
        "GroqCloud is a cloud-based platform developed by Groq, designed to provide high-speed AI inference capabilities. It supports a variety of large language models (LLMs) from different developers.\n",
        "\n",
        "You will need to sign up for an account on the platform to obtain an API key, at the time this example is created, you can get an API key for free.\n",
        "\n",
        "This example shows how to use the **Colab Secret** supported by Google Colab, it is designed to help users securely manage sensitive information like API keys, environment variables, etc. On the left sidebar of Google Colab, youâ€™ll see a key icon. Click on it to open the Secrets section, and add a new Secret, give it a name (in this case, **GROQ_API_KEY**) and enter the value which is the API Key you got from Groq Cloud.\n",
        "\n",
        "Below code snippet shows how to retrieve it.\n",
        "\n",
        "Note, if you don't use Google Colab, use other ways to manage the keys, and make sure it's secure and not exposed to others."
      ],
      "metadata": {
        "id": "hGL9tRjcKhlA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from groq import Groq\n",
        "\n",
        "client = Groq(\n",
        "    api_key = userdata.get('GROQ_API_KEY')\n",
        ")"
      ],
      "metadata": {
        "id": "EcNcdC7vFvFw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. A Sample Call to Groq\n",
        "\n",
        "Reference: https://console.groq.com/docs/api-reference#chat-create\n",
        "\n",
        "Note, you can specify the optional parameters like *temperature*, *max_tokens*, *top_p*, etc."
      ],
      "metadata": {
        "id": "AzohinP7NiBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = \"llama3-8b-8192\"\n",
        "completion = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Who are you and please introduce yourself.\"\n",
        "        }\n",
        "    ],\n",
        "\n",
        "    # Controls randomness: lowering results in less random completions.\n",
        "    # As the temperature approaches zero, the model will become deterministic\n",
        "    # and repetitive.\n",
        "    temperature=1,\n",
        "\n",
        "    # The maximum number of tokens to generate. Requests can use up to\n",
        "    # 2048 tokens shared between prompt and completion.\n",
        "    max_tokens=2048,\n",
        "\n",
        "    # Controls diversity via nucleus sampling: 0.5 means half of all\n",
        "    # likelihood-weighted options are considered.\n",
        "    top_p=1,\n",
        "\n",
        "    # If set, partial message deltas will be sent.\n",
        "    stream=True,\n",
        "\n",
        "    # A stop sequence is a predefined or user-specified text string that\n",
        "    # signals an AI to stop generating content, ensuring its responses\n",
        "    # remain focused and concise. Examples include punctuation marks and\n",
        "    # markers like \"[end]\".\n",
        "    stop=None,\n",
        ")\n",
        "\n",
        "for chunk in completion:\n",
        "    print(chunk.choices[0].delta.content or \"\", end=\"\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FXWQIWBGvS_",
        "outputId": "a9c86423-c811-4a3f-8de7-3b64b5691cd3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm LLaMA, an AI assistant developed by Meta AI that can understand and respond to human input in a conversational manner. I'm not a human, but a computer program designed to simulate conversation and answer questions to the best of my knowledge based on the data I've been trained on.\n",
            "\n",
            "I'm a large language model, which means I've been trained on a massive dataset of text from various sources, including books, articles, research papers, and more. This training allows me to understand and generate human-like language, making me seem intelligent and conversational.\n",
            "\n",
            "When you interact with me, I can:\n",
            "\n",
            "1. Answer questions: I can provide information on a wide range of topics, from science and history to entertainment and culture.\n",
            "2. Generate text: I can create text based on a prompt or topic, which can be useful for writing, proofreading, or even generating language samples.\n",
            "3. Chat: I can engage in conversations, responding to questions and statements in a conversational manner.\n",
            "4. Translate: I can translate text from one language to another (currently supporting over 40 languages).\n",
            "5. Summarize: I can summarize long pieces of text, like articles or documents, into shorter, more digestible versions.\n",
            "\n",
            "I'm a machine learning model, so I can learn and improve over time based on the data I receive and the conversations I have with users like you. My goal is to assist and provide useful information, while also engaging in fun and interesting conversations!"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Create a function interacting with Groq."
      ],
      "metadata": {
        "id": "pLGzx5edN7nV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_groq(input_text,\n",
        "             model=model,\n",
        "             temperature=1,\n",
        "             max_tokens=2048,\n",
        "             top_p=1,\n",
        "             stream=True,\n",
        "             stop=None):\n",
        "    completion = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": input_text\n",
        "            }],\n",
        "\n",
        "        temperature=temperature,\n",
        "        max_tokens=max_tokens,\n",
        "        top_p=top_p,\n",
        "        stream=stream,\n",
        "        stop=stop\n",
        "        )\n",
        "    response = \"\"\n",
        "    for chunk in completion:\n",
        "        response += chunk.choices[0].delta.content or \"\"\n",
        "\n",
        "    return response\n"
      ],
      "metadata": {
        "id": "EfPDZ3KkLS74"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = ask_groq(\"Tell a story about a mermaid flying on the sky.\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nC0yP_3iPlJi",
        "outputId": "f503f2c1-b268-4b8c-9185-3f5dc995f4e0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What a fantastical tale I have for you! In a land far, far away, where the ocean meets the sky, there lived a mermaid named Luna. She was a curious and adventurous soul, with shimmering scales that shone like the moon and sparkling hair that rippled like the seaweed in the ocean currents.\n",
            "\n",
            "One day, while swimming near the surface of the sea, Luna gazed longingly at the sky above. She had always dreamed of flying, just like the birds she had seen soaring overhead. The sea breeze rustled her hair as she watched a majestic swan glide effortlessly across the horizon.\n",
            "\n",
            "Driven by her curiosity, Luna sought out the wisest sea sage in the land, an ancient octopus named Aethon. She asked him for secret knowledge on how to defy gravity and touch the sky. Aethon, with his twinkling eyes and wiggly tentacles, revealed that only a select few mermaids possessed the gift of aeromancy, the magic of air and wind.\n",
            "\n",
            "Aethon handed Luna a delicate, intricately carved seashell, imbued with the essence of a thousand midday suns. \"As you blow the shell, the wind's whispers will carry you on its breath,\" he whispered. \"But, be warned, young one, the skies are treacherous, and only those with pure heart and untamed spirit can navigate its currents.\"\n",
            "\n",
            "With the shell in hand, Luna returned to her favorite coral reef, where she perfected her technique: raising the shell to her lips, she blew with all her might. At first, nothing seemed to happen. But then, a gentle breeze began to stir, caressing her scales and ruffling her hair.\n",
            "\n",
            "As the wind increased, Luna felt herself lifted off the sea floor. She whooped with joy, her laughter echoing across the waves. With the shell still held tight, she spread her arms, and to her amazement, she began to soar! Up, up, up she rose, her scales glistening in the sunlight, her hair streaming behind her like a banner.\n",
            "\n",
            "Luna danced on the wind, playing with the clouds as if they were cotton candy. She chased wispy contrails, leaving a trail of shimmering stardust in her wake. As she gazed down at the ocean below, she spotted her friends swimming in her wake, mesmerized by the sight of the mermaid flying through the air.\n",
            "\n",
            "Gliding effortlessly across the sky, Luna discovered hidden wonders: schools of iridescent butterflies, delicate as dust motes, flitted about her; and a wispy band of gold, the solar halo, encircled her, casting a warm, golden glow over all.\n",
            "\n",
            "But as the sun began to set, Luna reluctantly returned to the sea floor, her fins weary but her heart full of joy and wonder. From that day on, she'd often sneak away to practice her aeromancy, flying across the skies whenever the mood struck her, her laughter echoing across the waves, and her scales shining with the secrets of the wind.\n",
            "\n",
            "And so, dear friends, the legend of Luna, the mermaid who learned to fly on the wind, lives on forever, inspiring generations of sea creatures and whimsy-seekers to follow their dreams, no matter how impossible they may seem.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Example of Chatbot using LangChain with chat history\n",
        "\n",
        "This example shows how to build a simple chatbot with LangChain to maintain user chat history, allowing for more context-aware and coherent conversations.\n",
        "\n",
        "The following objects are used in the example:\n",
        "\n",
        "\n",
        "*   **ChatGroq**: This object initializes the connection to the Groq API using the provided API key and model name.\n",
        "*   **ConversationBufferWindowMemory**: This object manages the chat history. It keeps track of the last 5 messages (k=5) in the conversation, ensuring that the AI can reference recent interactions to provide more contextually relevant responses.\n",
        "*   **ChatPromptTemplate**: This object constructs the prompt template for the conversation.\n",
        "*   **LLMChain**: This object creates a conversation chain using the specified LLM (groq_chat), the constructed prompt template (prompt), and the memory object (memory). It orchestrates the interaction between these components to generate responses.\n",
        "*   **conversation.predict()**: This method sends the full prompt, including the user input and chat history, to the LLM to generate the chatbotâ€™s response. The response is then printed to the console.\n",
        "\n"
      ],
      "metadata": {
        "id": "ogPkpsMBUprW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain_core.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        "    MessagesPlaceholder,\n",
        ")\n",
        "from langchain_core.messages import SystemMessage\n",
        "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "def chat_with_groq(model):\n",
        "\n",
        "    groq_api_key = userdata.get('GROQ_API_KEY')\n",
        "\n",
        "    # Initialize Groq Langchain chat object and conversation\n",
        "    groq_chat = ChatGroq(\n",
        "            groq_api_key=groq_api_key,\n",
        "            model_name=model\n",
        "    )\n",
        "\n",
        "    print(\"Chatbot: How can I help you? (type 'quit' to stop)!\\n\")\n",
        "\n",
        "    # Manages the chat history, ensuring the AI remembers the specified number of history messages, in this case 5.\n",
        "    memory = ConversationBufferWindowMemory(k=5, memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "    while True:\n",
        "        user_question = input(\"You: \")\n",
        "\n",
        "        if user_question.lower() == \"quit\":\n",
        "            break\n",
        "\n",
        "        # Construct a chat prompt template using various components\n",
        "        prompt = ChatPromptTemplate.from_messages(\n",
        "            [\n",
        "                # This is the persistent system prompt, sets the initial context for the AI.\n",
        "                SystemMessage( content='You are a helpful AI assistant.'  ),\n",
        "                # This placeholder will take care of chat history.\n",
        "                MessagesPlaceholder( variable_name=\"chat_history\" ),\n",
        "                # This template is where the user's current input will be injected into the prompt.\n",
        "                HumanMessagePromptTemplate.from_template(\"{human_input}\" ),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Create a conversation chain using the LangChain\n",
        "        conversation = LLMChain(\n",
        "            # Specify the LLM that the LangChain is using\n",
        "            llm=groq_chat,\n",
        "            # Specify the prompt template to use for this conversation\n",
        "            prompt=prompt,  # The constructed prompt template.\n",
        "            # Disable verbose output, True enables it for debugging purpose\n",
        "            verbose=False,\n",
        "            # Specify the memory object for chat history\n",
        "            memory=memory,\n",
        "        )\n",
        "        # The chatbot's answer is generated by sending the full prompt to the Groq API.\n",
        "        response = conversation.predict(human_input=user_question)\n",
        "        print(\"Chatbot:\", response)\n",
        "        print(\"\\n\\n\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    model = \"llama-3.1-70b-versatile\"\n",
        "    chat_with_groq(model)\n"
      ],
      "metadata": {
        "id": "QO0Pjkn5TbvK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c9d57f9-0b64-4ca1-884d-62185ea33e1b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chatbot: How can I help you? (type 'quit' to stop)!\n",
            "\n",
            "You: How are you?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-d1a28b5be6fd>:45: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
            "  conversation = LLMChain(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chatbot: I'm functioning properly, thank you for asking. I'm a computer program designed to assist and communicate with users, so I don't have feelings or emotions like humans do. However, I'm here to help answer any questions or provide information on a wide range of topics, so please feel free to ask me anything. How can I assist you today?\n",
            "\n",
            "\n",
            "\n",
            "You: what is the distance from Tokyo to New York?\n",
            "Chatbot: The distance from Tokyo, Japan to New York City, USA is approximately 6,760 miles (10,880 kilometers). This is the straight-line distance, also known as the \"as the crow flies\" distance.\n",
            "\n",
            "However, if you're referring to the distance by air, which is more relevant for flights, the approximate distance is:\n",
            "\n",
            "* 6,742 miles (10,846 kilometers) for a direct flight from Tokyo's Narita International Airport (NRT) to New York's John F. Kennedy International Airport (JFK)\n",
            "* 6,784 miles (10,916 kilometers) for a direct flight from Tokyo's Haneda Airport (HND) to New York's John F. Kennedy International Airport (JFK)\n",
            "\n",
            "Keep in mind that flight distances can vary depending on the specific flight route and any layovers or connections.\n",
            "\n",
            "\n",
            "\n",
            "You: Then what from Kyoto?\n",
            "Chatbot: The distance from Kyoto, Japan to New York City, USA is approximately 6,823 miles (10,983 kilometers). This is the straight-line distance, also known as the \"as the crow flies\" distance.\n",
            "\n",
            "However, if you're referring to the distance by air, which is more relevant for flights, the approximate distance is:\n",
            "\n",
            "* 6,802 miles (10,945 kilometers) for a flight from Kyoto's Kansai International Airport (KIX) to New York's John F. Kennedy International Airport (JFK)\n",
            "* 6,844 miles (11,014 kilometers) for a flight from Kyoto's Osaka Itami Airport (ITM) to New York's John F. Kennedy International Airport (JFK)\n",
            "\n",
            "Keep in mind that Kyoto doesn't have a major international airport, so most flights from Kyoto to New York would involve a connection in another Japanese city, such as Tokyo or Osaka.\n",
            "\n",
            "\n",
            "\n",
            "You: And what form Shanghai?\n",
            "Chatbot: The distance from Shanghai, China to New York City, USA is approximately 7,576 miles (12,194 kilometers). This is the straight-line distance, also known as the \"as the crow flies\" distance.\n",
            "\n",
            "However, if you're referring to the distance by air, which is more relevant for flights, the approximate distance is:\n",
            "\n",
            "* 7,565 miles (12,176 kilometers) for a direct flight from Shanghai Pudong International Airport (PVG) to New York's John F. Kennedy International Airport (JFK)\n",
            "* 7,608 miles (12,243 kilometers) for a direct flight from Shanghai Hongqiao International Airport (SHA) to New York's John F. Kennedy International Airport (JFK)\n",
            "\n",
            "Keep in mind that flight distances can vary depending on the specific flight route and any layovers or connections.\n",
            "\n",
            "\n",
            "\n",
            "You: what from Toronto?\n",
            "Chatbot: The distance from Toronto, Canada to New York City, USA is approximately 342 miles (550 kilometers). This is the straight-line distance, also known as the \"as the crow flies\" distance.\n",
            "\n",
            "However, if you're referring to the distance by air, which is more relevant for flights, the approximate distance is:\n",
            "\n",
            "* 341 miles (549 kilometers) for a direct flight from Toronto Pearson International Airport (YYZ) to New York's John F. Kennedy International Airport (JFK)\n",
            "* 345 miles (555 kilometers) for a direct flight from Toronto Pearson International Airport (YYZ) to New York's LaGuardia Airport (LGA)\n",
            "\n",
            "Keep in mind that flight distances can vary depending on the specific flight route and any layovers or connections.\n",
            "\n",
            "\n",
            "\n",
            "You: quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Use RunnableSequence instead of LLMChain (deprecated)\n",
        "\n",
        "The below example uses RunnableSequence instead of LLMChain which is deprecated. The RunnableSequence is created using the | operator to chain the prompt template and the language model together.\n",
        "\n",
        "The following objects are used in the example:\n",
        "\n",
        "*   **ChatGroq**: Same as above, it initializes the connection to the Groq API using the provided API key and model name.\n",
        "*   **ConversationBufferWindowMemory**: Same as above, it manages the chat history.\n",
        "*   **ChatPromptTemplate**: Same as above, it constructs the prompt template for the conversation.\n",
        "*   **RunnableSequence**: This creates a sequence of operations using the | operator. Here,  ```conversation = prompt | groq_chat```\n",
        "it chains the prompt template (prompt) with the language model (groq_chat). This sequence will be used to generate responses based on the userâ€™s input and the chat history.\n",
        "*   **memory.load_memory_variables()**: Retrieves the chat history from the memory object. It returns a dictionary, and we access the chat_history key to get the list of historical messages.\n",
        "*   **conversation.invoke()**: Sends the full prompt, including the userâ€™s input and chat history, to the language model to generate the chatbotâ€™s response. The response is then printed to the console.\n",
        "*   **memory.save_context()**: Updates the memory with the new interaction. It takes two dictionaries: one for the userâ€™s input and one for the chatbotâ€™s output, ensuring that the conversation history is maintained for future interactions. You can ```print(memory.load_memory_variables({})[\"chat_history\"])``` to check the history.\n",
        "\n"
      ],
      "metadata": {
        "id": "qvR9lh3KbJJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chat_with_groq2(model):\n",
        "    groq_api_key = userdata.get('GROQ_API_KEY')\n",
        "\n",
        "    # Initialize Groq Langchain chat object and conversation\n",
        "    groq_chat = ChatGroq(\n",
        "            groq_api_key=groq_api_key,\n",
        "            model_name=model\n",
        "    )\n",
        "\n",
        "    print(\"Chatbot: How can I help you? (type 'quit' to stop)!\\n\")\n",
        "\n",
        "    # Manages the chat history, ensuring the AI remembers the specified number of history messages, in this case 5.\n",
        "    memory = ConversationBufferWindowMemory(k=5, memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "    while True:\n",
        "        user_question = input(\"You: \")\n",
        "\n",
        "        if user_question.lower() == \"quit\":\n",
        "            break\n",
        "\n",
        "        # Construct a chat prompt template using various components\n",
        "        prompt = ChatPromptTemplate.from_messages(\n",
        "            [\n",
        "                # This is the persistent system prompt, sets the initial context for the AI.\n",
        "                SystemMessage(content='You are a helpful AI assistant.'),\n",
        "                # This placeholder will take care of chat history.\n",
        "                MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "                # This template is where the user's current input will be injected into the prompt.\n",
        "                HumanMessagePromptTemplate.from_template(\"{human_input}\"),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Create a conversation sequence using RunnableSequence\n",
        "        conversation = prompt | groq_chat\n",
        "\n",
        "        # Load chat_history\n",
        "        chat_history = memory.load_memory_variables({})[\"chat_history\"]\n",
        "\n",
        "        # The chatbot's answer is generated by sending the full prompt to the LLM\n",
        "        response = conversation.invoke({\"human_input\": user_question, \"chat_history\": chat_history})\n",
        "        print(\"Chatbot:\", response.content)\n",
        "        print(\"\\n\\n\")\n",
        "\n",
        "        # Update the memory with the new interaction\n",
        "        memory.save_context({\"input\": user_question}, {\"output\": response.content})\n",
        "\n",
        "\n",
        "chat_with_groq2( model = \"llama3-70b-8192\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmTiLHpEVZCc",
        "outputId": "06fcebe0-b4e1-4b8d-d88b-86031ed10815"
      },
      "execution_count": 19,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chatbot: How can I help you? (type 'quit' to stop)!\n",
            "\n",
            "You: What's your name, and please introduce yourself.\n",
            "Chatbot: Nice to meet you! My name is Lumin, and I'm a friendly AI assistant designed to provide helpful and informative responses to your questions and engage in conversations. I'm here to assist you with any topics you'd like to discuss, from science and technology to entertainment and culture.\n",
            "\n",
            "I'm a large language model, which means I've been trained on a massive dataset of text from the internet and can generate human-like responses. I'm constantly learning and improving, so please bear with me if I make any mistakes.\n",
            "\n",
            "My goal is to provide accurate and helpful information, answer your questions to the best of my abilities, and even offer suggestions or ideas when needed. I'm a great listener, so feel free to share your thoughts, ask for advice, or simply chat with me about your day.\n",
            "\n",
            "I'm excited to get to know you better and assist you in any way I can. What's on your mind today?\n",
            "\n",
            "\n",
            "\n",
            "You: What's the distance from Tokyo to New York?\n",
            "Chatbot: The distance from Tokyo, Japan to New York City, USA is approximately:\n",
            "\n",
            "* 6,760 miles (10,880 kilometers) when measured as a straight line (also known as a great-circle distance)\n",
            "* 7,221 miles (11,617 kilometers) when following a typical flight route (which is usually not a straight line due to factors like wind, air traffic control, and fuel efficiency)\n",
            "\n",
            "To give you a better idea, a direct flight from Tokyo's Narita International Airport (NRT) or Haneda Airport (HND) to New York's John F. Kennedy International Airport (JFK) typically takes around 11-12 hours, depending on the airline, flight schedule, and weather conditions.\n",
            "\n",
            "Would you like to know more about flight routes, travel times, or maybe even some fun facts about Tokyo or New York City?\n",
            "\n",
            "\n",
            "\n",
            "You: Then what to Beijing?\n",
            "Chatbot: The distance from Tokyo, Japan to Beijing, China is approximately:\n",
            "\n",
            "* 534 miles (859 kilometers) when measured as a straight line (also known as a great-circle distance)\n",
            "* 620 miles (998 kilometers) when following a typical flight route (which is usually not a straight line due to factors like wind, air traffic control, and fuel efficiency)\n",
            "\n",
            "A direct flight from Tokyo's Narita International Airport (NRT) or Haneda Airport (HND) to Beijing Capital International Airport (PEK) typically takes around 2-3 hours, depending on the airline, flight schedule, and weather conditions.\n",
            "\n",
            "Beijing is a fascinating city, rich in history, culture, and delicious food! If you're planning a trip, I'd be happy to share some insights on must-see attractions, trying authentic Chinese cuisine, or exploring the city's vibrant neighborhoods.\n",
            "\n",
            "Would you like to know more about traveling to Beijing, or maybe compare it to other Asian cities?\n",
            "\n",
            "\n",
            "\n",
            "You: And what to Kyoto?\n",
            "Chatbot: Kyoto!\n",
            "\n",
            "The distance from Tokyo, Japan to Kyoto, Japan is approximately:\n",
            "\n",
            "* 314 miles (505 kilometers) when measured as a straight line (also known as a great-circle distance)\n",
            "* 343 miles (552 kilometers) when following a typical train route (like the famous Shinkansen bullet train)\n",
            "\n",
            "The travel time from Tokyo to Kyoto is relatively short, with options like:\n",
            "\n",
            "* By train: Around 2.5 hours on the Nozomi Shinkansen train, which runs frequently throughout the day.\n",
            "* By plane: About 1 hour, with flights available from Tokyo's Haneda Airport (HND) or Narita International Airport (NRT) to Kyoto's Kansai International Airport (KIX), followed by a 1-hour train or bus ride to Kyoto city.\n",
            "* By bus: Around 7-8 hours, depending on traffic and the route.\n",
            "\n",
            "Kyoto is a treasure trove of Japanese culture, history, and natural beauty! If you're planning a trip, I'd be delighted to share recommendations on:\n",
            "\n",
            "* Must-visit temples and shrines, like Fushimi Inari and Kinkaku-ji\n",
            "* Exploring Kyoto's geisha district, Gion\n",
            "* Discovering the city's delicious food scene, including kaiseki, shojin-ryori, and yudofu\n",
            "* Strolling through Arashiyama's picturesque bamboo forest\n",
            "\n",
            "What would you like to know more about Kyoto?\n",
            "\n",
            "\n",
            "\n",
            "You: quit\n"
          ]
        }
      ]
    }
  ]
}