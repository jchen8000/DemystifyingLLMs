{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jchen8000/DemystifyingLLMs/blob/main/6_Deployment/Chatbot_LangChain_Groq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odFnqwh7JiX-"
      },
      "source": [
        "# 6. Deployment of LLMs\n",
        "\n",
        "## 6.11 Chatbot, Example of LLM-Powered Application\n",
        "\n",
        "### **Building a Simple Chatbot with LangChain and GROQ model**\n",
        "\n",
        "This notebook demonstrates how to use **LangChain** to build a simple, interactive chatbot powered by a **GroqCloud-hosted large language model**.  \n",
        "The example shows how to structure conversational prompts, maintain chat history, and generate context-aware responses using modern LangChain patterns.\n",
        "\n",
        "### Model and API Requirements\n",
        "\n",
        "- The chatbot uses a language model served by **GroqCloud**\n",
        "- A valid **`GROQ_API_KEY`** is required to authenticate requests to the Groq API, see https://console.groq.com/docs/quickstart  \n",
        "- The API key is expected to be provided via your runtime environment (for example, as an environment variable or through notebook secrets)\n",
        "\n",
        "### What this example covers\n",
        "\n",
        "- Initializing a Groq-backed chat model with LangChain\n",
        "- Structuring conversations using system, human, and assistant messages\n",
        "- Maintaining short-term chat history for coherent multi-turn conversations\n",
        "- Invoking the model to generate responses in an interactive loop\n",
        "\n",
        "### Compatibility Note\n",
        "\n",
        "> **Important**  \n",
        "> This code has been tested and confirmed to work as of **January 2026**.  \n",
        "> However, both **LangChain** and **GroqCloud models / SDKs** are actively evolving.  \n",
        "> Future changes to package versions, APIs, or available models may require updates to this notebook for continued compatibility.\n",
        "\n",
        "This example is intended as a **learning and reference implementation** to illustrate current best practices rather than a permanently stable API contract.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HX3UexDhKnTm"
      },
      "source": [
        "### 1. Install required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6HaHQZaGa_v"
      },
      "outputs": [],
      "source": [
        "%pip install -q \\\n",
        "  groq==0.37.1 \\\n",
        "  langchain==1.2.3 \\\n",
        "  langchain-core==1.2.6 \\\n",
        "  langchain_groq==1.1.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGL9tRjcKhlA"
      },
      "source": [
        "### 2. API Key From Groq Cloud\n",
        "\n",
        "GroqCloud is a cloud-based platform developed by Groq, designed to provide high-speed AI inference capabilities. It supports a variety of large language models (LLMs) from different developers.\n",
        "\n",
        "You will need to sign up for an account on the platform to obtain an API key, at the time this example is created, you can get an API key for free.\n",
        "\n",
        "This example shows how to use the **Colab Secret** supported by Google Colab, it is designed to help users securely manage sensitive information like API keys, environment variables, etc. On the left sidebar of Google Colab, you’ll see a key icon. Click on it to open the Secrets section, and add a new Secret, give it a name (in this case, **GROQ_API_KEY**) and enter the value which is the API Key you got from Groq Cloud.\n",
        "\n",
        "Below code snippet shows how to retrieve it.\n",
        "\n",
        "Note, if you don't use Google Colab, use other ways to manage the keys, and make sure it's secure and not exposed to others."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcNcdC7vFvFw"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "from groq import Groq\n",
        "\n",
        "client = Groq(\n",
        "    api_key = userdata.get('GROQ_API_KEY')\n",
        ")\n",
        "\n",
        "GROQ_MODEL = \"llama-3.1-8b-instant\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzohinP7NiBA"
      },
      "source": [
        "### 3. A Sample Call to Groq\n",
        "\n",
        "Reference: https://console.groq.com/docs/api-reference#chat-create\n",
        "\n",
        "Note, you can specify the optional parameters like *temperature*, *max_tokens*, *top_p*, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FXWQIWBGvS_",
        "outputId": "a9c86423-c811-4a3f-8de7-3b64b5691cd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I'm LLaMA, an AI assistant developed by Meta AI that can understand and respond to human input in a conversational manner. I'm not a human, but a computer program designed to simulate conversation and answer questions to the best of my knowledge based on the data I've been trained on.\n",
            "\n",
            "I'm a large language model, which means I've been trained on a massive dataset of text from various sources, including books, articles, research papers, and more. This training allows me to understand and generate human-like language, making me seem intelligent and conversational.\n",
            "\n",
            "When you interact with me, I can:\n",
            "\n",
            "1. Answer questions: I can provide information on a wide range of topics, from science and history to entertainment and culture.\n",
            "2. Generate text: I can create text based on a prompt or topic, which can be useful for writing, proofreading, or even generating language samples.\n",
            "3. Chat: I can engage in conversations, responding to questions and statements in a conversational manner.\n",
            "4. Translate: I can translate text from one language to another (currently supporting over 40 languages).\n",
            "5. Summarize: I can summarize long pieces of text, like articles or documents, into shorter, more digestible versions.\n",
            "\n",
            "I'm a machine learning model, so I can learn and improve over time based on the data I receive and the conversations I have with users like you. My goal is to assist and provide useful information, while also engaging in fun and interesting conversations!"
          ]
        }
      ],
      "source": [
        "model = GROQ_MODEL\n",
        "completion = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Who are you and please introduce yourself.\"\n",
        "        }\n",
        "    ],\n",
        "\n",
        "    # Controls randomness: lowering results in less random completions.\n",
        "    # As the temperature approaches zero, the model will become deterministic\n",
        "    # and repetitive.\n",
        "    temperature=1,\n",
        "\n",
        "    # The maximum number of tokens to generate. Requests can use up to\n",
        "    # 2048 tokens shared between prompt and completion.\n",
        "    max_tokens=2048,\n",
        "\n",
        "    # Controls diversity via nucleus sampling: 0.5 means half of all\n",
        "    # likelihood-weighted options are considered.\n",
        "    top_p=1,\n",
        "\n",
        "    # If set, partial message deltas will be sent.\n",
        "    stream=True,\n",
        "\n",
        "    # A stop sequence is a predefined or user-specified text string that\n",
        "    # signals an AI to stop generating content, ensuring its responses\n",
        "    # remain focused and concise. Examples include punctuation marks and\n",
        "    # markers like \"[end]\".\n",
        "    stop=None,\n",
        ")\n",
        "\n",
        "for chunk in completion:\n",
        "    print(chunk.choices[0].delta.content or \"\", end=\"\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLGzx5edN7nV"
      },
      "source": [
        "### 4. Create a function interacting with Groq."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nC0yP_3iPlJi",
        "outputId": "f503f2c1-b268-4b8c-9185-3f5dc995f4e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What a fantastical tale I have for you! In a land far, far away, where the ocean meets the sky, there lived a mermaid named Luna. She was a curious and adventurous soul, with shimmering scales that shone like the moon and sparkling hair that rippled like the seaweed in the ocean currents.\n",
            "\n",
            "One day, while swimming near the surface of the sea, Luna gazed longingly at the sky above. She had always dreamed of flying, just like the birds she had seen soaring overhead. The sea breeze rustled her hair as she watched a majestic swan glide effortlessly across the horizon.\n",
            "\n",
            "Driven by her curiosity, Luna sought out the wisest sea sage in the land, an ancient octopus named Aethon. She asked him for secret knowledge on how to defy gravity and touch the sky. Aethon, with his twinkling eyes and wiggly tentacles, revealed that only a select few mermaids possessed the gift of aeromancy, the magic of air and wind.\n",
            "\n",
            "Aethon handed Luna a delicate, intricately carved seashell, imbued with the essence of a thousand midday suns. \"As you blow the shell, the wind's whispers will carry you on its breath,\" he whispered. \"But, be warned, young one, the skies are treacherous, and only those with pure heart and untamed spirit can navigate its currents.\"\n",
            "\n",
            "With the shell in hand, Luna returned to her favorite coral reef, where she perfected her technique: raising the shell to her lips, she blew with all her might. At first, nothing seemed to happen. But then, a gentle breeze began to stir, caressing her scales and ruffling her hair.\n",
            "\n",
            "As the wind increased, Luna felt herself lifted off the sea floor. She whooped with joy, her laughter echoing across the waves. With the shell still held tight, she spread her arms, and to her amazement, she began to soar! Up, up, up she rose, her scales glistening in the sunlight, her hair streaming behind her like a banner.\n",
            "\n",
            "Luna danced on the wind, playing with the clouds as if they were cotton candy. She chased wispy contrails, leaving a trail of shimmering stardust in her wake. As she gazed down at the ocean below, she spotted her friends swimming in her wake, mesmerized by the sight of the mermaid flying through the air.\n",
            "\n",
            "Gliding effortlessly across the sky, Luna discovered hidden wonders: schools of iridescent butterflies, delicate as dust motes, flitted about her; and a wispy band of gold, the solar halo, encircled her, casting a warm, golden glow over all.\n",
            "\n",
            "But as the sun began to set, Luna reluctantly returned to the sea floor, her fins weary but her heart full of joy and wonder. From that day on, she'd often sneak away to practice her aeromancy, flying across the skies whenever the mood struck her, her laughter echoing across the waves, and her scales shining with the secrets of the wind.\n",
            "\n",
            "And so, dear friends, the legend of Luna, the mermaid who learned to fly on the wind, lives on forever, inspiring generations of sea creatures and whimsy-seekers to follow their dreams, no matter how impossible they may seem.\n"
          ]
        }
      ],
      "source": [
        "def ask_groq(input_text,\n",
        "             model=model,\n",
        "             temperature=1,\n",
        "             max_tokens=2048,\n",
        "             top_p=1,\n",
        "             stream=True,\n",
        "             stop=None):\n",
        "    completion = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": input_text\n",
        "            }],\n",
        "\n",
        "        temperature=temperature,\n",
        "        max_tokens=max_tokens,\n",
        "        top_p=top_p,\n",
        "        stream=stream,\n",
        "        stop=stop\n",
        "        )\n",
        "    response = \"\"\n",
        "    for chunk in completion:\n",
        "        response += chunk.choices[0].delta.content or \"\"\n",
        "\n",
        "    return response\n",
        "\n",
        "response = ask_groq(\"Tell a story about a mermaid flying on the sky.\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogPkpsMBUprW"
      },
      "source": [
        "### 5. Example of Chatbot using LangChain with chat history\n",
        "\n",
        "This example shows how to build a simple chatbot with LangChain to maintain user chat history, allowing for more context-aware and coherent conversations.\n",
        "\n",
        "---\n",
        "\n",
        "#### Objects and concepts used in this example\n",
        "\n",
        "* **ChatGroq**  \n",
        "  Initializes the connection to the Groq API using the provided API key and model name.  \n",
        "  It is responsible for sending a list of structured chat messages to the Groq-hosted model and returning the model’s response.\n",
        "\n",
        "* **SystemMessage / HumanMessage / AIMessage**  \n",
        "  These message objects define the conversational structure:\n",
        "  - `SystemMessage` sets persistent behavior and instructions for the assistant\n",
        "  - `HumanMessage` represents user input\n",
        "  - `AIMessage` represents the model’s response  \n",
        "\n",
        "  Together, they form the conversational context passed to the model on each turn.\n",
        "\n",
        "* **Manual chat history (application-managed memory)**  \n",
        "  Instead of `ConversationBufferWindowMemory`, the conversation history is stored in a Python list containing `HumanMessage` and `AIMessage` objects.  \n",
        "  A rolling window is enforced to keep only the most recent interactions (e.g. the last 5 turns), ensuring:\n",
        "  - Controlled token usage\n",
        "  - Relevant short-term context\n",
        "  - Predictable behavior across versions\n",
        "\n",
        "* **ChatPromptTemplate (optional)**  \n",
        "  When used, this object defines how system messages, historical messages, and the current user input are combined into a prompt.  \n",
        "  In simpler cases, messages can be passed directly to the model without a template.\n",
        "\n",
        "* **Model invocation (`invoke`)**  \n",
        "  The chatbot sends the full conversational context—including the system message, chat history, and current user input—to the model using `invoke()`.  \n",
        "  The returned response is then printed and appended to the chat history for subsequent turns.\n",
        "\n",
        "---\n",
        "\n",
        "This example reflects the **recommended LangChain pattern in 2026** for building chatbots that maintain conversational context without relying on deprecated abstractions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QO0Pjkn5TbvK",
        "outputId": "6c9d57f9-0b64-4ca1-884d-62185ea33e1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chatbot: How can I help you? (type 'quit' to stop)!\n",
            "\n",
            "You: How are you?\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chatbot: I'm functioning properly, thank you for asking. I'm a computer program designed to assist and communicate with users, so I don't have feelings or emotions like humans do. However, I'm here to help answer any questions or provide information on a wide range of topics, so please feel free to ask me anything. How can I assist you today?\n",
            "\n",
            "\n",
            "\n",
            "You: what is the distance from Tokyo to New York?\n",
            "Chatbot: The distance from Tokyo, Japan to New York City, USA is approximately 6,760 miles (10,880 kilometers). This is the straight-line distance, also known as the \"as the crow flies\" distance.\n",
            "\n",
            "However, if you're referring to the distance by air, which is more relevant for flights, the approximate distance is:\n",
            "\n",
            "* 6,742 miles (10,846 kilometers) for a direct flight from Tokyo's Narita International Airport (NRT) to New York's John F. Kennedy International Airport (JFK)\n",
            "* 6,784 miles (10,916 kilometers) for a direct flight from Tokyo's Haneda Airport (HND) to New York's John F. Kennedy International Airport (JFK)\n",
            "\n",
            "Keep in mind that flight distances can vary depending on the specific flight route and any layovers or connections.\n",
            "\n",
            "\n",
            "\n",
            "You: Then what from Kyoto?\n",
            "Chatbot: The distance from Kyoto, Japan to New York City, USA is approximately 6,823 miles (10,983 kilometers). This is the straight-line distance, also known as the \"as the crow flies\" distance.\n",
            "\n",
            "However, if you're referring to the distance by air, which is more relevant for flights, the approximate distance is:\n",
            "\n",
            "* 6,802 miles (10,945 kilometers) for a flight from Kyoto's Kansai International Airport (KIX) to New York's John F. Kennedy International Airport (JFK)\n",
            "* 6,844 miles (11,014 kilometers) for a flight from Kyoto's Osaka Itami Airport (ITM) to New York's John F. Kennedy International Airport (JFK)\n",
            "\n",
            "Keep in mind that Kyoto doesn't have a major international airport, so most flights from Kyoto to New York would involve a connection in another Japanese city, such as Tokyo or Osaka.\n",
            "\n",
            "\n",
            "\n",
            "You: And what form Shanghai?\n",
            "Chatbot: The distance from Shanghai, China to New York City, USA is approximately 7,576 miles (12,194 kilometers). This is the straight-line distance, also known as the \"as the crow flies\" distance.\n",
            "\n",
            "However, if you're referring to the distance by air, which is more relevant for flights, the approximate distance is:\n",
            "\n",
            "* 7,565 miles (12,176 kilometers) for a direct flight from Shanghai Pudong International Airport (PVG) to New York's John F. Kennedy International Airport (JFK)\n",
            "* 7,608 miles (12,243 kilometers) for a direct flight from Shanghai Hongqiao International Airport (SHA) to New York's John F. Kennedy International Airport (JFK)\n",
            "\n",
            "Keep in mind that flight distances can vary depending on the specific flight route and any layovers or connections.\n",
            "\n",
            "\n",
            "\n",
            "You: what from Toronto?\n",
            "Chatbot: The distance from Toronto, Canada to New York City, USA is approximately 342 miles (550 kilometers). This is the straight-line distance, also known as the \"as the crow flies\" distance.\n",
            "\n",
            "However, if you're referring to the distance by air, which is more relevant for flights, the approximate distance is:\n",
            "\n",
            "* 341 miles (549 kilometers) for a direct flight from Toronto Pearson International Airport (YYZ) to New York's John F. Kennedy International Airport (JFK)\n",
            "* 345 miles (555 kilometers) for a direct flight from Toronto Pearson International Airport (YYZ) to New York's LaGuardia Airport (LGA)\n",
            "\n",
            "Keep in mind that flight distances can vary depending on the specific flight route and any layovers or connections.\n",
            "\n",
            "\n",
            "\n",
            "You: quit\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "def chat_with_groq(model):\n",
        "    groq_api_key = userdata.get(\"GROQ_API_KEY\")\n",
        "\n",
        "    llm = ChatGroq(\n",
        "        groq_api_key=groq_api_key,\n",
        "        model_name=model,\n",
        "    )\n",
        "\n",
        "    chat_history = []  # <-- YOU manage memory\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        SystemMessage(content=\"You are a helpful AI assistant.\"),\n",
        "        *chat_history,\n",
        "        (\"human\", \"{human_input}\")\n",
        "    ])\n",
        "\n",
        "    print(\"Chatbot: How can I help you? (type 'quit' to stop)\\n\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() == \"quit\":\n",
        "            break\n",
        "\n",
        "        response = llm.invoke([\n",
        "            SystemMessage(content=\"You are a helpful AI assistant.\"),\n",
        "            *chat_history,\n",
        "            HumanMessage(content=user_input)\n",
        "        ])\n",
        "\n",
        "        chat_history.append(HumanMessage(content=user_input))\n",
        "        chat_history.append(AIMessage(content=response.content))\n",
        "\n",
        "        # keep last 5 turns\n",
        "        chat_history[:] = chat_history[-10:]\n",
        "\n",
        "        print(\"Chatbot:\", response.content)\n",
        "        print()\n",
        "\n",
        "model = GROQ_MODEL\n",
        "chat_with_groq(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvR9lh3KbJJ9"
      },
      "source": [
        "### 6. Use RunnableSequence instead of LLMChain\n",
        "\n",
        "The following example demonstrates how to use **RunnableSequence** (LCEL) instead of the deprecated `LLMChain`.  \n",
        "\n",
        "RunnableSequence is created using the `|` operator to chain a prompt template and a language model into a single executable pipeline.\n",
        "\n",
        "---\n",
        "\n",
        "#### Objects used in this example\n",
        "\n",
        "* **ChatGroq**  \n",
        "  Initializes the connection to the Groq API using the provided API key and model name. It is responsible for sending the formatted messages to the Groq-hosted LLM and returning the model’s response.\n",
        "\n",
        "* **ChatPromptTemplate**  \n",
        "  Defines how messages are structured before being sent to the model.  \n",
        "  It includes:\n",
        "  - A persistent system message\n",
        "  - A placeholder for chat history\n",
        "  - A template for the current user input\n",
        "\n",
        "* **MessagesPlaceholder**  \n",
        "  Acts as an insertion point for historical messages. The application supplies the current `chat_history` list at runtime.\n",
        "\n",
        "* **RunnableSequence**  \n",
        "  Created using the `|` operator:\n",
        "  ```python\n",
        "  conversation = prompt | groq_chat\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmTiLHpEVZCc",
        "outputId": "06fcebe0-b4e1-4b8d-d88b-86031ed10815"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chatbot: How can I help you? (type 'quit' to stop)!\n",
            "\n",
            "You: What's your name, and please introduce yourself.\n",
            "Chatbot: Nice to meet you! My name is Lumin, and I'm a friendly AI assistant designed to provide helpful and informative responses to your questions and engage in conversations. I'm here to assist you with any topics you'd like to discuss, from science and technology to entertainment and culture.\n",
            "\n",
            "I'm a large language model, which means I've been trained on a massive dataset of text from the internet and can generate human-like responses. I'm constantly learning and improving, so please bear with me if I make any mistakes.\n",
            "\n",
            "My goal is to provide accurate and helpful information, answer your questions to the best of my abilities, and even offer suggestions or ideas when needed. I'm a great listener, so feel free to share your thoughts, ask for advice, or simply chat with me about your day.\n",
            "\n",
            "I'm excited to get to know you better and assist you in any way I can. What's on your mind today?\n",
            "\n",
            "\n",
            "\n",
            "You: What's the distance from Tokyo to New York?\n",
            "Chatbot: The distance from Tokyo, Japan to New York City, USA is approximately:\n",
            "\n",
            "* 6,760 miles (10,880 kilometers) when measured as a straight line (also known as a great-circle distance)\n",
            "* 7,221 miles (11,617 kilometers) when following a typical flight route (which is usually not a straight line due to factors like wind, air traffic control, and fuel efficiency)\n",
            "\n",
            "To give you a better idea, a direct flight from Tokyo's Narita International Airport (NRT) or Haneda Airport (HND) to New York's John F. Kennedy International Airport (JFK) typically takes around 11-12 hours, depending on the airline, flight schedule, and weather conditions.\n",
            "\n",
            "Would you like to know more about flight routes, travel times, or maybe even some fun facts about Tokyo or New York City?\n",
            "\n",
            "\n",
            "\n",
            "You: Then what to Beijing?\n",
            "Chatbot: The distance from Tokyo, Japan to Beijing, China is approximately:\n",
            "\n",
            "* 534 miles (859 kilometers) when measured as a straight line (also known as a great-circle distance)\n",
            "* 620 miles (998 kilometers) when following a typical flight route (which is usually not a straight line due to factors like wind, air traffic control, and fuel efficiency)\n",
            "\n",
            "A direct flight from Tokyo's Narita International Airport (NRT) or Haneda Airport (HND) to Beijing Capital International Airport (PEK) typically takes around 2-3 hours, depending on the airline, flight schedule, and weather conditions.\n",
            "\n",
            "Beijing is a fascinating city, rich in history, culture, and delicious food! If you're planning a trip, I'd be happy to share some insights on must-see attractions, trying authentic Chinese cuisine, or exploring the city's vibrant neighborhoods.\n",
            "\n",
            "Would you like to know more about traveling to Beijing, or maybe compare it to other Asian cities?\n",
            "\n",
            "\n",
            "\n",
            "You: And what to Kyoto?\n",
            "Chatbot: Kyoto!\n",
            "\n",
            "The distance from Tokyo, Japan to Kyoto, Japan is approximately:\n",
            "\n",
            "* 314 miles (505 kilometers) when measured as a straight line (also known as a great-circle distance)\n",
            "* 343 miles (552 kilometers) when following a typical train route (like the famous Shinkansen bullet train)\n",
            "\n",
            "The travel time from Tokyo to Kyoto is relatively short, with options like:\n",
            "\n",
            "* By train: Around 2.5 hours on the Nozomi Shinkansen train, which runs frequently throughout the day.\n",
            "* By plane: About 1 hour, with flights available from Tokyo's Haneda Airport (HND) or Narita International Airport (NRT) to Kyoto's Kansai International Airport (KIX), followed by a 1-hour train or bus ride to Kyoto city.\n",
            "* By bus: Around 7-8 hours, depending on traffic and the route.\n",
            "\n",
            "Kyoto is a treasure trove of Japanese culture, history, and natural beauty! If you're planning a trip, I'd be delighted to share recommendations on:\n",
            "\n",
            "* Must-visit temples and shrines, like Fushimi Inari and Kinkaku-ji\n",
            "* Exploring Kyoto's geisha district, Gion\n",
            "* Discovering the city's delicious food scene, including kaiseki, shojin-ryori, and yudofu\n",
            "* Strolling through Arashiyama's picturesque bamboo forest\n",
            "\n",
            "What would you like to know more about Kyoto?\n",
            "\n",
            "\n",
            "\n",
            "You: quit\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.messages import (\n",
        "    SystemMessage,\n",
        "    HumanMessage,\n",
        "    AIMessage,\n",
        ")\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "\n",
        "def chat_with_groq2(model):\n",
        "    groq_api_key = userdata.get(\"GROQ_API_KEY\")\n",
        "\n",
        "    groq_chat = ChatGroq(\n",
        "        groq_api_key=groq_api_key,\n",
        "        model_name=model,\n",
        "    )\n",
        "\n",
        "    print(\"Chatbot: How can I help you? (type 'quit' to stop)!\\n\")\n",
        "\n",
        "    chat_history = []\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        SystemMessage(content=\"You are a helpful AI assistant.\"),\n",
        "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "        (\"human\", \"{human_input}\"),\n",
        "    ])\n",
        "\n",
        "    conversation = prompt | groq_chat  # <-- RunnableSequence\n",
        "\n",
        "    MAX_TURNS = 5\n",
        "    MAX_MESSAGES = MAX_TURNS * 2\n",
        "\n",
        "    while True:\n",
        "        user_question = input(\"You: \")\n",
        "        if user_question.lower() == \"quit\":\n",
        "            break\n",
        "\n",
        "        response = conversation.invoke({\n",
        "            \"human_input\": user_question,\n",
        "            \"chat_history\": chat_history,\n",
        "        })\n",
        "\n",
        "        print(\"Chatbot:\", response.content)\n",
        "        print()\n",
        "\n",
        "        # Update manual memory\n",
        "        chat_history.append(HumanMessage(content=user_question))\n",
        "        chat_history.append(AIMessage(content=response.content))\n",
        "\n",
        "        # Keep last k turns\n",
        "        chat_history[:] = chat_history[-MAX_MESSAGES:]\n",
        "\n",
        "\n",
        "chat_with_groq2(model=GROQ_MODEL)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNDoUt8oRjpOzL2SVoxzMyk",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
